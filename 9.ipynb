{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "9.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cd166929bcc54b6abc0207708532fdf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_595a66c0c7bb4195ae44bcf95285ef8f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6823239db42543c59eb2feae40358a5f",
              "IPY_MODEL_4bd9b9ba678a4f0988904861ac1425da"
            ]
          }
        },
        "595a66c0c7bb4195ae44bcf95285ef8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6823239db42543c59eb2feae40358a5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c7a88a005e9f434a8f28dce02c980827",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_75d6a6e3e9c842488a043c62c9509e09"
          }
        },
        "4bd9b9ba678a4f0988904861ac1425da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_efa05073f73e45019d5d52a62dc2f2b1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:00&lt;00:00, 510kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_42be44f8afa24d44a13b5287470786c3"
          }
        },
        "c7a88a005e9f434a8f28dce02c980827": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "75d6a6e3e9c842488a043c62c9509e09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "efa05073f73e45019d5d52a62dc2f2b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "42be44f8afa24d44a13b5287470786c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "de70af565f164d2299cadc3660f59a32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_92a5b8aa11e84e669caafb527a8e5401",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3a7be42e06f44b97851df454b0ff7d1b",
              "IPY_MODEL_b8aa4967028d466fb7c94945b3683b3a"
            ]
          }
        },
        "92a5b8aa11e84e669caafb527a8e5401": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3a7be42e06f44b97851df454b0ff7d1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_17f78fa26485417bb1e91e2f398d4c8c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 29,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 29,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ed27845a7aca4184b254ab49b2333a0a"
          }
        },
        "b8aa4967028d466fb7c94945b3683b3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_805f52ceae2241998b35c71b38585bd3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29.0/29.0 [00:00&lt;00:00, 72.3B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_db8450e5e4d14eb18df646ce40541880"
          }
        },
        "17f78fa26485417bb1e91e2f398d4c8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ed27845a7aca4184b254ab49b2333a0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "805f52ceae2241998b35c71b38585bd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "db8450e5e4d14eb18df646ce40541880": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ffb59f745a7f4d57b4f88b0229db91f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fd5b7ca54f8e47bf87d77fe1cac8baf0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8d3f116b99d4495fbc881550dc497ff2",
              "IPY_MODEL_45a63dbdb06c4c7bba3bcf8cedc3ab82"
            ]
          }
        },
        "fd5b7ca54f8e47bf87d77fe1cac8baf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8d3f116b99d4495fbc881550dc497ff2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7d9c0d184a7c4c89809fe729b1a36c94",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435797,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435797,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_98e2453ff0aa4934a306c01050e40074"
          }
        },
        "45a63dbdb06c4c7bba3bcf8cedc3ab82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a46c652e0f654dbd99628d229bb3b334",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436k/436k [00:00&lt;00:00, 3.42MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_265da60f5f6b468fb214fbe35d83ec14"
          }
        },
        "7d9c0d184a7c4c89809fe729b1a36c94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "98e2453ff0aa4934a306c01050e40074": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a46c652e0f654dbd99628d229bb3b334": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "265da60f5f6b468fb214fbe35d83ec14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karube044/100/blob/master/9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yjd7BWit4t42"
      },
      "source": [
        "# 80. ID番号への変換\n",
        "# 準備\n",
        "# 問50で作成した学習、検証、評価データを用いる\n",
        "import pandas as pd\n",
        "train = pd.read_csv('train.txt', header=0, sep='\\t')\n",
        "valid = pd.read_csv('valid.txt', header=0, sep='\\t')\n",
        "test = pd.read_csv('test.txt', header=0, sep='\\t')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZK3qzBwJTG_",
        "outputId": "46c411c4-f854-426a-9e53-52de71e15f3e"
      },
      "source": [
        "# 単語のID番号を付与する\n",
        "import collections\n",
        "import string\n",
        "\n",
        "# 本文から記号を消去し、単語ごとに分けすべてリストに格納する\n",
        "table = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
        "l = []\n",
        "for text in train['TITLE']:\n",
        "  words = text.translate(table).split()\n",
        "  for word in words:\n",
        "    l.append(word)\n",
        "\n",
        "# collections.Counterでリスト内の単語の出現頻度を辞書型として取得\n",
        "c = collections.Counter(l)\n",
        "# sorted()で辞書の要素を出現頻度の降順にリストとして取得\n",
        "f = sorted(c.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# リストの順番に順位(単語ID)をつけていく(2回以上出現した単語のみ)\n",
        "word_id={}\n",
        "for i, (w, cnt) in enumerate(f):\n",
        "  if cnt > 1:\n",
        "    word_id[w]= i+1 \n",
        "\n",
        "# 確認\n",
        "print(word_id)\n",
        "print(len(set(word_id.values())))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'to': 1, 's': 2, 'in': 3, 'UPDATE': 4, 'on': 5, 'as': 6, 'US': 7, 'for': 8, 'of': 9, 'The': 10, '1': 11, 'To': 12, '2': 13, 'the': 14, 'and': 15, 'In': 16, 'Of': 17, 'at': 18, 'a': 19, 'A': 20, 'With': 21, 'Is': 22, 'with': 23, 'after': 24, 'For': 25, 'And': 26, 'New': 27, '3': 28, 'China': 29, 'Kardashian': 30, 'up': 31, 'On': 32, 'by': 33, 'Kim': 34, 'After': 35, 'says': 36, 'At': 37, 'is': 38, 'ECB': 39, 'STOCKS': 40, 'Fed': 41, 't': 42, 'From': 43, 'from': 44, '4': 45, 'new': 46, 'shares': 47, 'her': 48, 'Wall': 49, 'Says': 50, 'FOREX': 51, 'It': 52, 'Miley': 53, 'Cyrus': 54, 'Dollar': 55, '5': 56, 'First': 57, 'Euro': 58, 'data': 59, 'CEO': 60, 'West': 61, 'St': 62, 'S': 63, 'over': 64, 'May': 65, 'Google': 66, 'Ukraine': 67, 'About': 68, 'Up': 69, 'Chris': 70, 'she': 71, 'Will': 72, 'You': 73, 'Be': 74, 'bln': 75, 'As': 76, 'More': 77, 'be': 78, 'Kanye': 79, 'I': 80, 'Apple': 81, 'Stocks': 82, 'off': 83, 'Over': 84, 'Justin': 85, 'GM': 86, 'Billion': 87, 'euro': 88, 'Bank': 89, 'Bieber': 90, 'GLOBAL': 91, 'Are': 92, 'Star': 93, 'Yellen': 94, '7': 95, '2014': 96, 'How': 97, 'out': 98, 'RPT': 99, 'it': 100, 'UK': 101, 'but': 102, 'that': 103, 'deal': 104, 'Twitter': 105, 'sales': 106, 'Day': 107, 'more': 108, 'Not': 109, 'MARKETS': 110, 'he': 111, 'year': 112, 'Time': 113, 'pct': 114, 'That': 115, 'rise': 116, 'near': 117, 'P': 118, 'American': 119, 'Her': 120, '6': 121, 'CORRECTED': 122, 'profit': 123, 'are': 124, 'Gold': 125, 'down': 126, 'Game': 127, 'York': 128, 'high': 129, 'IPO': 130, 'America': 131, 'Out': 132, 'No': 133, 'One': 134, 'What': 135, 'not': 136, 'month': 137, 'growth': 138, 'Sales': 139, 'Lohan': 140, 'set': 141, 'low': 142, 'Beyonce': 143, 'Facebook': 144, 'By': 145, 'This': 146, 'Lindsay': 147, 'Amazon': 148, 'T': 149, 'could': 150, 'fall': 151, 'Million': 152, 'first': 153, 'Jay': 154, 'High': 155, 'Most': 156, 'buy': 157, 'Michael': 158, 'Deal': 159, 'reveals': 160, 'Draghi': 161, 'will': 162, 'oil': 163, 'Home': 164, 'All': 165, 'Movie': 166, 'inflation': 167, 'Thrones': 168, 'day': 169, 'Your': 170, 'has': 171, 'Selena': 172, 'His': 173, 'Ebola': 174, 'about': 175, 'Iraq': 176, 'WRAPUP': 177, 'George': 178, 'Paul': 179, 'Video': 180, 'Was': 181, 'higher': 182, '10': 183, 'European': 184, 'Gomez': 185, 'may': 186, 'stocks': 187, 'Has': 188, 'his': 189, 'was': 190, 'record': 191, 'Z': 192, 'Year': 193, 'World': 194, 'Russia': 195, 'Alibaba': 196, 'TV': 197, 'Why': 198, 'Show': 199, 'falls': 200, 'We': 201, 'week': 202, 'Awards': 203, '8': 204, 'Fitch': 205, '9': 206, 'Amid': 207, 'Jennifer': 208, 'shows': 209, 'Report': 210, 'BNP': 211, 'ahead': 212, 'Man': 213, 'rate': 214, 'Low': 215, 'Rise': 216, 'than': 217, 'Have': 218, 'rises': 219, 'Shares': 220, 'Than': 221, 'gains': 222, 'L': 223, 'have': 224, 'Falls': 225, 'Outlook': 226, 'wedding': 227, 'Europe': 228, 'Said': 229, 'Men': 230, '500': 231, 'Big': 232, 'lower': 233, 'Jackson': 234, 'Japan': 235, 'June': 236, 'Ford': 237, 'Before': 238, 'Profit': 239, 'Drop': 240, 'Could': 241, 'Scott': 242, 'mln': 243, 'Get': 244, 'prices': 245, 'Month': 246, 'jobs': 247, 'Can': 248, 'Samsung': 249, 'Death': 250, 'hit': 251, 'Week': 252, 'James': 253, 'Met': 254, 'into': 255, 'Wars': 256, 'Futures': 257, 'zone': 258, 'Street': 259, 'Two': 260, 'sees': 261, 'Top': 262, 'Just': 263, 'German': 264, 'Wedding': 265, 'Hong': 266, 'Kong': 267, 'dollar': 268, 'against': 269, 'Pfizer': 270, 'Rate': 271, 'But': 272, 'Microsoft': 273, 'before': 274, 'PRECIOUS': 275, 'Pay': 276, 'Love': 277, 'Jagger': 278, 'Oil': 279, 'two': 280, 'Estimates': 281, 'flat': 282, 'Obama': 283, 'Growth': 284, 'Buy': 285, 'North': 286, 'Shows': 287, 'Since': 288, 'People': 289, 'Brown': 290, 'Music': 291, 'Mother': 292, 'Mick': 293, 'Years': 294, 'no': 295, 'Jessica': 296, 'hits': 297, 'Climate': 298, 'Its': 299, 'REFILE': 300, 'Change': 301, 'SNAPSHOT': 302, 'Into': 303, 'Martin': 304, 'Health': 305, 'can': 306, 'pay': 307, 'Williams': 308, 'bank': 309, 'Robert': 310, 'Data': 311, 'top': 312, 'Credit': 313, 'Emma': 314, 'revenue': 315, 'who': 316, 'Don': 317, 'Taylor': 318, 'Record': 319, 'She': 320, 'Set': 321, 'Dies': 322, 'bond': 323, 'India': 324, 'percent': 325, 'Mobile': 326, 'He': 327, 'Drops': 328, 'gets': 329, 'Jolie': 330, 'business': 331, 'Best': 332, 'star': 333, 'Film': 334, 'April': 335, 'Talks': 336, 'Off': 337, 'Jenner': 338, 'Who': 339, 'Second': 340, 'talks': 341, 'Angelina': 342, 'AstraZeneca': 343, 'Season': 344, 'show': 345, 'Study': 346, 'take': 347, 'Swift': 348, 'Market': 349, 'cuts': 350, 'back': 351, 'House': 352, 'billion': 353, 'Zac': 354, 'Efron': 355, 'Netflix': 356, 'gas': 357, 'Court': 358, 'Obamacare': 359, 'Back': 360, 'yields': 361, 'report': 362, 'bid': 363, 'Now': 364, 'French': 365, 'Fox': 366, 'David': 367, 'Argentina': 368, 'France': 369, 'market': 370, 'Gain': 371, 'Seen': 372, 'time': 373, 'Internet': 374, 'since': 375, 'million': 376, 'Rises': 377, 'years': 378, 'Against': 379, 'takes': 380, 'Affirms': 381, 'March': 382, 'Trailer': 383, 'E': 384, 'FDA': 385, 'court': 386, 'Comcast': 387, 'AP': 388, '—': 389, 'drug': 390, 'Review': 391, 'Morgan': 392, 'all': 393, 'home': 394, 'Alstom': 395, 'Clooney': 396, 'their': 397, 'Spider': 398, 'Gains': 399, 'banks': 400, 'Gwyneth': 401, 'Yen': 402, 'they': 403, 'Tesla': 404, 'Episode': 405, 'offer': 406, 'ends': 407, 'White': 408, 'claims': 409, 'Down': 410, 'Fans': 411, 'Some': 412, 'Khloe': 413, 'strong': 414, 'Young': 415, 'open': 416, 'case': 417, 'Walker': 418, 'BOJ': 419, 'economy': 420, 'Robin': 421, 'Still': 422, 'Simpson': 423, 'Johnny': 424, 'Economy': 425, 'Stone': 426, 'drops': 427, 'Three': 428, 'Chinese': 429, 'cut': 430, '50': 431, 'source': 432, 'News': 433, 'rates': 434, 'Make': 435, 'quarter': 436, 'Paltrow': 437, 'John': 438, 'EU': 439, 'South': 440, 'study': 441, 'Ryan': 442, 'Five': 443, 'Won': 444, 'an': 445, 'Stars': 446, 'AT': 447, 'Ex': 448, 'Brent': 449, 'U': 450, 'Brad': 451, 'Barclays': 452, 'Pregnant': 453, 'Target': 454, 'So': 455, 'Gets': 456, 'Bonds': 457, 'seen': 458, 'end': 459, 'policy': 460, 'Inflation': 461, 'comments': 462, 'its': 463, 'Wren': 464, 'debt': 465, 'Cancer': 466, 'Global': 467, 'Know': 468, 'MERS': 469, 'Asian': 470, 'Dead': 471, 'MTV': 472, 'you': 473, 'earnings': 474, 'Pharrell': 475, 'make': 476, 'one': 477, 'Banks': 478, 'Box': 479, 'trading': 480, '2015': 481, 'Festival': 482, '20': 483, 'firm': 484, 'makes': 485, 'slips': 486, 'An': 487, 'End': 488, 'GRAINS': 489, 'Forecast': 490, 'O': 491, 'Tour': 492, 'Harrison': 493, 'still': 494, 'Here': 495, 'Air': 496, 'just': 497, 'Yahoo': 498, 'Noah': 499, 'risk': 500, 'man': 501, 'Role': 502, 'Nick': 503, 'My': 504, 'Watch': 505, 'Shia': 506, 'Risk': 507, 'McDonald': 508, 'Prices': 509, 'Beats': 510, 'Captain': 511, 'rally': 512, 'Demand': 513, 'raises': 514, 'London': 515, 'cars': 516, 'Apparel': 517, 'dies': 518, 'Rates': 519, 'Like': 520, 'Valeant': 521, 'loss': 522, '100': 523, 'Instagram': 524, 'Plan': 525, 'Family': 526, 'Office': 527, 'Sees': 528, 'Real': 529, 'Cuts': 530, 'Kate': 531, 'Seth': 532, 'Pitt': 533, 'drop': 534, 'Life': 535, 'Should': 536, 'Harris': 537, 'maker': 538, 'Canada': 539, 'Good': 540, 'six': 541, 'Rolling': 542, 'weak': 543, 'Allergan': 544, 'View': 545, 'again': 546, 'Thicke': 547, 'Fall': 548, 'Baby': 549, 'Fight': 550, 'Cannes': 551, 'Asia': 552, 'GE': 553, 'Africa': 554, 'opens': 555, 'Things': 556, 'Cast': 557, 'sell': 558, 'Mila': 559, 'Kunis': 560, 'plan': 561, 'Case': 562, 'Kids': 563, 'vs': 564, 'debut': 565, 'merger': 566, 'concerns': 567, 'Again': 568, 'heart': 569, 'Lady': 570, 'Andrew': 571, 'Play': 572, 'Jr': 573, 'eyes': 574, 'Future': 575, 'hike': 576, 'Stable': 577, 'steady': 578, 'IMF': 579, 'under': 580, 'probe': 581, 'second': 582, 'Photo': 583, 'During': 584, 'Go': 585, 'Loss': 586, 'video': 587, 'Disney': 588, 'Sex': 589, 'holds': 590, 'Amazing': 591, 'Even': 592, 'party': 593, 'FCC': 594, 'Calls': 595, 'Live': 596, 'Takes': 597, 'UN': 598, 'Australia': 599, 'Warner': 600, 'Depp': 601, 'Lena': 602, 'Dunham': 603, 'bonds': 604, 'Bell': 605, 'Mars': 606, 'Neil': 607, 'boost': 608, 'during': 609, 'office': 610, 'world': 611, 'Do': 612, 'box': 613, 'lows': 614, 'Smith': 615, 'Bad': 616, 'being': 617, 'Did': 618, 'When': 619, 'edge': 620, 'Gala': 621, 'Reveals': 622, 'Lea': 623, 'plans': 624, 'or': 625, 'Voice': 626, 'Actor': 627, 'Garfield': 628, 'Makes': 629, 'Arrested': 630, 'Hollywood': 631, 'Rally': 632, 'wants': 633, 'Plans': 634, 'supply': 635, 'Red': 636, 'Months': 637, 'Virus': 638, 'jumps': 639, 'NY': 640, 'Franco': 641, 'recall': 642, 'Near': 643, 'Boeing': 644, 'sex': 645, 'face': 646, 'See': 647, 'Women': 648, 'help': 649, 'if': 650, 'Stones': 651, 'Singer': 652, 'Michele': 653, 'next': 654, '30': 655, 'global': 656, 'Decline': 657, 'Last': 658, 'Bill': 659, 'life': 660, 'Miranda': 661, 'this': 662, 'tour': 663, 'VIDEO': 664, 'Ahead': 665, 'Heart': 666, 'dress': 667, 'Carney': 668, 'wins': 669, 'outlook': 670, 'results': 671, 'Really': 672, 'Mad': 673, 'WSJ': 674, 'steps': 675, 're': 676, 'Stanley': 677, 'baby': 678, 'forecast': 679, 'Us': 680, 'Director': 681, 'Food': 682, 'Gas': 683, '14': 684, 'cancer': 685, 'm': 686, 'Tax': 687, 'Album': 688, 'Shire': 689, 'Face': 690, 'Paribas': 691, 'Solange': 692, 'Too': 693, 'Tech': 694, 'Former': 695, 'California': 696, 'LaBeouf': 697, 'Jobs': 698, 'Debt': 699, 'gain': 700, 'despite': 701, 'Lana': 702, 'Del': 703, 'Rey': 704, 'sources': 705, '13': 706, 'three': 707, 'Rihanna': 708, 'Nasdaq': 709, 'com': 710, 'Gaga': 711, 'Take': 712, 'Rogen': 713, 'Or': 714, 'Jump': 715, 'Cut': 716, 'Dow': 717, 'Black': 718, 'Money': 719, 'List': 720, 'people': 721, 'Party': 722, '12': 723, 'Woman': 724, 'Broadway': 725, 'Gay': 726, 'Test': 727, 'death': 728, 'Capital': 729, 'Times': 730, 'Rules': 731, 'Stock': 732, 'fears': 733, 'below': 734, 'Cars': 735, 'Short': 736, 'price': 737, 'Paris': 738, 'unit': 739, 'Wants': 740, 'Say': 741, 'yen': 742, 'King': 743, 'Being': 744, 'McCarthy': 745, 'Jimmy': 746, 'Goldman': 747, 'Russell': 748, 'Bid': 749, 'beats': 750, 'Biggest': 751, 'Seeks': 752, 'Way': 753, 'car': 754, 'GDP': 755, 'Recall': 756, 'your': 757, 'Chrysler': 758, 'Earth': 759, 'company': 760, 'like': 761, 'get': 762, 'Bryan': 763, 'Increase': 764, 'Vietnam': 765, 'Finds': 766, 'away': 767, 'Opens': 768, 'leaves': 769, 'Bachelorette': 770, 'Rob': 771, 'They': 772, 'Bond': 773, 'big': 774, 'close': 775, 'demand': 776, 'meeting': 777, 'test': 778, 'nearly': 779, 'look': 780, 'family': 781, 'President': 782, 'estimates': 783, 'investors': 784, 'Business': 785, 'Ice': 786, 'Wife': 787, 'Probe': 788, 'key': 789, 'stake': 790, 'Claims': 791, 'VII': 792, 'J': 793, 'rules': 794, 'British': 795, 'fight': 796, 'Demi': 797, 'Lovato': 798, 'expected': 799, 'sister': 800, 'Maker': 801, 'amid': 802, 'Michelle': 803, 'Dancing': 804, 'Suisse': 805, 'Net': 806, 'BofA': 807, 'while': 808, 'Space': 809, 'JPMorgan': 810, 'Investors': 811, 'tops': 812, 'settle': 813, 'Half': 814, 'Posts': 815, 'NEW': 816, 'Toyota': 817, 'virus': 818, '11': 819, 'Russian': 820, 'July': 821, 'Katie': 822, 'red': 823, 'Pound': 824, 'chief': 825, 'Power': 826, 'Lewis': 827, 'Car': 828, 'little': 829, 'now': 830, 'Children': 831, 'found': 832, 'Other': 833, 'possible': 834, 'goes': 835, 'crisis': 836, 'Fiat': 837, 'DirecTV': 838, 'Kristen': 839, 'Help': 840, 'Johnson': 841, 'Downey': 842, 'Glass': 843, 'Ban': 844, 'Americans': 845, 'Free': 846, 'Girls': 847, 'warns': 848, 'mortgage': 849, 'Another': 850, 'Little': 851, 'FX': 852, 'reports': 853, 'Cable': 854, 'Deutsche': 855, 'start': 856, 'economic': 857, 'YORK': 858, 'HBO': 859, 'Critics': 860, 'Jenny': 861, 'black': 862, 'best': 863, 'live': 864, 'Look': 865, 'crude': 866, 'names': 867, '18': 868, 'De': 869, 'fans': 870, 'Challenge': 871, 'Full': 872, 'Earnings': 873, 'app': 874, 'Action': 875, 'birthday': 876, 'Need': 877, 'Hemsworth': 878, 'Tribute': 879, 'General': 880, 'Tops': 881, 'Kendall': 882, 'Story': 883, 'long': 884, 'Index': 885, 'Tv': 886, 'plane': 887, 'film': 888, 'Close': 889, '15': 890, 'edges': 891, 'posts': 892, 'AbbVie': 893, 'Push': 894, 'action': 895, 'Drug': 896, 'free': 897, 'Coachella': 898, 'Neutrality': 899, 'Christina': 900, 'Merger': 901, 'PMI': 902, 'trade': 903, 'sells': 904, 'Finally': 905, 'health': 906, 'too': 907, 'Markets': 908, 'support': 909, 'ex': 910, 'Child': 911, 'WHO': 912, 'Climbs': 913, 'early': 914, 'Energy': 915, 'approves': 916, 'Policy': 917, 'Photos': 918, 'Airlines': 919, 'raise': 920, 'State': 921, 'Corn': 922, 'finds': 923, 'Spanish': 924, 'easing': 925, 'lawsuit': 926, 'Their': 927, 'Better': 928, 'Bets': 929, 'Marvel': 930, 'Offer': 931, 'These': 932, 'highs': 933, 'Behind': 934, 'Morning': 935, 'dead': 936, 'Mark': 937, 'so': 938, 'Senate': 939, 'mother': 940, 'Lopez': 941, 'Frozen': 942, 'Megan': 943, 'board': 944, 'wife': 945, 'Our': 946, 'Goes': 947, 'dips': 948, 'Birthday': 949, 'judge': 950, 'losses': 951, 'Premiere': 952, 'say': 953, 'C': 954, 'fund': 955, 'Call': 956, 'dip': 957, 'files': 958, 'CANADA': 959, 'firms': 960, 'Treasuries': 961, 'Raises': 962, 'half': 963, 'some': 964, 'Outbreak': 965, 'ignition': 966, '24': 967, 'won': 968, 'Yields': 969, 'Sir': 970, 'Next': 971, 'Late': 972, 'had': 973, 'focus': 974, 'Rolf': 975, 'Making': 976, 'Candy': 977, 'Recap': 978, 'Cover': 979, 'guilty': 980, 'Jon': 981, 'Leads': 982, 'Higher': 983, 'auto': 984, 'Been': 985, 'Anti': 986, 'share': 987, 'Kourtney': 988, 'Industry': 989, 'Book': 990, 'gold': 991, 'Sequel': 992, 'Sell': 993, 'Days': 994, 'Galaxy': 995, 'Harry': 996, 'Hospital': 997, 'Manufacturing': 998, 'Phone': 999, 'tech': 1000, 'Libya': 1001, 'Korea': 1002, 'Siemens': 1003, 'slightly': 1004, 'o': 1005, 'Dress': 1006, 'last': 1007, 'days': 1008, 'Think': 1009, 'Malaysia': 1010, 'Happy': 1011, 'Company': 1012, 'return': 1013, 'True': 1014, 'lifts': 1015, 'jump': 1016, 'consumer': 1017, 'Co': 1018, 'Los': 1019, 'Angeles': 1020, 'Nikkei': 1021, 'official': 1022, 'girl': 1023, 'daughter': 1024, 'Economic': 1025, 'X': 1026, 'takeover': 1027, 'post': 1028, 'Want': 1029, 'see': 1030, 'Head': 1031, 'IBM': 1032, 'Idol': 1033, 'Kris': 1034, 'Charges': 1035, 'CDC': 1036, '25': 1037, 'sanctions': 1038, 'll': 1039, 'Own': 1040, 'Trial': 1041, 'use': 1042, 'Biopic': 1043, 'love': 1044, 'Reportedly': 1045, 'Wanted': 1046, 'Swiss': 1047, 'Crush': 1048, 'Winter': 1049, 'Financial': 1050, 'biggest': 1051, 'Does': 1052, 'Ellen': 1053, 'Canadian': 1054, 'capital': 1055, 'Summer': 1056, 'Trading': 1057, 'Ever': 1058, 'Heartbleed': 1059, 'Had': 1060, 'another': 1061, 'Getting': 1062, 'Prince': 1063, '22': 1064, 'Factors': 1065, 'Keith': 1066, 'above': 1067, 'Steps': 1068, 'Friday': 1069, 'M': 1070, 'Treasury': 1071, 'confirms': 1072, 'African': 1073, 'Ben': 1074, 'Made': 1075, 'Meet': 1076, 'Creator': 1077, 'Chelsea': 1078, 'Four': 1079, 'Release': 1080, 'BOE': 1081, 'Use': 1082, 'call': 1083, 'hopes': 1084, 'Stage': 1085, 'recalls': 1086, 'Q1': 1087, 'Nyong': 1088, 'joins': 1089, 'Step': 1090, 'Were': 1091, 'Return': 1092, 'Long': 1093, 'exports': 1094, 'Son': 1095, 'subdued': 1096, 'Lambert': 1097, 'adds': 1098, 'Transformers': 1099, 'head': 1100, 'denies': 1101, 'Games': 1102, 'Got': 1103, 'Scientists': 1104, 'Lawsuit': 1105, 'Ackman': 1106, 'BET': 1107, 'Puerto': 1108, 'Rico': 1109, 'Hall': 1110, 'Price': 1111, 'Under': 1112, 'Stimulus': 1113, 'TREASURIES': 1114, 'Putin': 1115, 'Neighbors': 1116, 'expectations': 1117, 'reveal': 1118, 'Dating': 1119, 'Musk': 1120, 'leads': 1121, 'Spears': 1122, 'Gosling': 1123, 'Joe': 1124, 'Germany': 1125, 'four': 1126, 'less': 1127, 'looks': 1128, 'talk': 1129, 'gives': 1130, 'Looks': 1131, 'Guinea': 1132, 'Lead': 1133, 'sterling': 1134, 'forecasts': 1135, 'Tori': 1136, 'Six': 1137, 'yr': 1138, 'Joan': 1139, 'service': 1140, 'Batman': 1141, 'iPad': 1142, 'Job': 1143, 'arrested': 1144, 'If': 1145, 'quarterly': 1146, 'split': 1147, 'Malaysian': 1148, 'Stop': 1149, 'Between': 1150, 'Medtronic': 1151, 'sale': 1152, 'Vogue': 1153, 'minister': 1154, 'Once': 1155, 'Uber': 1156, 'orders': 1157, 'lead': 1158, 'LA': 1159, 'users': 1160, 'Patrick': 1161, 'Jack': 1162, 'Work': 1163, 'marriage': 1164, 'Crude': 1165, 'Foods': 1166, 'Q2': 1167, 'Right': 1168, 'Law': 1169, 'lift': 1170, 'Lupita': 1171, '2013': 1172, 'Indian': 1173, 'Shailene': 1174, 'Woodley': 1175, 'Lawrence': 1176, 'buys': 1177, 'Misses': 1178, 'yet': 1179, 'Abuse': 1180, 'Finale': 1181, 'Latest': 1182, 'Daniel': 1183, 'spending': 1184, 'Boosts': 1185, 'safety': 1186, 'housing': 1187, 'Richard': 1188, 'model': 1189, 'Leaves': 1190, 'Fire': 1191, 'Oprah': 1192, 'system': 1193, 'Old': 1194, 'Hit': 1195, 'Ignition': 1196, 'working': 1197, 'Less': 1198, 'Following': 1199, 'Tweet': 1200, 'Wins': 1201, 'Montana': 1202, 'worries': 1203, 'Negative': 1204, 'Cameron': 1205, 'Gary': 1206, 'recovery': 1207, 'Found': 1208, 'Workers': 1209, 'Cobain': 1210, 'Allen': 1211, 'Versus': 1212, 'would': 1213, 'Debut': 1214, 'Blue': 1215, 'made': 1216, 'Guilty': 1217, 'Fund': 1218, 'old': 1219, 'Detroit': 1220, 'much': 1221, 'tests': 1222, 'Florida': 1223, 'Slams': 1224, 'Never': 1225, 'latest': 1226, 'work': 1227, 'manufacturing': 1228, 'Released': 1229, 'Isn': 1230, 'Steve': 1231, 'Users': 1232, 'Speed': 1233, 'Easter': 1234, 'Crowe': 1235, '35': 1236, 'BlackBerry': 1237, 'ever': 1238, 'Revenue': 1239, '16': 1240, 'phone': 1241, 'Urban': 1242, 'been': 1243, 'search': 1244, 'go': 1245, 'night': 1246, 'Mom': 1247, 'battle': 1248, 'Police': 1249, 'Married': 1250, 'Maleficent': 1251, 'Mariah': 1252, 'Cannon': 1253, 'Tom': 1254, 'news': 1255, 'were': 1256, 'Rooney': 1257, 'missing': 1258, 'Stewart': 1259, 'Frankie': 1260, 'Rick': 1261, 'While': 1262, 'Defends': 1263, 'Advance': 1264, 'Move': 1265, 'Night': 1266, 'Tony': 1267, 'figure': 1268, 'Bachelor': 1269, 'Final': 1270, 'public': 1271, 'Washington': 1272, 'Rock': 1273, 'premiere': 1274, 'Share': 1275, 'bankruptcy': 1276, 'Trade': 1277, 'Support': 1278, 'Lowest': 1279, 'due': 1280, 'Open': 1281, 'NASA': 1282, 'arrives': 1283, 'hold': 1284, 'Peter': 1285, 'Cases': 1286, 'Reaches': 1287, 'Citigroup': 1288, 'term': 1289, 'ECONOMY': 1290, 'Age': 1291, 'Suit': 1292, 'good': 1293, 'moment': 1294, 'air': 1295, 'Britney': 1296, 'dating': 1297, 'stimulus': 1298, 'Whole': 1299, 'Assault': 1300, 'Niro': 1301, 'late': 1302, 'Aereo': 1303, 'third': 1304, 'Bob': 1305, 'Quarter': 1306, 'Beyoncé': 1307, 'Spelling': 1308, 'Dean': 1309, 'Area': 1310, 'Sony': 1311, 'tax': 1312, '45': 1313, 'Joins': 1314, 'Split': 1315, 'Japanese': 1316, 'Moon': 1317, 'Jason': 1318, 'War': 1319, 'him': 1320, 'Drew': 1321, 'Barrymore': 1322, 'Service': 1323, 'tensions': 1324, 'Mexico': 1325, 'Emerging': 1326, 'sector': 1327, 've': 1328, 'Snapchat': 1329, 'NYC': 1330, 'Crisis': 1331, 'Oscar': 1332, 'Third': 1333, 'Cancels': 1334, 'most': 1335, 'Olivia': 1336, 'Weeks': 1337, 'father': 1338, 'co': 1339, 'through': 1340, 'Stephen': 1341, 'aged': 1342, 'energy': 1343, 'Orders': 1344, 'Carey': 1345, 'Perry': 1346, 'vehicles': 1347, 'Sorry': 1348, 'network': 1349, 'Host': 1350, 'factory': 1351, 'Speculation': 1352, 'Louis': 1353, 'Scandal': 1354, 'small': 1355, 'Mortgage': 1356, 'Products': 1357, 'per': 1358, 'role': 1359, 'calls': 1360, 'bad': 1361, 'secret': 1362, 'Much': 1363, 'likely': 1364, 'City': 1365, 'Optimism': 1366, 'BBB': 1367, 'Records': 1368, 'retail': 1369, 'Father': 1370, 'signs': 1371, 'Percent': 1372, 'driving': 1373, 'Actually': 1374, 'Recovery': 1375, 'step': 1376, 'Peaches': 1377, 'Cost': 1378, 'Sprint': 1379, 'Fix': 1380, 'Lost': 1381, 'tight': 1382, 'Queen': 1383, 'Central': 1384, 'Watson': 1385, 'Despite': 1386, 'slip': 1387, 'Dee': 1388, 'white': 1389, 'should': 1390, 'Due': 1391, 'Issues': 1392, 'Water': 1393, 'Search': 1394, 'Charlie': 1395, 'investment': 1396, 'very': 1397, 'Him': 1398, 'Worst': 1399, 'Scarlett': 1400, 'History': 1401, 'Direct': 1402, 'Adam': 1403, 'Alzheimer': 1404, 'Post': 1405, 'fuel': 1406, 'Would': 1407, 'cash': 1408, 'light': 1409, 'Everything': 1410, 'Fast': 1411, 'England': 1412, 'launch': 1413, 'Gives': 1414, 'keeps': 1415, 'win': 1416, 'Hill': 1417, 'Sanctions': 1418, 'Reports': 1419, '2nd': 1420, 'Almost': 1421, 'Buys': 1422, 'Guardians': 1423, 'wren': 1424, 'Dark': 1425, 'Girl': 1426, 'Josh': 1427, 'Julia': 1428, 'Sale': 1429, 'Nasa': 1430, 'Song': 1431, 'Duke': 1432, 'Chairman': 1433, 'Great': 1434, 'Production': 1435, 'costs': 1436, 'book': 1437, 'Argentine': 1438, 'Melissa': 1439, 'Stay': 1440, 'SAC': 1441, 'outbreak': 1442, 'Tyson': 1443, 'Deals': 1444, 'crash': 1445, 'Elsa': 1446, 'fine': 1447, 'Charney': 1448, 'view': 1449, 'QE': 1450, 'tumble': 1451, 'Tonight': 1452, 'launches': 1453, 'Affleck': 1454, 'Potter': 1455, 'short': 1456, 'what': 1457, 'my': 1458, 'States': 1459, 'Turns': 1460, 'Where': 1461, 'EBay': 1462, 'Called': 1463, 'Ready': 1464, 'Pattinson': 1465, 'Nissan': 1466, 'Text': 1467, 'Blood': 1468, 'Eric': 1469, 'stay': 1470, 'Controversial': 1471, 'Radcliffe': 1472, 'movie': 1473, 'keep': 1474, 'Aussie': 1475, 'Wage': 1476, 'Adds': 1477, 'going': 1478, 'Supreme': 1479, 'cost': 1480, 'Today': 1481, 'Colbert': 1482, 'director': 1483, 'agency': 1484, 'point': 1485, 'Stake': 1486, 'without': 1487, 'Gazprom': 1488, 'Federal': 1489, 'ready': 1490, 'further': 1491, 'got': 1492, 'Around': 1493, 'Geldof': 1494, 'Weekend': 1495, 'Australian': 1496, 'trailer': 1497, 'AA': 1498, 'Zendaya': 1499, 'Declines': 1500, 'Columbus': 1501, 'FTSE': 1502, 'Android': 1503, 'host': 1504, 'McCartney': 1505, 'Nicki': 1506, 'Minaj': 1507, 'There': 1508, 'drugs': 1509, 'reality': 1510, 'push': 1511, 'selling': 1512, 'cover': 1513, 'gown': 1514, 'Floyd': 1515, 'Transcendence': 1516, 'urges': 1517, 'Johansson': 1518, 'Ashton': 1519, 'Missing': 1520, 'rebound': 1521, 'Buffett': 1522, 'Jackman': 1523, 'Raise': 1524, 'Lower': 1525, 'treatment': 1526, 'Recalls': 1527, 'Costs': 1528, 'Colin': 1529, 'Government': 1530, 'streaming': 1531, 'jet': 1532, 'weighs': 1533, 'FTC': 1534, 'Interest': 1535, 'Highest': 1536, 'because': 1537, 'Avicii': 1538, 'Planet': 1539, 'Hits': 1540, 'Evans': 1541, 'trial': 1542, 'misses': 1543, 'Security': 1544, 'Rivers': 1545, 'Cloud': 1546, 'strike': 1547, 'mobile': 1548, 'Far': 1549, 'Taco': 1550, 'music': 1551, 'Weight': 1552, 'PRESS': 1553, 'even': 1554, 'announces': 1555, 'Italian': 1556, 'Bear': 1557, 'well': 1558, 'Eva': 1559, 'Britain': 1560, '17': 1561, 'Signs': 1562, 'JD': 1563, 'Gibson': 1564, 'Wheat': 1565, 'labor': 1566, 'Bring': 1567, 'proposed': 1568, 'Husband': 1569, 'moves': 1570, 'Billboard': 1571, 'only': 1572, 'boy': 1573, 'singer': 1574, 'Sick': 1575, 'Attack': 1576, 'smart': 1577, 'Means': 1578, 'yuan': 1579, 'beat': 1580, 'review': 1581, 'Diaz': 1582, 'Superman': 1583, 'SEC': 1584, 'deadly': 1585, 'Oscars': 1586, 'Mickey': 1587, 'Huge': 1588, 'Announce': 1589, 'Slump': 1590, 'way': 1591, 'Rosie': 1592, 'bets': 1593, 'Chart': 1594, 'e': 1595, 'Fail': 1596, 'stock': 1597, 'Line': 1598, 'Longer': 1599, 'Loan': 1600, 'Freddie': 1601, 'traders': 1602, 'Keep': 1603, 'Auto': 1604, 'unemployment': 1605, 'Rare': 1606, '27': 1607, 'Past': 1608, 'Plane': 1609, 'dark': 1610, '19': 1611, 'shareholders': 1612, 'Fame': 1613, 'Releases': 1614, 'Single': 1615, 'tells': 1616, 'Denies': 1617, 'Reality': 1618, 'Sexual': 1619, 'Linked': 1620, 'Garth': 1621, 'Pays': 1622, 'Streaming': 1623, 'Public': 1624, 'Italy': 1625, 'Kurt': 1626, 'Daughter': 1627, 'puts': 1628, 'East': 1629, 'changed': 1630, 'Join': 1631, 'surge': 1632, 'actor': 1633, 'sign': 1634, 'blood': 1635, 'pressure': 1636, 'Aronofsky': 1637, 'Middleton': 1638, 'Selfie': 1639, 'pays': 1640, 'Lifetime': 1641, 'Jamie': 1642, 'Marries': 1643, 'Levine': 1644, 'Terry': 1645, 'Find': 1646, 'Kutcher': 1647, 'Announces': 1648, 'Minutes': 1649, 'Hugh': 1650, 'Kylie': 1651, 'Selling': 1652, 'CFO': 1653, 'School': 1654, 'game': 1655, 'Anna': 1656, 'NOT': 1657, 'war': 1658, 'Birth': 1659, 'Breaks': 1660, 'Hotel': 1661, 'Bulgaria': 1662, 'Confidence': 1663, 'Weekly': 1664, 'Spending': 1665, 'Thursday': 1666, 'Series': 1667, 'investigation': 1668, 'Opening': 1669, 'list': 1670, 'net': 1671, 'Knowles': 1672, 'electric': 1673, 'minutes': 1674, 'government': 1675, 'Piketty': 1676, 'unveils': 1677, 'Signals': 1678, 'hours': 1679, 'Saudi': 1680, 'Cash': 1681, 'revealed': 1682, 'Movies': 1683, 'Pushes': 1684, 'Roberts': 1685, 'Run': 1686, 'Spain': 1687, 'Matthew': 1688, 'Boost': 1689, 'DIGEST': 1690, 'Alleged': 1691, 'Jet': 1692, 'Firm': 1693, 'Thing': 1694, 'Problem': 1695, 'chain': 1696, 'switch': 1697, 'BMW': 1698, 'Stores': 1699, 'Concert': 1700, 'months': 1701, 'La': 1702, 'Sofia': 1703, 'Marijuana': 1704, 'Climb': 1705, 'Arquette': 1706, 'children': 1707, 'Congress': 1708, 'Amy': 1709, 'Sun': 1710, 'Driving': 1711, 'meet': 1712, 'Mrs': 1713, 'when': 1714, 'change': 1715, 'Monty': 1716, 'Wayne': 1717, 'Talk': 1718, 'Message': 1719, 'Pictures': 1720, 'didn': 1721, 'Miss': 1722, 'Intel': 1723, 'anti': 1724, 'Takeover': 1725, 'five': 1726, 'online': 1727, 'Stress': 1728, 'put': 1729, 'Faces': 1730, 'warming': 1731, 'Going': 1732, 'Wal': 1733, 'Mart': 1734, 'decline': 1735, 'cigarettes': 1736, 'Museum': 1737, 'Secret': 1738, 'Lee': 1739, 'Texas': 1740, 'Surprise': 1741, 'Weds': 1742, 'herself': 1743, 'Friends': 1744, 'Settlement': 1745, 'Trying': 1746, 'Start': 1747, 'Legal': 1748, 'media': 1749, '90': 1750, 'Abramson': 1751, 'Gilead': 1752, 'order': 1753, 'Kerry': 1754, 'Judge': 1755, 'Leaving': 1756, 'Roll': 1757, 'BoE': 1758, 'smartphone': 1759, 'Media': 1760, 'assets': 1761, 'Madonna': 1762, 'Citi': 1763, 'Orange': 1764, 'Morrissey': 1765, 'cancels': 1766, 'join': 1767, 'Marc': 1768, 'Double': 1769, 'hospital': 1770, 'National': 1771, 'Khloé': 1772, 'Funeral': 1773, 'wears': 1774, 'deals': 1775, 'buying': 1776, 'fan': 1777, 'Xbox': 1778, 'money': 1779, 'Elizabeth': 1780, 'Buying': 1781, 'HTC': 1782, 'Smartphone': 1783, 'agrees': 1784, 'charge': 1785, 'Orlando': 1786, 'Bloom': 1787, 'pregnant': 1788, 'WTI': 1789, 'Sign': 1790, 'Daily': 1791, 'Ruby': 1792, 'Save': 1793, 'Woody': 1794, 'property': 1795, 'Herbalife': 1796, 'Godzilla': 1797, 'Patients': 1798, 'profits': 1799, 'loan': 1800, 'Risks': 1801, 'Burger': 1802, 'Charged': 1803, 'Ratings': 1804, 'Monday': 1805, 'Leonardo': 1806, 'DiCaprio': 1807, 'season': 1808, 'Divergent': 1809, 'Sherri': 1810, 'Shepherd': 1811, 'manager': 1812, 'Model': 1813, 'Fails': 1814, 'Consumer': 1815, 'Currency': 1816, 'Web': 1817, 'Companies': 1818, 'play': 1819, 'Stacy': 1820, 'Novartis': 1821, 'soon': 1822, 'Begins': 1823, 'films': 1824, 'threat': 1825, 'Ohio': 1826, 'Direction': 1827, 'Deadly': 1828, 'Number': 1829, 'Needs': 1830, 'Offers': 1831, 'Sea': 1832, 'Bucket': 1833, 'Middle': 1834, 'weigh': 1835, 'Teva': 1836, 'Illinois': 1837, 'Teen': 1838, 'admits': 1839, 'ring': 1840, 'BP': 1841, 'Doesn': 1842, 'picture': 1843, 'Celebrates': 1844, 'patent': 1845, 'equities': 1846, 'Nicole': 1847, 'Kidman': 1848, 'target': 1849, 'Dr': 1850, 'private': 1851, 'rising': 1852, 'Together': 1853, 'Yet': 1854, 'run': 1855, 'pulls': 1856, 'OF': 1857, 'Turkey': 1858, 'Researchers': 1859, 'Massive': 1860, 'Blasts': 1861, 'settlement': 1862, 'Delayed': 1863, 'GoPro': 1864, 'Rapper': 1865, 'son': 1866, 'Lily': 1867, 'Gap': 1868, 'kids': 1869, '1st': 1870, 'slump': 1871, 'Carpet': 1872, 'Kerr': 1873, 'fraud': 1874, 'Cory': 1875, 'Fair': 1876, 'city': 1877, 'Officials': 1878, 'Pope': 1879, 'Francis': 1880, 'Honda': 1881, 'Cube': 1882, 'Rating': 1883, 'Give': 1884, 'Acquire': 1885, 'exit': 1886, 'Patent': 1887, 'Fargo': 1888, 'girlfriend': 1889, 'carpet': 1890, 'Oldman': 1891, 'Crash': 1892, 'Led': 1893, 'Tracy': 1894, 'Murdoch': 1895, 'ruling': 1896, 'Azalea': 1897, 'CBS': 1898, 'Reason': 1899, 'Jones': 1900, 'Python': 1901, 'Handler': 1902, 'Award': 1903, 'coming': 1904, 'Housing': 1905, 'Jada': 1906, 'Musical': 1907, 'Conscious': 1908, 'Uncoupling': 1909, 'Lorde': 1910, 'wheat': 1911, 'eases': 1912, 'Leaked': 1913, 'Urges': 1914, 'Yuan': 1915, 'Sunday': 1916, 'Cigarette': 1917, 'Knuckles': 1918, '36': 1919, 'Plus': 1920, 'Chicago': 1921, 'NFL': 1922, 'Spread': 1923, 'Aguilera': 1924, 'defends': 1925, 'Check': 1926, 'Fannie': 1927, 'Fallon': 1928, 'extend': 1929, 'Pablo': 1930, 'Surge': 1931, 'Mean': 1932, 'hepatitis': 1933, 'Threat': 1934, 'Revealed': 1935, 'SpaceX': 1936, 'Results': 1937, 'Medicare': 1938, 'NBC': 1939, 'Matt': 1940, 'pregnancy': 1941, 'Order': 1942, 'Prime': 1943, 'Only': 1944, 'Verizon': 1945, 'looms': 1946, 'VW': 1947, '2012': 1948, 'interest': 1949, 'Speech': 1950, 'Sued': 1951, 'Technology': 1952, 'cap': 1953, 'ease': 1954, 'Among': 1955, 'giant': 1956, 'worth': 1957, '2009': 1958, 'Revises': 1959, 'Switch': 1960, 'Meeting': 1961, 'left': 1962, 'sets': 1963, 'Yield': 1964, 'February': 1965, 'taking': 1966, 'band': 1967, 'space': 1968, 'credit': 1969, 'regulator': 1970, 'major': 1971, 'Avril': 1972, 'Lavigne': 1973, 'Sheen': 1974, 'Name': 1975, 'Ousted': 1976, 'charges': 1977, 'ban': 1978, 'App': 1979, 'Aaliyah': 1980, 'Becomes': 1981, 'deadline': 1982, 'track': 1983, 'Asset': 1984, 'Mara': 1985, 'Billionaire': 1986, 'need': 1987, 'boyfriend': 1988, 'Rising': 1989, 'Keibler': 1990, 'Tribeca': 1991, 'Plant': 1992, 'former': 1993, 'executive': 1994, 'general': 1995, 'criminal': 1996, 'cases': 1997, 'ABC': 1998, 'HP': 1999, 'HIV': 2000, 'Same': 2001, 'Wintour': 2002, 'awaited': 2003, 'Pharma': 2004, 'Paula': 2005, 'parents': 2006, 'Iggy': 2007, 'Giant': 2008, 'Veronica': 2009, 'Boy': 2010, 'Thomas': 2011, 'Irish': 2012, 'Jonah': 2013, 'turns': 2014, 'Focus': 2015, 'spread': 2016, 'Actress': 2017, 'Level': 2018, 'Advances': 2019, 'Pratt': 2020, 'Simon': 2021, '23': 2022, 'Returns': 2023, 'style': 2024, 'release': 2025, 'PlayStation': 2026, 'Nothing': 2027, 'date': 2028, 'quit': 2029, 'behind': 2030, 'Investigation': 2031, 'Tatum': 2032, 'series': 2033, 'Fisher': 2034, 'drag': 2035, 'Sutherland': 2036, 'security': 2037, 'supplies': 2038, 'husband': 2039, 'rejects': 2040, 'Kevin': 2041, 'suit': 2042, 'Winslet': 2043, 'Couric': 2044, 'Heard': 2045, 'THE': 2046, 'watch': 2047, 'Warns': 2048, 'Beat': 2049, 'Panel': 2050, 'Liam': 2051, 'dispute': 2052, 'G': 2053, 'Cooper': 2054, 'Jumps': 2055, 'Dispute': 2056, 'house': 2057, 'child': 2058, 'Suicide': 2059, 'TSX': 2060, 'Moms': 2061, 'Soybeans': 2062, 'aims': 2063, 'Wireless': 2064, 'Soldier': 2065, 'power': 2066, 'Arabia': 2067, 'Eli': 2068, 'Monteith': 2069, 'photo': 2070, 'rumours': 2071, 'better': 2072, 'Starbucks': 2073, 'Safety': 2074, 'Files': 2075, 'Total': 2076, 'stage': 2077, 'Sierra': 2078, 'Leone': 2079, 'offers': 2080, 'flight': 2081, 'Makeup': 2082, 'Diane': 2083, 'soars': 2084, 'eyed': 2085, 'Tammy': 2086, 'Cruise': 2087, 'officials': 2088, 'Loses': 2089, 'Marriage': 2090, 'Andi': 2091, 'Words': 2092, 'Brooks': 2093, 'faces': 2094, 'Author': 2095, 'stars': 2096, 'Joining': 2097, 'Icahn': 2098, 'Hilary': 2099, 'Lot': 2100, 'Mike': 2101, 'Eminem': 2102, 'friends': 2103, 'Animal': 2104, 'Rowling': 2105, 'Seven': 2106, 'Holds': 2107, 'OECD': 2108, 'Pinkett': 2109, 'called': 2110, 'Favreau': 2111, 'Controversy': 2112, 'Katy': 2113, 'records': 2114, 'Motors': 2115, 'Jan': 2116, 'Reunite': 2117, 'corn': 2118, 'Very': 2119, 'really': 2120, 'retailer': 2121, 'author': 2122, 'Privacy': 2123, 'Early': 2124, 'invest': 2125, 'selfie': 2126, 'reunion': 2127, 'scientists': 2128, 'Confirms': 2129, 'photos': 2130, 'killed': 2131, 'January': 2132, 'Seconds': 2133, 'body': 2134, 'eight': 2135, 'Outside': 2136, 'Club': 2137, 'panel': 2138, 'Rivals': 2139, 'Hard': 2140, 'Win': 2141, 'Juan': 2142, 'loves': 2143, 'Giving': 2144, 'group': 2145, 'Expected': 2146, 'Rumours': 2147, 'EPA': 2148, 'DNA': 2149, 'Station': 2150, 'Dave': 2151, 'Electric': 2152, 'teen': 2153, 'Bullard': 2154, 'Airways': 2155, 'safe': 2156, 'Kelly': 2157, 'Tattoo': 2158, 'positive': 2159, 'breaks': 2160, 'worst': 2161, 'Let': 2162, 'Battle': 2163, 'plea': 2164, 'Turn': 2165, 'sick': 2166, 'D': 2167, 'Bossy': 2168, 'Jeopardy': 2169, 'Strengthens': 2170, 'resolve': 2171, 'weight': 2172, 'slides': 2173, 'Ruling': 2174, 'Kimye': 2175, 'production': 2176, 'slows': 2177, 'Draper': 2178, 'auction': 2179, 'boosts': 2180, 'mixed': 2181, 'Doctor': 2182, 'card': 2183, 'Shoot': 2184, 'Hamptons': 2185, 'size': 2186, 'Group': 2187, 'helps': 2188, 'Customers': 2189, 'Haven': 2190, 'Hair': 2191, 'Darren': 2192, 'Launch': 2193, 'performance': 2194, 'Ireland': 2195, 'USA': 2196, 'stop': 2197, 'Chase': 2198, 'Pretty': 2199, 'Green': 2200, 'Holcim': 2201, 'Lafarge': 2202, 'Ways': 2203, 'water': 2204, 'Detective': 2205, 'testimony': 2206, 'age': 2207, 'extends': 2208, 'weaker': 2209, 'lowest': 2210, 'almost': 2211, 'Richardson': 2212, 'Notes': 2213, 'act': 2214, 'Chief': 2215, 'did': 2216, 'Yum': 2217, 'Libyan': 2218, 'Supply': 2219, 'Output': 2220, 'reaches': 2221, 'young': 2222, 'seeks': 2223, 'Rolls': 2224, 'International': 2225, 'skin': 2226, 'Condition': 2227, 'Online': 2228, 'Must': 2229, 'do': 2230, 'stays': 2231, 'Wells': 2232, 'Union': 2233, 'Approval': 2234, 'Emirates': 2235, 'Michigan': 2236, 'Breaking': 2237, 'Enough': 2238, 'Ring': 2239, 'Coach': 2240, 'Seek': 2241, 'Scene': 2242, 'Alien': 2243, 'Probably': 2244, 'Competition': 2245, 'charged': 2246, 'optimism': 2247, 'Sends': 2248, 'attack': 2249, 'Hamm': 2250, 'Many': 2251, 'COLUMN': 2252, 'Dawn': 2253, 'Schwarzenegger': 2254, 'acting': 2255, 'Ross': 2256, 'Weak': 2257, 'delayed': 2258, 'Tells': 2259, 'Dallas': 2260, 'Control': 2261, 'job': 2262, 'Choice': 2263, 'Channing': 2264, 'surges': 2265, 'Bitcoin': 2266, 'Possible': 2267, 'between': 2268, 'Ariana': 2269, 'Grande': 2270, 'Kiefer': 2271, 'vows': 2272, 'Project': 2273, 'Shot': 2274, 'forced': 2275, 'upbeat': 2276, 'v': 2277, 'Uninsured': 2278, 'which': 2279, 'NYMEX': 2280, 'Forecasts': 2281, 'BLOGS': 2282, 'DAY': 2283, 'Upon': 2284, 'real': 2285, 'industry': 2286, 'Joke': 2287, 'Adams': 2288, 'Celebrate': 2289, 'Sister': 2290, 'Hyundai': 2291, 'Filming': 2292, '26': 2293, 'tumbles': 2294, 'Every': 2295, 'name': 2296, 'plant': 2297, 'financial': 2298, 'slide': 2299, 'Ifo': 2300, 'Fan': 2301, 'Catch': 2302, 'Glee': 2303, 'bring': 2304, 'room': 2305, 'Drake': 2306, 'tribute': 2307, 'Quarterly': 2308, 'Investment': 2309, 'Topless': 2310, 'Magazine': 2311, 'Without': 2312, 'Allegedly': 2313, 'tanker': 2314, 'Explains': 2315, 'sexy': 2316, 'diabetes': 2317, 'Vergara': 2318, 'Super': 2319, 'FBI': 2320, 'Muppets': 2321, 'final': 2322, 'USDA': 2323, 'Lives': 2324, 'nears': 2325, 'Team': 2326, 'Puts': 2327, 'B': 2328, 'Sawyer': 2329, 'Fine': 2330, 'Sandra': 2331, 'Partners': 2332, 'Letter': 2333, 'Reasons': 2334, 'Hold': 2335, 'Might': 2336, 'Barra': 2337, 'MH370': 2338, 'customers': 2339, 'climate': 2340, 'Everyone': 2341, 'Casey': 2342, 'Kasem': 2343, 'Hayden': 2344, 'iPhone': 2345, 'Zeppelin': 2346, 'Terrible': 2347, 'Named': 2348, 'Fresh': 2349, 'does': 2350, 'Chef': 2351, 'Force': 2352, 'Bang': 2353, 'Debate': 2354, 'Duff': 2355, 'ad': 2356, 'tattoo': 2357, 'same': 2358, 'Me': 2359, 'negative': 2360, 'returns': 2361, 'Increases': 2362, 'Celebrity': 2363, 'discovered': 2364, 'Slumps': 2365, 'food': 2366, 'Hillshire': 2367, 'Elec': 2368, 'Come': 2369, 'Jude': 2370, 'Beautiful': 2371, 'SoftBank': 2372, 'weekly': 2373, 'land': 2374, 'comes': 2375, 'Weakens': 2376, 'Anthony': 2377, 'Fired': 2378, 'Straight': 2379, 'held': 2380, 'joint': 2381, 'risks': 2382, 'Act': 2383, 'Retirement': 2384, 'trigger': 2385, 'confidence': 2386, 'Aged': 2387, 'Donnell': 2388, 'Billy': 2389, 'attacks': 2390, 'Cell': 2391, 'Accused': 2392, 'approval': 2393, 'mostly': 2394, 'contestant': 2395, 'Until': 2396, 'Defense': 2397, 'skirt': 2398, 'Platinum': 2399, 'older': 2400, 'Agrees': 2401, 'Labeouf': 2402, 'Monster': 2403, 'famous': 2404, 'Page': 2405, 'Pressure': 2406, 'Dimon': 2407, 'Amal': 2408, 'Alamuddin': 2409, 'natural': 2410, 'Sues': 2411, 'tie': 2412, 'Faster': 2413, 'Tina': 2414, 'Fey': 2415, 'Launches': 2416, 'Reveal': 2417, 'Baker': 2418, 'Arrest': 2419, 'jail': 2420, 'Round': 2421, 'Alba': 2422, 'rallies': 2423, 'Brings': 2424, 'Pregnancy': 2425, 'others': 2426, 'union': 2427, 'Labor': 2428, 'separate': 2429, 'Ukrainian': 2430, 'men': 2431, 'flashes': 2432, 'pre': 2433, 'Ad': 2434, 'DEBT': 2435, 'picks': 2436, 'Comeback': 2437, 'move': 2438, 'Quit': 2439, 'Spring': 2440, 'San': 2441, 'Snow': 2442, 'Electronics': 2443, 'Courtney': 2444, 'Millions': 2445, 'Student': 2446, 'fire': 2447, 'struggle': 2448, 'Hackers': 2449, 'AC': 2450, 'DC': 2451, 'break': 2452, 'opening': 2453, 'Surges': 2454, 'healthy': 2455, 'why': 2456, 'Taking': 2457, 'Break': 2458, 'Governor': 2459, 'Grows': 2460, 'me': 2461, 'slow': 2462, 'Christian': 2463, 'Craig': 2464, 'Ferguson': 2465, 'leather': 2466, 'VMAs': 2467, 'Rehab': 2468, 'OWN': 2469, 'Prevent': 2470, '21': 2471, 'Ends': 2472, 'find': 2473, 'GQ': 2474, 'Copyright': 2475, 'Eating': 2476, 'Divorce': 2477, 'selloff': 2478, 'Mail': 2479, 'Common': 2480, 'disease': 2481, 'Apology': 2482, '250': 2483, 'Gene': 2484, 'Engagement': 2485, 'Complete': 2486, 'tries': 2487, 'turnaround': 2488, 'Pulled': 2489, 'Travel': 2490, 'signals': 2491, 'Die': 2492, 'Elle': 2493, 'Willow': 2494, 'rapper': 2495, 'attorney': 2496, '2000': 2497, 'Collapse': 2498, 'Growing': 2499, 'Rebounds': 2500, 'Interview': 2501, 'Iliad': 2502, 'starts': 2503, 'CBO': 2504, 'Winning': 2505, 'Meets': 2506, 'Cigarettes': 2507, 'funding': 2508, 'website': 2509, 'Erste': 2510, 'FedEx': 2511, 'Healthcare': 2512, 'Lilly': 2513, 'social': 2514, 'Twitch': 2515, 'women': 2516, 'hard': 2517, 'Parents': 2518, 'Hills': 2519, 'Train': 2520, 'camera': 2521, 'song': 2522, 'F': 2523, 'front': 2524, 'Put': 2525, 'Scenes': 2526, 'announce': 2527, 'Coldplay': 2528, 'Macklemore': 2529, 'competition': 2530, 'Vegas': 2531, 'entire': 2532, 'full': 2533, 'y': 2534, 'Comedy': 2535, 'Insider': 2536, '0': 2537, 'Jace': 2538, 'Murder': 2539, 'Paparazzi': 2540, 'CNBC': 2541, 'flash': 2542, 'helped': 2543, 'DeGeneres': 2544, 'Unit': 2545, 'Attorney': 2546, 'Date': 2547, 'Arnold': 2548, '200': 2549, 'Mt': 2550, 'Gox': 2551, 'Ginnifer': 2552, 'Goodwin': 2553, 'Proves': 2554, 'boss': 2555, 'Tran': 2556, 'Didn': 2557, 'Copaxone': 2558, 'September': 2559, 'Banking': 2560, 'Row': 2561, 'mystery': 2562, 'blow': 2563, 'Comic': 2564, 'around': 2565, 'Medical': 2566, 'restaurant': 2567, 'other': 2568, 'Loans': 2569, 'books': 2570, 'Elon': 2571, 'Anderson': 2572, 'Read': 2573, 'line': 2574, 'Coast': 2575, 'Board': 2576, 'Services': 2577, 'Weaker': 2578, 'members': 2579, 'give': 2580, 'must': 2581, 'broad': 2582, 'hair': 2583, 'estimate': 2584, 'cools': 2585, 'multi': 2586, 'Factory': 2587, 'row': 2588, 'Greek': 2589, 'leave': 2590, 'Executive': 2591, 'lawmakers': 2592, 'continues': 2593, 'crop': 2594, 'Works': 2595, 'direct': 2596, 'Sarah': 2597, 'Republicans': 2598, 'lunch': 2599, 'Flight': 2600, 'rare': 2601, 'Soon': 2602, 'Longest': 2603, 'soft': 2604, 'H': 2605, 'expands': 2606, 'Tyler': 2607, 'Keeps': 2608, 'toll': 2609, 'Firth': 2610, 'Edwards': 2611, 'Rose': 2612, 'workers': 2613, 'Eight': 2614, 'Tiffany': 2615, '1000': 2616, 'Tim': 2617, 'pleads': 2618, 'towards': 2619, 'Richards': 2620, 'Concern': 2621, 'Dov': 2622, 'Away': 2623, 'Criminal': 2624, 'storage': 2625, 'funeral': 2626, 'Boys': 2627, 'Church': 2628, 'Admits': 2629, 'Magic': 2630, 'Pan': 2631, 'Well': 2632, 'Default': 2633, 'Palermo': 2634, 'disappoints': 2635, 'Scrutiny': 2636, 'payment': 2637, 'Letterman': 2638, 'Emmy': 2639, 'Aniston': 2640, 'surprise': 2641, 'outside': 2642, 'Bullock': 2643, 'closes': 2644, 'class': 2645, 'SNL': 2646, 'unveil': 2647, 'Sean': 2648, 'fashion': 2649, 'Expecting': 2650, 'Fourth': 2651, 'Katherine': 2652, 'police': 2653, 'straight': 2654, 'Pippa': 2655, 'Breach': 2656, 'Hewitt': 2657, 'Equal': 2658, 'Weather': 2659, 'Murray': 2660, 'Gwen': 2661, 'Theory': 2662, 'Doubtfire': 2663, 'Fake': 2664, 'Decision': 2665, 'Guide': 2666, 'Bulgarian': 2667, 'Settle': 2668, 'within': 2669, 'law': 2670, 'Makers': 2671, 'Ed': 2672, 'Lips': 2673, 'Guy': 2674, 'victims': 2675, 'Amanda': 2676, 'thinks': 2677, '57': 2678, '56': 2679, 'Lands': 2680, 'wake': 2681, 'Brands': 2682, 'guidance': 2683, 'pill': 2684, 'Sparks': 2685, 'crashes': 2686, 'fell': 2687, 'Currencies': 2688, 'Tweets': 2689, 'Bigger': 2690, 'Reviews': 2691, 'Positive': 2692, 'Cancelled': 2693, 'climb': 2694, 'Exports': 2695, 'Term': 2696, 'Ray': 2697, 'warn': 2698, 'Lucas': 2699, 'medical': 2700, 'guest': 2701, 'markets': 2702, 'Device': 2703, 'Mac': 2704, 'bill': 2705, 'Daddy': 2706, 'Coming': 2707, 'control': 2708, 'Performance': 2709, 'gay': 2710, 'solar': 2711, 'pictured': 2712, 'Defect': 2713, 'Responds': 2714, 'accused': 2715, 'Nirvana': 2716, 'Sterling': 2717, 'futures': 2718, 'challenge': 2719, 'Greece': 2720, '3rd': 2721, 'Himself': 2722, 'making': 2723, 'Slows': 2724, 'celebrates': 2725, 'Justice': 2726, 'Lamar': 2727, 'Fees': 2728, 'sparks': 2729, 'Hollande': 2730, 'road': 2731, 'Add': 2732, 'lets': 2733, 'following': 2734, 'Fit': 2735, 'Slide': 2736, 'Receives': 2737, 'Chipotle': 2738, 'Kill': 2739, 'Hosting': 2740, 'store': 2741, 'Worth': 2742, 'issue': 2743, 'Using': 2744, 'doctors': 2745, 'Lloyds': 2746, 'cast': 2747, 'Inside': 2748, 'told': 2749, 'Malcolm': 2750, 'weekend': 2751, 'station': 2752, 'Constancio': 2753, 'Motor': 2754, 'Ant': 2755, 'grows': 2756, 'issues': 2757, 'Dancer': 2758, 'event': 2759, 'Build': 2760, 'climbs': 2761, 'Celebrities': 2762, 'ABS': 2763, 'Link': 2764, 'drags': 2765, 'hint': 2766, 'reduce': 2767, 'bikini': 2768, 'fresh': 2769, 'Care': 2770, 'agree': 2771, 'Slow': 2772, 'Depot': 2773, 'Pine': 2774, 'Pleads': 2775, 'Heaven': 2776, 'brain': 2777, 'dons': 2778, 'Tarantino': 2779, 'Rachel': 2780, 'Clinton': 2781, 'divorce': 2782, 'awaits': 2783, 'awards': 2784, 'Career': 2785, '51': 2786, 'Soars': 2787, '1300': 2788, 'Retail': 2789, 'Pizza': 2790, 'Channel': 2791, 'train': 2792, 'carbon': 2793, 'RR': 2794, 'Coca': 2795, 'Cola': 2796, 'Jesus': 2797, 'Fanning': 2798, 'hunting': 2799, 'beautiful': 2800, 'Pot': 2801, 'HSBC': 2802, '87': 2803, 'Omnicom': 2804, 'Highlights': 2805, 'Eyes': 2806, 'Prize': 2807, 'Thanks': 2808, 'Kit': 2809, 'Patton': 2810, 'Philips': 2811, 'Bosses': 2812, 'Perfect': 2813, 'Threatens': 2814, 'Deflation': 2815, 'married': 2816, 'Beverly': 2817, 'lending': 2818, 'recalled': 2819, 'Unexpectedly': 2820, 'Korean': 2821, 'cites': 2822, 'Naked': 2823, 'election': 2824, 'allows': 2825, 'Holmes': 2826, 'Engaged': 2827, 'Rape': 2828, 'Airbus': 2829, 'Morris': 2830, 'Ticket': 2831, 'session': 2832, 'prepares': 2833, 'Tied': 2834, 'Shooting': 2835, 'filming': 2836, 'Oh': 2837, 'sentiment': 2838, 'increase': 2839, 'Drugs': 2840, 'losing': 2841, 'scare': 2842, 'Ultra': 2843, 'replaces': 2844, 'output': 2845, 'chairman': 2846, 'Longtime': 2847, 'Minimum': 2848, '60': 2849, 'assault': 2850, 'Any': 2851, 'Try': 2852, 'Gig': 2853, 'Heading': 2854, 'Karrueche': 2855, 'asset': 2856, 'switches': 2857, 'NYT': 2858, 'Miami': 2859, 'Era': 2860, 'Pounds': 2861, 'Re': 2862, 'Welcome': 2863, '70': 2864, 'works': 2865, 'Response': 2866, 'Segel': 2867, 'right': 2868, 'Inc': 2869, 'Dre': 2870, 'platinum': 2871, 'Arizona': 2872, 'needed': 2873, 'WTO': 2874, 'Brittany': 2875, 'arrest': 2876, 'Walking': 2877, 'Slides': 2878, 'Pamela': 2879, 'Boston': 2880, 'Bloomberg': 2881, 'Trades': 2882, 'Ending': 2883, 'pilots': 2884, 'Solar': 2885, 'Amber': 2886, 'Reach': 2887, 'hacking': 2888, 'Vodafone': 2889, 'Forget': 2890, 'Ultimate': 2891, 'Warrior': 2892, 'many': 2893, 'Trails': 2894, 'Strong': 2895, 'Hungary': 2896, 'insider': 2897, 'Value': 2898, 'activity': 2899, 'blasts': 2900, '3D': 2901, 'Legendary': 2902, 'Fifty': 2903, 'Grey': 2904, 'Carter': 2905, 'Picks': 2906, 'Geithner': 2907, 'Edge': 2908, 'Camera': 2909, 'deflation': 2910, 'Easing': 2911, 'Leave': 2912, 'prevent': 2913, 'stance': 2914, 'Merrill': 2915, 'Hachette': 2916, 'weeks': 2917, 'steadies': 2918, 'Wu': 2919, 'Clan': 2920, 'Class': 2921, 'school': 2922, 'ACM': 2923, 'Porn': 2924, 'valued': 2925, 'protest': 2926, 'problems': 2927, 'miners': 2928, 'Brain': 2929, 'want': 2930, 'Tape': 2931, 'sinks': 2932, 'c': 2933, 'remains': 2934, 'Aid': 2935, 'Retreat': 2936, 'rating': 2937, 'via': 2938, 'qtr': 2939, 'founder': 2940, 'nude': 2941, 'Jury': 2942, 'jobless': 2943, 'Reunion': 2944, 'Largest': 2945, 'Normal': 2946, 'Violence': 2947, 'False': 2948, 'GOP': 2949, 'visits': 2950, 'legal': 2951, 'Culkin': 2952, 'moving': 2953, 'pound': 2954, 'Nearly': 2955, 'R': 2956, 'Mendes': 2957, 'Wild': 2958, 'Major': 2959, 'Picture': 2960, 'Kuroda': 2961, 'Ask': 2962, 'K': 2963, 'Saturn': 2964, 'accepts': 2965, 'Investigating': 2966, 'Traders': 2967, 'Blake': 2968, 'Studios': 2969, 'Parts': 2970, 'Relationship': 2971, 'Land': 2972, 'own': 2973, 'SXSW': 2974, 'Sopranos': 2975, 'Place': 2976, 'Digital': 2977, 'Special': 2978, 'Emmys': 2979, 'Reduce': 2980, 'covers': 2981, 'd': 2982, 'Evil': 2983, 'Advertising': 2984, 'breach': 2985, 'Spreads': 2986, 'them': 2987, 'Tries': 2988, 'Grow': 2989, 'Fracking': 2990, 'Furious': 2991, 'Ann': 2992, 'Hurt': 2993, 'Foreign': 2994, 'special': 2995, 'Idina': 2996, 'Menzel': 2997, 'employees': 2998, 'sea': 2999, 'across': 3000, 'Crashes': 3001, 'Hedge': 3002, 'October': 3003, 'Fuel': 3004, 'Wright': 3005, 'Weird': 3006, 'Drone': 3007, 'securities': 3008, 'Dorfman': 3009, 'Bids': 3010, 'Debbie': 3011, 'Disease': 3012, 'Comments': 3013, 'Panettiere': 3014, 'Rich': 3015, 'Mystery': 3016, 'Heigl': 3017, 'export': 3018, 'Deaths': 3019, 'rocket': 3020, 'weather': 3021, 'Spotify': 3022, 'Saturday': 3023, 'Expect': 3024, 'Members': 3025, 'Officially': 3026, 'Doing': 3027, 'questions': 3028, 'Jupiter': 3029, 'dovish': 3030, 'spot': 3031, 'Pistorius': 3032, 'getting': 3033, 'Stefani': 3034, 'Thor': 3035, 'Oracle': 3036, 'Culture': 3037, 'Speaks': 3038, 'Barnes': 3039, 'Noble': 3040, 'Chad': 3041, 'allow': 3042, 'Mega': 3043, 'Maine': 3044, 'Ruffalo': 3045, 'Garner': 3046, 'far': 3047, 'Markit': 3048, 'debris': 3049, 'Ports': 3050, 'Foster': 3051, 'Pinnacle': 3052, 'highest': 3053, 'political': 3054, 'planting': 3055, 'Caterpillar': 3056, 'Michaels': 3057, 'Which': 3058, 'Sexy': 3059, 'Likely': 3060, 'passengers': 3061, 'MH17': 3062, 'Sets': 3063, 'Fault': 3064, 'Develop': 3065, 'replace': 3066, 'where': 3067, 'Cheating': 3068, 'Daimler': 3069, 'develop': 3070, 'rebounds': 3071, 'Private': 3072, 'Stem': 3073, 'tobacco': 3074, 'proposes': 3075, 'viewers': 3076, 'litigation': 3077, 'Rights': 3078, 'Mae': 3079, 'Dividend': 3080, 'vote': 3081, 'Restaurant': 3082, 'Tributes': 3083, 'Comes': 3084, 'fiancée': 3085, 'Used': 3086, 'Hunger': 3087, 'Calm': 3088, 'shock': 3089, 'Delay': 3090, 'healthcare': 3091, 'Anita': 3092, 'Warrant': 3093, 'Forced': 3094, 'Seat': 3095, 'bars': 3096, 'strikes': 3097, 'contract': 3098, 'STUDY': 3099, 'Taken': 3100, 'Rule': 3101, 'cautious': 3102, 'biopic': 3103, 'Legacy': 3104, 'Secrets': 3105, 'Offering': 3106, 'VMA': 3107, 'perfect': 3108, 'Beyond': 3109, 'Oculus': 3110, 'Changed': 3111, 'Teaser': 3112, 'stable': 3113, 'begins': 3114, 'plunging': 3115, 'Pandora': 3116, 'stolen': 3117, 'protect': 3118, 'IPhone': 3119, 'Teams': 3120, 'insists': 3121, '4th': 3122, 'changes': 3123, 'Dream': 3124, 'Sons': 3125, 'Alex': 3126, 'compensation': 3127, 'Alcoa': 3128, 'Raising': 3129, 'caught': 3130, 'Spike': 3131, 'Factbox': 3132, 'inches': 3133, 'continue': 3134, 'fired': 3135, 'bag': 3136, 'accuses': 3137, 'probes': 3138, 'toned': 3139, 'legs': 3140, 'confirm': 3141, 'spin': 3142, '93': 3143, 'slumps': 3144, 'Fantastic': 3145, 'Pet': 3146, 'perform': 3147, 'Sold': 3148, 'Volatility': 3149, 'central': 3150, 'fails': 3151, 'critical': 3152, 'Paid': 3153, 'Feud': 3154, 'Lockheed': 3155, 'engagement': 3156, 'Tracking': 3157, 'Region': 3158, 'Fewer': 3159, 'save': 3160, 'Dublin': 3161, 'wig': 3162, 'Claire': 3163, 'cleavage': 3164, 'Challenges': 3165, 'Given': 3166, 'concerned': 3167, 'Developers': 3168, 'tap': 3169, 'alcohol': 3170, 'Lynn': 3171, 'sequel': 3172, 'Kimmel': 3173, 'Fun': 3174, 'Marquez': 3175, 'killer': 3176, 'hot': 3177, 'snaps': 3178, 'streak': 3179, 'payrolls': 3180, 'seek': 3181, 'Regulator': 3182, 'Human': 3183, 'rated': 3184, 'approve': 3185, 'Satellite': 3186, 'planes': 3187, '68': 3188, 'Done': 3189, 'Remains': 3190, 'Alcohol': 3191, 'our': 3192, 'hosts': 3193, 'advance': 3194, 'valuation': 3195, 'times': 3196, 'Brother': 3197, 'birth': 3198, 'Noto': 3199, 'BB': 3200, 'Publicis': 3201, 'Exchange': 3202, 'Joint': 3203, 'links': 3204, 'Ruble': 3205, 'Label': 3206, 'Gabriel': 3207, 'Lose': 3208, 'Stream': 3209, 'Working': 3210, 'faulty': 3211, 'Harington': 3212, 'Details': 3213, 'Christine': 3214, 'Lagarde': 3215, 'aid': 3216, 'celebrate': 3217, 'Venice': 3218, 'wearing': 3219, 'Rumors': 3220, 'Pictured': 3221, 'Anglo': 3222, 'illegal': 3223, 'Passengers': 3224, 'Unrest': 3225, 'Midnight': 3226, 'Producer': 3227, 'jumpsuit': 3228, 'spreads': 3229, 'Subscribers': 3230, 'Nintendo': 3231, 'Las': 3232, 'lost': 3233, 'neutrality': 3234, 'AIG': 3235, '78': 3236, 'imports': 3237, 'fires': 3238, 'falling': 3239, 'lab': 3240, 'Unemployment': 3241, 'Point': 3242, 'Track': 3243, 'Accident': 3244, 'McDermott': 3245, 'Benzino': 3246, 'consumers': 3247, 'Teenage': 3248, 'Replaces': 3249, 'Fires': 3250, 'president': 3251, 'Apes': 3252, 'Motorola': 3253, 'Losses': 3254, 'Ma': 3255, 'campaign': 3256, 'products': 3257, 'Philip': 3258, 'until': 3259, 'least': 3260, 'FAA': 3261, 'UBS': 3262, 'Duchess': 3263, 'Cambridge': 3264, 'Extinction': 3265, 'Crimea': 3266, 'shoot': 3267, 'Webb': 3268, 'heads': 3269, 'Favorite': 3270, 'looking': 3271, 'enough': 3272, 'Losing': 3273, 'Memorial': 3274, 'Contract': 3275, 'Incident': 3276, 'double': 3277, 'Qatar': 3278, '300': 3279, 'casts': 3280, 'cold': 3281, 'Mixed': 3282, 'brands': 3283, 'tension': 3284, 'Nancy': 3285, 'chic': 3286, 'Prinze': 3287, 'measures': 3288, 'begin': 3289, 'Firing': 3290, 'facing': 3291, 'Treatment': 3292, 'bump': 3293, 'using': 3294, 'Pop': 3295, 'Collins': 3296, 'GameStop': 3297, 'Abortion': 3298, 'Portugal': 3299, 'BES': 3300, 'Acting': 3301, 'Seacrest': 3302, 'Bet': 3303, 'Survey': 3304, 'Murphy': 3305, 'Aren': 3306, 'Country': 3307, 'Wish': 3308, 'Recent': 3309, '28': 3310, 'Walk': 3311, 'Caught': 3312, 'kiwi': 3313, 'Bynes': 3314, 'Danica': 3315, 'Cara': 3316, 'Delevingne': 3317, 'Personal': 3318, 'walk': 3319, '88': 3320, 'cent': 3321, 'marries': 3322, 'value': 3323, 'fiance': 3324, 'producer': 3325, 'bigger': 3326, 'monetary': 3327, 'Decade': 3328, 'Unveils': 3329, 'Killed': 3330, 'Makeover': 3331, 'Exit': 3332, 'how': 3333, 'prompt': 3334, 'Slowing': 3335, 'state': 3336, 'jets': 3337, 'dazzles': 3338, 'mini': 3339, 'including': 3340, 'Funding': 3341, 'Shakira': 3342, 'Bradley': 3343, 'Upcoming': 3344, 'expecting': 3345, 'activists': 3346, 'Opera': 3347, 'Names': 3348, 'Levels': 3349, 'Gun': 3350, 'Shades': 3351, 'brother': 3352, 'Susan': 3353, 'level': 3354, 'Deputy': 3355, 'past': 3356, 'Carolina': 3357, 'Happiness': 3358, 'Strike': 3359, 'Hospitalized': 3360, 'used': 3361, 'Wisconsin': 3362, 'Female': 3363, 'ADP': 3364, 'Tell': 3365, 'peak': 3366, 'Snaps': 3367, 'Shell': 3368, 'Toll': 3369, 'Brothers': 3370, 'doubles': 3371, 'Watching': 3372, 'Belle': 3373, 'Manager': 3374, 'Hunt': 3375, 'robust': 3376, 'winter': 3377, 'biotech': 3378, 'advances': 3379, 'living': 3380, 'Tuesday': 3381, 'Mental': 3382, 'Ridiculous': 3383, 'Grace': 3384, 'Planning': 3385, 'Kitty': 3386, 'Mozilla': 3387, 'Tobacco': 3388, 'Liberia': 3389, 'Marry': 3390, 'inside': 3391, 'port': 3392, 'trapped': 3393, 'Lawmakers': 3394, 'version': 3395, 'loans': 3396, 'mid': 3397, 'Expansion': 3398, 'valve': 3399, 'Pataky': 3400, 'Totally': 3401, 'Design': 3402, 'ratings': 3403, 'Fights': 3404, 'Quentin': 3405, 'Iran': 3406, 'expansion': 3407, 'worker': 3408, 'emissions': 3409, 'Broke': 3410, 'Barbara': 3411, 'Walters': 3412, '17000': 3413, 'Bankruptcy': 3414, 'Wilde': 3415, 'Crime': 3416, 'Broken': 3417, 'targets': 3418, 'drive': 3419, 'speed': 3420, 'Export': 3421, 'Style': 3422, 'exec': 3423, 'pipeline': 3424, 'Macaulay': 3425, 'bizarre': 3426, 'cents': 3427, 'Brazil': 3428, 'steal': 3429, 'Damage': 3430, 'Randall': 3431, 'Policies': 3432, 'released': 3433, 'Addresses': 3434, 'Mergers': 3435, 'mth': 3436, 'authorities': 3437, 'TO': 3438, 'race': 3439, 'tweets': 3440, 'Asiana': 3441, 'Covidien': 3442, 'soar': 3443, 'Academy': 3444, 'Because': 3445, 'Potential': 3446, 'Weibo': 3447, 'Nadella': 3448, 'YouTube': 3449, 'Least': 3450, 'geopolitical': 3451, 'Experience': 3452, 'Walmart': 3453, 'Pilot': 3454, 'rose': 3455, 'Navy': 3456, 'DUI': 3457, 'relationship': 3458, 'Community': 3459, 'Cause': 3460, 'VIX': 3461, 'pull': 3462, 'Art': 3463, 'Advice': 3464, 'jeans': 3465, 'tablet': 3466, 'affect': 3467, 'struggles': 3468, 'linked': 3469, 'Fear': 3470, 'Coal': 3471, 'Demands': 3472, 'Property': 3473, 'porn': 3474, 'asks': 3475, 'kiss': 3476, 'Janet': 3477, 'Rest': 3478, 'Thousands': 3479, 'companies': 3480, 'rights': 3481, 'index': 3482, 'economist': 3483, 'Funds': 3484, 'Nobody': 3485, 'Edgar': 3486, 'Pace': 3487, 'Anniversary': 3488, 'Trail': 3489, 'Lessons': 3490, 'Compliance': 3491, 'Mass': 3492, 'Childhood': 3493, 'Shop': 3494, 'Mel': 3495, 'progress': 3496, 'Shouldn': 3497, 'friend': 3498, 'Confused': 3499, 'Fat': 3500, 'Winner': 3501, 'Battery': 3502, 'warning': 3503, 'reject': 3504, 'soy': 3505, 'Facing': 3506, 'Kiwi': 3507, 'Screen': 3508, 'expand': 3509, 'claim': 3510, 'Hate': 3511, 'uptick': 3512, 'Sad': 3513, 'Non': 3514, 'future': 3515, '98': 3516, 'Fears': 3517, 'Abrams': 3518, 'Flu': 3519, 'Nine': 3520, 'software': 3521, '2011': 3522, 'Adkins': 3523, 'Bean': 3524, 'miss': 3525, 'models': 3526, 'Lawyer': 3527, 'Swaps': 3528, 'Self': 3529, 'surgery': 3530, 'Access': 3531, 'Island': 3532, 'Looms': 3533, 'earlier': 3534, 'Options': 3535, 'Valley': 3536, 'Bouygues': 3537, 'employers': 3538, 'huge': 3539, 'Driver': 3540, 'Strahan': 3541, 'Nook': 3542, 'ministers': 3543, 'Outdoor': 3544, 'dog': 3545, 'Colorado': 3546, 'Knight': 3547, 'Meg': 3548, 'Spin': 3549, 'satellite': 3550, 'Spends': 3551, 'Tools': 3552, 'reverse': 3553, 'paper': 3554, 'Rebels': 3555, 'Jodie': 3556, 'Wait': 3557, 'Alert': 3558, 'Tupac': 3559, 'Shakur': 3560, 'Mitsubishi': 3561, 'financing': 3562, 'Crafts': 3563, 'Bikini': 3564, 'mission': 3565, 'Racist': 3566, 'Awesome': 3567, 'ads': 3568, 'Maya': 3569, 'Knew': 3570, 'Christie': 3571, '59': 3572, 'build': 3573, 'violence': 3574, 'Marketing': 3575, 'Images': 3576, 'Appear': 3577, 'Nashville': 3578, 'copper': 3579, 'devices': 3580, 'praises': 3581, 'Tiger': 3582, 'Iconic': 3583, 'Extends': 3584, 'Appearance': 3585, 'Southern': 3586, 'Beatles': 3587, 'Adrienne': 3588, 'Bailon': 3589, 'Banana': 3590, 'Please': 3591, 'Founder': 3592, 'Vote': 3593, 'strength': 3594, 'number': 3595, 'Site': 3596, 'Nikki': 3597, 'become': 3598, 'Freeman': 3599, 'Plea': 3600, 'Drama': 3601, 'Key': 3602, 'Therapy': 3603, 'publisher': 3604, 'Grand': 3605, 'V': 3606, 'Alabama': 3607, 'knot': 3608, 'Winfrey': 3609, 'drink': 3610, 'Bull': 3611, 'Crushes': 3612, 'Swedish': 3613, 'crown': 3614, 'Existing': 3615, 'Warming': 3616, 'Living': 3617, 'Slower': 3618, 'Newly': 3619, 'involved': 3620, 'largest': 3621, 'remain': 3622, 'Avoid': 3623, 'CancelColbert': 3624, 'Restraining': 3625, 'KISS': 3626, '72': 3627, 'Nude': 3628, 'Erases': 3629, 'Tesco': 3630, 'Store': 3631, 'Rupert': 3632, 'haven': 3633, 'Strategy': 3634, 'Osbourne': 3635, 'Dad': 3636, 'Jewish': 3637, 'Analysts': 3638, 'Dying': 3639, 'Boss': 3640, 'Hobbit': 3641, 'construction': 3642, 'area': 3643, 'indexes': 3644, 'fate': 3645, 'Heads': 3646, 'modestly': 3647, '2007': 3648, 'never': 3649, 'Touts': 3650, 'Schumacher': 3651, 'rival': 3652, 'Features': 3653, 'aim': 3654, 'Swap': 3655, 'Corporate': 3656, 'door': 3657, 'tragic': 3658, '5000': 3659, 'Course': 3660, 'II': 3661, 'Bros': 3662, 'doing': 3663, 'FT': 3664, 'Coleman': 3665, 'Agree': 3666, 'Traffic': 3667, 'Trebek': 3668, 'fat': 3669, 'together': 3670, 'Egypt': 3671, 'TABLE': 3672, 'sends': 3673, 'bride': 3674, 'Peace': 3675, 'refuses': 3676, 'concert': 3677, 'senior': 3678, 'Gere': 3679, 'LG': 3680, 'inspired': 3681, 'Grease': 3682, 'Hour': 3683, 'Rodriguez': 3684, 'Dragon': 3685, 'Pain': 3686, 'Infection': 3687, 'restructuring': 3688, 'Salmonella': 3689, 'Mice': 3690, 'Corey': 3691, 'monthly': 3692, 'scrutiny': 3693, 'master': 3694, 'Cup': 3695, 'Rio': 3696, 'Religious': 3697, 'happy': 3698, 'lose': 3699, 'Mccartney': 3700, 'quits': 3701, 'Charge': 3702, 'Cards': 3703, 'Sue': 3704, 'Mary': 3705, 'Olsen': 3706, 'Junk': 3707, 'Warning': 3708, 'lives': 3709, 'racy': 3710, 'Ivy': 3711, 'terms': 3712, '49': 3713, 'Activision': 3714, 'Victims': 3715, 'Light': 3716, 'abuse': 3717, 'spring': 3718, 'Wrong': 3719, 'Joss': 3720, 'Whedon': 3721, 'extra': 3722, 'die': 3723, 'Promises': 3724, 'McAdams': 3725, 'Merkel': 3726, 'response': 3727, 'pension': 3728, 'retirement': 3729, 'himself': 3730, 'Sandberg': 3731, 'Virgin': 3732, 'Sachs': 3733, 'executives': 3734, 'Carbon': 3735, 'Failure': 3736, 'along': 3737, 'Nowotny': 3738, 'bags': 3739, 'Angry': 3740, 'Naomi': 3741, 'Safe': 3742, 'levels': 3743, 'franc': 3744, 'scene': 3745, 'controversial': 3746, 'walks': 3747, 'nine': 3748, 'VERY': 3749, 'Dolly': 3750, 'Parton': 3751, 'Taxes': 3752, 'Estate': 3753, 'Q': 3754, 'Nobel': 3755, 'Cutting': 3756, 'marry': 3757, 'Costume': 3758, 'Tears': 3759, 'Backs': 3760, 'conference': 3761, 'exposed': 3762, 'Introduces': 3763, 'Fashion': 3764, 'Research': 3765, 'speech': 3766, 'means': 3767, 'Massachusetts': 3768, 'Kindred': 3769, 'Gentiva': 3770, 'infected': 3771, 'we': 3772, 'apps': 3773, 'Maybe': 3774, 'Commercial': 3775, 'Kissing': 3776, 'Flash': 3777, 'EM': 3778, 'ASIA': 3779, 'know': 3780, 'Cent': 3781, 'Sells': 3782, 'Opportunity': 3783, 'Dowd': 3784, 'hurt': 3785, 'airport': 3786, 'Jail': 3787, 'Airline': 3788, 'Trader': 3789, 'stores': 3790, 'Reported': 3791, '280': 3792, 'Powerful': 3793, 'UniCredit': 3794, 'Rider': 3795, 'shy': 3796, 'Selfies': 3797, 'device': 3798, 'confirmed': 3799, 'Antarctic': 3800, 'Polio': 3801, 'led': 3802, 'check': 3803, 'Receive': 3804, 'Accord': 3805, 'Increased': 3806, '85': 3807, 'CNN': 3808, 'Experiment': 3809, 'Boyfriend': 3810, 'Barrie': 3811, 'Smaller': 3812, 'Blockbuster': 3813, 'hands': 3814, 'Gupta': 3815, 'form': 3816, 'Listen': 3817, 'great': 3818, 'Official': 3819, 'kept': 3820, 'Roseland': 3821, 'outfits': 3822, 'Scotty': 3823, 'Leftovers': 3824, 'Side': 3825, 'Awkward': 3826, 'Clips': 3827, 'ice': 3828, 'await': 3829, 'euros': 3830, 'Girlfriend': 3831, 'Shanghai': 3832, 'Dj': 3833, 'Bennett': 3834, 'PC': 3835, 'Curbs': 3836, 'spur': 3837, 'Zebra': 3838, 'Concerns': 3839, 'Extend': 3840, 'sits': 3841, 'Worldwide': 3842, 'allergic': 3843, 'Scientific': 3844, 'Thought': 3845, 'Spill': 3846, 'Trust': 3847, 'Topix': 3848, 'sisters': 3849, 'condensate': 3850, 'enjoy': 3851, 'Knows': 3852, 'Crop': 3853, 'Continues': 3854, 'Feels': 3855, 'Stays': 3856, 'Doctors': 3857, 'Unilever': 3858, 'Heathers': 3859, 'Pink': 3860, 'Poised': 3861, 'Jill': 3862, 'Hip': 3863, 'shut': 3864, 'Phil': 3865, 'consoles': 3866, 'deaths': 3867, 'fiancee': 3868, 'Halle': 3869, 'accelerates': 3870, 'Fighting': 3871, 'Something': 3872, 'recovers': 3873, 'owner': 3874, '43': 3875, 'Leading': 3876, 'TWC': 3877, 'import': 3878, 'Eurovision': 3879, 'BILLION': 3880, 'JetBlue': 3881, 'Suggests': 3882, 'Those': 3883, 'Mostly': 3884, 'Silence': 3885, 'dangerous': 3886, 'tracking': 3887, 'Moves': 3888, 'Toward': 3889, 'govt': 3890, 'advice': 3891, 'Winners': 3892, 'Includes': 3893, 'seeking': 3894, 'whether': 3895, 'Filled': 3896, 'Rant': 3897, 'AOL': 3898, 'Gotham': 3899, 'Explain': 3900, 'murder': 3901, 'Autism': 3902, 'merge': 3903, 'Them': 3904, 'Strikes': 3905, 'Smokers': 3906, 'According': 3907, '83': 3908, 'pushing': 3909, 'Heartbreaking': 3910, 'Riot': 3911, 'Paisley': 3912, 'Statement': 3913, 'Rita': 3914, 'Ora': 3915, 'Mccarthy': 3916, 'wary': 3917, 'Osborne': 3918, 'pal': 3919, 'Bizarre': 3920, 'leaving': 3921, 'DIARY': 3922, 'Events': 3923, 'SunTrust': 3924, 'Partnership': 3925, 'Failed': 3926, 'Problems': 3927, 'plunge': 3928, 'border': 3929, 'Small': 3930, 'remarks': 3931, 'Promotes': 3932, 'Dog': 3933, 'Hearing': 3934, 'Write': 3935, 'leg': 3936, 'gloom': 3937, 'Bruce': 3938, 'charity': 3939, 'Knox': 3940, 'Account': 3941, 'demands': 3942, 'funds': 3943, 'palladium': 3944, 'nuclear': 3945, 'snap': 3946, 'momentum': 3947, 'Modern': 3948, '7th': 3949, 'Television': 3950, 'Cheaper': 3951, 'Farley': 3952, 'Mowat': 3953, '92': 3954, '91': 3955, 'Allegations': 3956, 'Zach': 3957, 'comedy': 3958, 'Steinberg': 3959, 'Sentenced': 3960, 'Computer': 3961, 'Refuses': 3962, 'Horse': 3963, 'Band': 3964, 'Zillow': 3965, 'Suspends': 3966, 'Honduran': 3967, 'heavy': 3968, 'TIME': 3969, 'Rumor': 3970, 'anxiety': 3971, 'Paddington': 3972, 'Van': 3973, 'Vehicles': 3974, 'twin': 3975, 'accident': 3976, 'Glory': 3977, '64': 3978, 'romantic': 3979, 'disappoint': 3980, 'museum': 3981, 'Danny': 3982, 'Israel': 3983, 'Jane': 3984, 'girls': 3985, 'Mercedes': 3986, 'Dynasty': 3987, 'Larry': 3988, 'Cabaret': 3989, 'Weighs': 3990, 'battery': 3991, 'Lately': 3992, 'Flaw': 3993, 'Explorer': 3994, 'Nuclear': 3995, '30th': 3996, 'Humans': 3997, 'DJ': 3998, 'smoking': 3999, 'TrueCar': 4000, 'Veteran': 4001, 'Rebhorn': 4002, 'Lake': 4003, 'refinery': 4004, 'Longoria': 4005, 'daring': 4006, 'annual': 4007, 'Chain': 4008, 'Hortons': 4009, 'team': 4010, 'survey': 4011, 'Replacing': 4012, 'River': 4013, 'Gauge': 4014, 'Manganiello': 4015, 'Beef': 4016, 'Recalled': 4017, 'technology': 4018, 'priced': 4019, 'halt': 4020, 'running': 4021, 'Nighter': 4022, 'Vows': 4023, 'acquisitions': 4024, 'Stuns': 4025, 'policies': 4026, 'Noyer': 4027, 'Obesity': 4028, 'album': 4029, 'songs': 4030, 'displays': 4031, 'died': 4032, 'Bright': 4033, 'Fatal': 4034, 'Alexander': 4035, 'Lung': 4036, 'hope': 4037, 'Thinking': 4038, 'Cranston': 4039, 'Treatments': 4040, 'Ocean': 4041, 'Frequency': 4042, 'Hilarious': 4043, 'Enter': 4044, 'Yukos': 4045, 'Metro': 4046, 'needs': 4047, 'Status': 4048, '113': 4049, 'Email': 4050, 'Card': 4051, 'Network': 4052, 'mulls': 4053, '42': 4054, 'Hastings': 4055, 'flaw': 4056, 'Dina': 4057, 'Keys': 4058, 'Developing': 4059, 'economies': 4060, 'Seinfeld': 4061, 'drama': 4062, 'Jobless': 4063, 'Count': 4064, 'dinosaurs': 4065, 'speculation': 4066, 'ship': 4067, 'carrying': 4068, 'PM': 4069, 'Primary': 4070, 'pace': 4071, 'Artist': 4072, 'Critical': 4073, 'millions': 4074, 'Purple': 4075, 'Science': 4076, 'solid': 4077, 'Republican': 4078, 'rivals': 4079, 'Prompt': 4080, 'Asks': 4081, 'limits': 4082, 'Tea': 4083, 'Cody': 4084, 'Damon': 4085, 'Attacked': 4086, 'investor': 4087, 'morale': 4088, 'Kocherlakota': 4089, 'Stairway': 4090, 'Fell': 4091, 'sues': 4092, 'Georgina': 4093, 'Haig': 4094, 'avoid': 4095, '31': 4096, 'Broadband': 4097, 'place': 4098, 'Estimated': 4099, 'UnitedHealth': 4100, 'Davis': 4101, 'CPI': 4102, 'William': 4103, 'Crumbs': 4104, 'Dylan': 4105, 'infection': 4106, 'Restrictions': 4107, 'Claim': 4108, 'dance': 4109, 'Replace': 4110, 'smaller': 4111, 'finally': 4112, 'Stunning': 4113, 'Thailand': 4114, 'Cement': 4115, 'defect': 4116, 'pictures': 4117, 'Proposes': 4118, 'Combs': 4119, 'Emergency': 4120, 'Speak': 4121, 'Body': 4122, 'Testing': 4123, 'Victory': 4124, 'Gone': 4125, 'Kind': 4126, 'MARKET': 4127, 'Streak': 4128, 'lags': 4129, 'Bobby': 4130, 'Womack': 4131, 'considers': 4132, 'Mr': 4133, '787': 4134, 'Bird': 4135, 'brings': 4136, 'meets': 4137, 'Jared': 4138, 'Stronger': 4139, 'copyright': 4140, 'Zealand': 4141, '76': 4142, 'broken': 4143, 'Mothers': 4144, 'Analyst': 4145, 'Emotional': 4146, 'Blames': 4147, 'Cinco': 4148, 'closer': 4149, 'Owners': 4150, 'given': 4151, 'Ken': 4152, 'pool': 4153, '4000': 4154, 'banned': 4155, 'Models': 4156, 'Dance': 4157, 'Carriers': 4158, 'cool': 4159, 'musical': 4160, 'Shocked': 4161, 'here': 4162, 'objects': 4163, 'Potentially': 4164, 'Auction': 4165, 'Iceland': 4166, 'Ranbaxy': 4167, 'impact': 4168, 'Indiana': 4169, 'BBC': 4170, 'flies': 4171, 'Jersey': 4172, 'Smart': 4173, 'theft': 4174, 'Wallach': 4175, 'Returning': 4176, 'Hedwig': 4177, 'delays': 4178, 'pending': 4179, 'Flaming': 4180, 'Starts': 4181, 'Trace': 4182, 'Frances': 4183, 'sags': 4184, 'babies': 4185, 'bug': 4186, 'decision': 4187, 'there': 4188, 'doesn': 4189, 'Wasn': 4190, 'Surface': 4191, 'Adele': 4192, 'Investor': 4193, 'Spot': 4194, 'Twice': 4195, 'hints': 4196, 'PokerStars': 4197, 'poses': 4198, 'Told': 4199, 'August': 4200, 'gasoline': 4201, 'Worker': 4202, 'LGBT': 4203, 'Protect': 4204, 'rush': 4205, 'fees': 4206, 'Rhode': 4207, 'caused': 4208, 'Learned': 4209, 'bachelor': 4210, 'factories': 4211, 'outflows': 4212, 'Caps': 4213, 'Supplies': 4214, 'Miller': 4215, 'Lively': 4216, 'Guns': 4217, 'Mayer': 4218, 'improved': 4219, 'SFR': 4220, 'holding': 4221, 'adjust': 4222, 'Protest': 4223, 'rail': 4224, 'cargo': 4225, 'states': 4226, 'Itself': 4227, 'Airplane': 4228, 'Ferrell': 4229, 'wild': 4230, 'Cites': 4231, 'Remember': 4232, 'experiment': 4233, 'Op': 4234, 'cameo': 4235, 'Visits': 4236, 'games': 4237, 'Tinder': 4238, 'Valuation': 4239, 'exposure': 4240, 'anthrax': 4241, 'Accuser': 4242, 'eye': 4243, 'course': 4244, 'Happen': 4245, 'steel': 4246, 'Astra': 4247, 'capex': 4248, '80': 4249, 'Toy': 4250, 'Shane': 4251, 'designer': 4252, 'funny': 4253, 'hacked': 4254, 'Sentiment': 4255, 'Appeal': 4256, 'experts': 4257, 'Footage': 4258, 'Volkswagen': 4259, 'Angelou': 4260, '86': 4261, 'Tomlinson': 4262, 'Cyber': 4263, 'curb': 4264, 'Trip': 4265, 'heard': 4266, 'Fincher': 4267, 'prime': 4268, 'Roche': 4269, 'Drives': 4270, 'Joel': 4271, 'hop': 4272, 'Explosive': 4273, 'faster': 4274, 'Advantage': 4275, 'Christopher': 4276, 'Shocking': 4277, 'Injured': 4278, 'confident': 4279, 'Chiquita': 4280, 'Fyffes': 4281, 'Carphone': 4282, 'Dixons': 4283, 'sharply': 4284, 'revised': 4285, 'Reacts': 4286, '29': 4287, 'Beloved': 4288, 'TIMELINE': 4289, 'Prospects': 4290, 'Cops': 4291, 'appoints': 4292, 'Lord': 4293, 'Attenborough': 4294, 'mood': 4295, 'photographer': 4296, 'isn': 4297, 'Remembering': 4298, 'RBA': 4299, 'Getty': 4300, 'plays': 4301, 'Sara': 4302, 'Gilbert': 4303, 'Linda': 4304, 'Raging': 4305, 'Match': 4306, 'stung': 4307, 'Limit': 4308, 'Create': 4309, 'Artificial': 4310, 'Brockie': 4311, 'Died': 4312, 'Heroin': 4313, 'LOS': 4314, 'ANGELES': 4315, 'planet': 4316, 'Moment': 4317, 'EXCLUSIVE': 4318, 'bans': 4319, 'Lauer': 4320, 'press': 4321, 'Drinking': 4322, 'Backlash': 4323, 'foreign': 4324, 'Fields': 4325, 'enrollment': 4326, '110': 4327, 'Below': 4328, 'Diet': 4329, 'Hours': 4330, 'Pershing': 4331, 'Empire': 4332, 'bailout': 4333, 'Southeast': 4334, 'Tested': 4335, 'Protests': 4336, 'dressed': 4337, 'Houston': 4338, 'Cox': 4339, 'Moscow': 4340, 'Trend': 4341, 'Homeless': 4342, 'Testimony': 4343, 'mayor': 4344, 'Israeli': 4345, 'Cyprus': 4346, 'benchmark': 4347, 'SPOILER': 4348, 'Odom': 4349, 'Mya': 4350, 'expects': 4351, '114': 4352, 'covered': 4353, 'Tests': 4354, 'Mission': 4355, 'Ancier': 4356, 'Goddard': 4357, 'Pledge': 4358, 'Slack': 4359, 'Updates': 4360, 'Andy': 4361, 'Warhol': 4362, 'create': 4363, 'twins': 4364, 'Helps': 4365, 'MannKind': 4366, 'Already': 4367, 'Worsens': 4368, 'Honour': 4369, 'Affirmed': 4370, 'Nears': 4371, 'Authorities': 4372, 'Payment': 4373, 'durable': 4374, 'goods': 4375, 'payments': 4376, 'Serious': 4377, 'Lights': 4378, 'pink': 4379, 'breast': 4380, 'Kickstarter': 4381, 'Steel': 4382, 'critics': 4383, 'breaking': 4384, 'flying': 4385, 'personal': 4386, 'Broadcast': 4387, 'thought': 4388, 'backs': 4389, 'eBay': 4390, 'Venture': 4391, 'ingredients': 4392, 'Approves': 4393, 'Toby': 4394, 'Kebbell': 4395, 'Reboot': 4396, 'suspend': 4397, 'Lithuania': 4398, 'concern': 4399, 'Poses': 4400, 'Conviction': 4401, 'WEEKAHEAD': 4402, 'Woes': 4403, 'Matter': 4404, 'throws': 4405, 'Snake': 4406, 'Bite': 4407, 'Spurs': 4408, 'Prank': 4409, 'Princess': 4410, 'Genetic': 4411, 'revamp': 4412, '66': 4413, 'Emerge': 4414, 'TWO': 4415, 'Avengers': 4416, 'blonde': 4417, 'Holt': 4418, 'Etihad': 4419, 'bet': 4420, 'blockbuster': 4421, 'pins': 4422, 'spills': 4423, 'cannabis': 4424, 'Charter': 4425, 'appeal': 4426, 'forward': 4427, 'Turkish': 4428, 'hurts': 4429, 'Drink': 4430, 'Hell': 4431, 'Adaptation': 4432, 'Heartfelt': 4433, 'Orleans': 4434, 'similar': 4435, 'Notebook': 4436, 'Bullish': 4437, 'Wilson': 4438, 'Funny': 4439, 'Block': 4440, 'approved': 4441, 'Ground': 4442, 'cause': 4443, 'LNG': 4444, 'Cleared': 4445, 'Stops': 4446, 'Boom': 4447, 'airline': 4448, 'Forms': 4449, 'Erykah': 4450, 'Badu': 4451, 'W': 4452, 'currency': 4453, 'sedans': 4454, 'Takata': 4455, 'local': 4456, 'gym': 4457, 'Campbell': 4458, 'dioxide': 4459, 'Vice': 4460, 'nominated': 4461, 'Warren': 4462, 'toward': 4463, 'Birdman': 4464, 'Mexican': 4465, 'Ceremony': 4466, 'Bit': 4467, 'Different': 4468, 'Information': 4469, 'Gisele': 4470, 'Brady': 4471, 'images': 4472, 'Garcia': 4473, 'magical': 4474, 'Profits': 4475, 'Apart': 4476, 'Halts': 4477, 'kill': 4478, 'Steady': 4479, 'Estimate': 4480, 'hikes': 4481, 'sexual': 4482, 'HIGHLIGHTS': 4483, 'announced': 4484, 'Comedian': 4485, 'Causes': 4486, 'Lavrov': 4487, 'Okay': 4488, 'Penney': 4489, 'Retailer': 4490, 'console': 4491, 'sufferers': 4492, 'emerging': 4493, '2008': 4494, 'Sanofi': 4495, 'shocking': 4496, 'woman': 4497, 'Plunging': 4498, 'epidemic': 4499, 'shake': 4500, 'bracelet': 4501, 'available': 4502, 'hero': 4503, 'Salesforce': 4504, 'Horrible': 4505, 'Trio': 4506, 'Improved': 4507, 'tweet': 4508, 'startup': 4509, 'mice': 4510, 'gorgeous': 4511, 'semi': 4512, 'sheer': 4513, 'care': 4514, 'dad': 4515, 'retreat': 4516, 'Incredibles': 4517, 'Pipeline': 4518, 'Continue': 4519, 'Hands': 4520, 'things': 4521, '150': 4522, 'reviews': 4523, 'ground': 4524, 'beef': 4525, 'Committee': 4526, 'subscribers': 4527, 'named': 4528, 'Stand': 4529, 'Wearing': 4530, 'DAB': 4531, 'f': 4532, 'ing': 4533, 'bomb': 4534, 'cbank': 4535, 'Become': 4536, 'Adobe': 4537, 'Projected': 4538, 'Stunt': 4539, 'Honours': 4540, 'Semitic': 4541, 'Honey': 4542, 'Neill': 4543, 'divestitures': 4544, 'Pooch': 4545, 'regulators': 4546, 'shot': 4547, 'de': 4548, 'appear': 4549, 'Bills': 4550, 'Counter': 4551, 'MS': 4552, 'managers': 4553, 'bit': 4554, 'NJ': 4555, 'Held': 4556, 'serves': 4557, 'Shield': 4558, 'Brand': 4559, 'Few': 4560, 'Consider': 4561, 'wasn': 4562, 'cyber': 4563, 'Performs': 4564, 'Ballroom': 4565, 'Shower': 4566, 'once': 4567, 'Tequila': 4568, 'pollution': 4569, 'apologises': 4570, 'poster': 4571, 'Ninja': 4572, 'Turtles': 4573, 'Tencent': 4574, 'Symantec': 4575, 'Victim': 4576, 'Lure': 4577, 'Petco': 4578, 'Treats': 4579, 'Dai': 4580, 'magazine': 4581, 'Firms': 4582, 'Building': 4583, 'Drones': 4584, 'Dreamliner': 4585, 'Settles': 4586, 'bottom': 4587, 'Zaki': 4588, 'wish': 4589, 'dinner': 4590, 'emerges': 4591, 'failing': 4592, 'reach': 4593, 'plants': 4594, 'Allergies': 4595, 'Questions': 4596, 'SingPost': 4597, 'Exxon': 4598, 'Fossil': 4599, 'Effect': 4600, 'Disputed': 4601, 'Cheapest': 4602, 'repair': 4603, 'Carrie': 4604, 'Skid': 4605, 'Amgen': 4606, 'Corp': 4607, 'Encana': 4608, 'Assets': 4609, 'Center': 4610, 'Studies': 4611, 'hires': 4612, 'avert': 4613, 'forgotten': 4614, 'parts': 4615, 'recent': 4616, 'React': 4617, 'BIS': 4618, 'history': 4619, 'Bangerz': 4620, 'Curb': 4621, 'slams': 4622, 'Activists': 4623, 'Berry': 4624, 'Character': 4625, 'Royce': 4626, 'Danielle': 4627, 'Bug': 4628, 'Spotted': 4629, 'homeless': 4630, 'loses': 4631, 'Sharp': 4632, 'Stalker': 4633, 'Through': 4634, 'Ups': 4635, 'Attention': 4636, 'duties': 4637, 'Healthy': 4638, 'Brody': 4639, 'reaction': 4640, '3000': 4641, 'weds': 4642, 'Molner': 4643, 'building': 4644, 'denim': 4645, 'Attacks': 4646, 'AAA': 4647, 'raising': 4648, 'Tensions': 4649, 'current': 4650, 'affair': 4651, 'Ill': 4652, 'retailers': 4653, 'statement': 4654, 'Jem': 4655, 'Holograms': 4656, 'blue': 4657, 'trucks': 4658, 'problem': 4659, 'Robbery': 4660, 'Telefonica': 4661, 'suspends': 4662, 'Situation': 4663, 'refused': 4664, 'driver': 4665, 'upgrade': 4666, 'Daum': 4667, 'Kakao': 4668, 'wait': 4669, 'Jokes': 4670, 'stem': 4671, 'Ease': 4672, 'Remove': 4673, 'revive': 4674, 'Piers': 4675, 'Airbnb': 4676, 'Sarandon': 4677, 'brave': 4678, 'Decades': 4679, 'threatened': 4680, 'animal': 4681, 'Gasoline': 4682, 'Organic': 4683, 'Discusses': 4684, 'Explodes': 4685, 'Happening': 4686, 'Cold': 4687, 'Needed': 4688, 'Spacey': 4689, 'OkCupid': 4690, 'Employment': 4691, '65': 4692, 'fiscal': 4693, 'points': 4694, 'throat': 4695, 'awarded': 4696, 'Finance': 4697, 'Neighbours': 4698, 'performs': 4699, 'evidence': 4700, 'Confirmed': 4701, 'Technologies': 4702, 'helicopter': 4703, 'Crossover': 4704, 'investigating': 4705, 'jailed': 4706, 'NSA': 4707, 'tang': 4708, 'kicks': 4709, 'Moments': 4710, 'steals': 4711, 'fixing': 4712, 'Hacked': 4713, 'Kicks': 4714, 'follow': 4715, 'naked': 4716, 'Keeping': 4717, 'Mazursky': 4718, 'ties': 4719, 'Intuit': 4720, 'Strange': 4721, 'Dutch': 4722, 'Allergic': 4723, 'Blame': 4724, 'Anne': 4725, 'actress': 4726, 'diamond': 4727, '96': 4728, 'Hello': 4729, 'Hires': 4730, 'prison': 4731, 'Management': 4732, 'ISS': 4733, 'Lobster': 4734, 'poised': 4735, 'gap': 4736, 'suicide': 4737, 'Nike': 4738, 'Enters': 4739, 'actors': 4740, 'delivery': 4741, 'Bangladesh': 4742, 'Adding': 4743, 'Trulia': 4744, '2006': 4745, 'Chasing': 4746, 'Inspiration': 4747, 'Rescuers': 4748, 'downed': 4749, 'planets': 4750, 'outfit': 4751, 'different': 4752, 'Whitey': 4753, 'Bulger': 4754, 'metal': 4755, 'Premier': 4756, 'Prepares': 4757, '47': 4758, 'defensive': 4759, 'subscription': 4760, 'Treated': 4761, 'Begin': 4762, 'dying': 4763, 'Believe': 4764, 'disappointed': 4765, 'selfies': 4766, 'Slips': 4767, 'welcome': 4768, 'College': 4769, 'Forever': 4770, 'corporations': 4771, 'NSFW': 4772, 'PHOTOS': 4773, 'Mobileye': 4774, 'portfolio': 4775, 'fuels': 4776, 'Talking': 4777, 'Books': 4778, 'knocks': 4779, 'Source': 4780, 'hundreds': 4781, 'defects': 4782, 'later': 4783, 'Rep': 4784, 'Widens': 4785, 'Bags': 4786, 'Brief': 4787, 'fastest': 4788, 'tiny': 4789, 'Hepatitis': 4790, 'TE': 4791, 'Connectivity': 4792, 'sensor': 4793, 'Quinta': 4794, 'beau': 4795, 'cyclicals': 4796, 'caps': 4797, 'Botox': 4798, 'Rental': 4799, 'Conference': 4800, 'strips': 4801, 'Allure': 4802, 'k': 4803, 'services': 4804, 'Designer': 4805, 'Democrats': 4806, 'hedge': 4807, 'Underground': 4808, 'Samuel': 4809, 'Feature': 4810, 'Finding': 4811, 'quick': 4812, 'gallon': 4813, 'Effects': 4814, 'phones': 4815, 'Pillinger': 4816, 'Faulty': 4817, 'Concerts': 4818, 'Rex': 4819, 'Smoke': 4820, 'Acquires': 4821, 'Flavors': 4822, 'Cargill': 4823, 'Employee': 4824, 'Stealing': 4825, 'Always': 4826, 'Dressed': 4827, 'Gareth': 4828, 'strip': 4829, 'Dotcom': 4830, 'dropped': 4831, 'Press': 4832, 'debuts': 4833, 'flagship': 4834, 'shirt': 4835, 'rehab': 4836, 'alongside': 4837, 'brighter': 4838, 'Efforts': 4839, 'Closes': 4840, 'Myers': 4841, 'Jesse': 4842, 'seven': 4843, 'clears': 4844, 'Discovered': 4845, 'Deep': 4846, 'Looking': 4847, 'Original': 4848, 'watching': 4849, 'Tomorrow': 4850, 'Allison': 4851, 'December': 4852, 'Battling': 4853, 'worried': 4854, '101': 4855, 'Momentum': 4856, 'chance': 4857, 'Mumps': 4858, 'Autos': 4859, 'Bar': 4860, 'LOOK': 4861, '50th': 4862, 'Countries': 4863, 'Sycamore': 4864, 'Express': 4865, 'center': 4866, 'Anchor': 4867, 'drone': 4868, 'MTA': 4869, 'currencies': 4870, 'Barack': 4871, 'Crew': 4872, 'spacecraft': 4873, 'injured': 4874, 'Exclusive': 4875, 'Effort': 4876, 'bumper': 4877, 'Cancel': 4878, 'Saw': 4879, 'Sleep': 4880, 'Palme': 4881, 'Leno': 4882, 'Retiring': 4883, 'Part': 4884, 'falters': 4885, 'runs': 4886, 'offsets': 4887, 'Wanna': 4888, 'premiums': 4889, 'damages': 4890, 'let': 4891, 'fear': 4892, '20000': 4893, 'twist': 4894, 'Improving': 4895, 'Rebound': 4896, 'IRS': 4897, 'commodity': 4898, 'Overhaul': 4899, 'Road': 4900, 'Guidance': 4901, 'BAT': 4902, 'Lorillard': 4903, 'Mansion': 4904, 'Plays': 4905, 'Exodus': 4906, 'Sitcom': 4907, 'lands': 4908, 'Edie': 4909, 'Brickell': 4910, 'Commission': 4911, 'Romance': 4912, 'Shines': 4913, 'Laura': 4914, 'Pimco': 4915, 'Beach': 4916, 'Theatre': 4917, 'Hot': 4918, 'Lisa': 4919, 'aside': 4920, 'Apologizes': 4921, 'Studio': 4922, 'Lyrics': 4923, '69': 4924, 'Saves': 4925, 'default': 4926, 'Resumes': 4927, 'Conduct': 4928, '5th': 4929, 'Idris': 4930, 'Elba': 4931, 'Frank': 4932, 'Apache': 4933, 'Chevron': 4934, 'original': 4935, 'watchdog': 4936, 'Customer': 4937, 'Royal': 4938, 'protection': 4939, 'Nas': 4940, 'Stover': 4941, 'Lindt': 4942, 'airlines': 4943, 'signal': 4944, 'makers': 4945, 'Alter': 4946, 'Quest': 4947, 'actions': 4948, 'Francisco': 4949, 'parties': 4950, 'pledge': 4951, 'Eagle': 4952, 'Widow': 4953, 'Puff': 4954, 'lights': 4955, 'fights': 4956, 'Political': 4957, 'Proposed': 4958, 'Appeals': 4959, 'Billions': 4960, 'enters': 4961, 'uncertainty': 4962, 'Arthur': 4963, 'cell': 4964, 'Holdings': 4965, 'SiriusXM': 4966, 'Bionic': 4967, 'deGrasse': 4968, 'Plead': 4969, 'Member': 4970, 'Producers': 4971, 'Brunei': 4972, 'Poll': 4973, 'Ten': 4974, 'EYE': 4975, 'feed': 4976, 'Neeson': 4977, 'Andre': 4978, 'Corporation': 4979, 'Lachey': 4980, 'computer': 4981, 'Bus': 4982, 'Grab': 4983, 'Paying': 4984, 'Predictions': 4985, 'bidders': 4986, 'Targets': 4987, 'Turnaround': 4988, 'Pobre': 4989, 'Breast': 4990, 'reported': 4991, 'overseas': 4992, 'summer': 4993, 'Lions': 4994, 'Perform': 4995, 'wk': 4996, 'Jennette': 4997, 'soybean': 4998, 'Lufthansa': 4999, 'Famous': 5000, 'Dads': 5001, 'Fathers': 5002, 'satellites': 5003, 'hearing': 5004, 'Wearhouse': 5005, 'Jos': 5006, 'buyout': 5007, 'hovers': 5008, 'note': 5009, 'changing': 5010, 'Follow': 5011, 'Mayo': 5012, 'OK': 5013, 'McLarty': 5014, 'Fonda': 5015, 'Tomlin': 5016, 'Muse': 5017, 'Bey': 5018, 'Later': 5019, 'Regulators': 5020, 'seat': 5021, 'challenges': 5022, 'Rallies': 5023, 'thing': 5024, 'Trims': 5025, 'Romania': 5026, 'Turned': 5027, 'Friend': 5028, 'Loach': 5029, 'Huntsman': 5030, 'flights': 5031, 'Exist': 5032, 'BeyoncÃ©': 5033, 'Playing': 5034, 'driven': 5035, 'agreement': 5036, 'Finish': 5037, 'García': 5038, 'Márquez': 5039, 'having': 5040, 'Farewell': 5041, 'Cools': 5042, 'Bed': 5043, 'Moonlight': 5044, 'System': 5045, 'blames': 5046, 'Bush': 5047, 'MORE': 5048, 'Dealers': 5049, 'incredible': 5050, 'Hillary': 5051, 'Toya': 5052, 'Wahlberg': 5053, 'Yellow': 5054, 'wed': 5055, 'lot': 5056, 'Ascending': 5057, 'side': 5058, 'VIEW': 5059, 'access': 5060, 'kick': 5061, 'Mockingjay': 5062, 'Titan': 5063, 'part': 5064, 'Novatek': 5065, 'Blocks': 5066, 'Person': 5067, 'iWatch': 5068, 'met': 5069, 'easy': 5070, 'site': 5071, 'painkiller': 5072, 'Glaxo': 5073, 'YOU': 5074, 'troops': 5075, 'Argument': 5076, 'inquiry': 5077, 'vulnerable': 5078, 'stress': 5079, 'dresses': 5080, 'Otis': 5081, 'Creates': 5082, 'Mayweather': 5083, 'Ethan': 5084, 'Hawke': 5085, 'Solution': 5086, 'Above': 5087, 'shooting': 5088, 'Accelerates': 5089, 'festival': 5090, 'YOUR': 5091, 'self': 5092, 'potential': 5093, 'Minnesota': 5094, 'patient': 5095, 'Alice': 5096, 'unions': 5097, 'shops': 5098, 'deposits': 5099, 'Welcomes': 5100, 'cameras': 5101, 'faced': 5102, 'printed': 5103, 'Lets': 5104, 'Sharing': 5105, 'Mulberry': 5106, 'Guillon': 5107, 'ANOTHER': 5108, 'Lew': 5109, 'Question': 5110, 'giving': 5111, 'Apparently': 5112, 'confronts': 5113, 'income': 5114, 'practices': 5115, 'Amaya': 5116, 'rep': 5117, 'engine': 5118, 'went': 5119, 'Selloff': 5120, 'Zuckerberg': 5121, 'Kurdish': 5122, 'NZ': 5123, 'Expands': 5124, 'beach': 5125, 'Kid': 5126, 'Walter': 5127, 'Sing': 5128, 'Landed': 5129, 'Hints': 5130, 'Pool': 5131, '2010': 5132, 'Midstream': 5133, 'options': 5134, 'Struggle': 5135, 'volume': 5136, 'us': 5137, 'cloud': 5138, 'singers': 5139, 'accounts': 5140, 'Activist': 5141, 'DETROIT': 5142, 'Weir': 5143, 'link': 5144, 'Chocolate': 5145, 'drinks': 5146, 'volcano': 5147, 'Silicon': 5148, 'Trouble': 5149, 'Spinoff': 5150, '55': 5151, 'moon': 5152, 'Door': 5153, '40': 5154, 'issued': 5155, 'refining': 5156, 'donnell': 5157, 'trend': 5158, 'gov': 5159, 'Website': 5160, 'divided': 5161, 'Katt': 5162, 'Vivendi': 5163, 'Creative': 5164, 'spokesman': 5165, 'Pulp': 5166, 'Fiction': 5167, 'Iwata': 5168, 'overheats': 5169, 'businesses': 5170, 'Estranged': 5171, 'goals': 5172, 'Survive': 5173, 'Surfaces': 5174, 'Driverless': 5175, 'Sounds': 5176, 'Recreational': 5177, 'Weed': 5178, 'S5': 5179, 'range': 5180, 'Hunts': 5181, 'success': 5182, 'cellphone': 5183, 'feature': 5184, 'Dempsey': 5185, 'story': 5186, 'image': 5187, 'Octopus': 5188, 'contact': 5189, 'lens': 5190, 'Senators': 5191, 'Surrender': 5192, 'Iron': 5193, 'truck': 5194, 'finalise': 5195, 'Telecom': 5196, 'smashes': 5197, 'Thai': 5198, 'Hanks': 5199, 'delay': 5200, 'Literally': 5201, 'aren': 5202, '33': 5203, 'stops': 5204, 'protests': 5205, '473': 5206, 'victim': 5207, 'account': 5208, 'Social': 5209, 'minute': 5210, 'Rupee': 5211, 'Reserve': 5212, 'Prompts': 5213, 'Cumia': 5214, 'Radio': 5215, 'headed': 5216, 'Garment': 5217, 'Allow': 5218, 'Hubble': 5219, 'telescope': 5220, 'took': 5221, 'Probes': 5222, 'Complaints': 5223, 'Acquisition': 5224, 'Minute': 5225, 'Plug': 5226, 'Deficit': 5227, 'Lover': 5228, 'worsens': 5229, 'tankan': 5230, 'Pioneer': 5231, 'Elisabeth': 5232, 'Hasselbeck': 5233, 'Alexa': 5234, 'Performing': 5235, 'Outkast': 5236, 'Messages': 5237, 'Remain': 5238, 'slammed': 5239, 'deletes': 5240, 'Player': 5241, 'appeals': 5242, 'Regulations': 5243, 'derriere': 5244, 'Wind': 5245, 'ebbs': 5246, '218000': 5247, 'Ancient': 5248, 'Dinosaur': 5249, 'Strip': 5250, 'Gleeson': 5251, 'postpones': 5252, 'Bunny': 5253, 'Galavis': 5254, 'Disick': 5255, 'barely': 5256, 'Eases': 5257, 'Forbes': 5258, 'Cure': 5259, 'Theft': 5260, 'Claiming': 5261, 'Skeptics': 5262, 'ceremony': 5263, 'smoke': 5264, 'Valerie': 5265, 'Harper': 5266, 'Proceed': 5267, 'insurers': 5268, 'Justices': 5269, 'GWAR': 5270, 'Overdose': 5271, 'extended': 5272, 'spreading': 5273, 'digital': 5274, 'lover': 5275, 'alone': 5276, 'east': 5277, 'places': 5278, 'frock': 5279, 'Teens': 5280, 'Flies': 5281, 'paedophile': 5282, 'Harder': 5283, 'Legend': 5284, 'O2': 5285, 'Pricey': 5286, 'Downgrades': 5287, 'Fought': 5288, 'clients': 5289, 'Purchases': 5290, 'Molestation': 5291, 'Whitney': 5292, 'shareholder': 5293, 'Misguided': 5294, 'Apps': 5295, 'Coldwater': 5296, 'Creek': 5297, 'NUMSA': 5298, 'wage': 5299, 'both': 5300, 'Virtual': 5301, 'Ordered': 5302, 'Payments': 5303, 'Armies': 5304, 'Wounded': 5305, 'stands': 5306, 'reason': 5307, 'midriff': 5308, 'marketing': 5309, 'provision': 5310, 'ALERT': 5311, 'flurry': 5312, 'financials': 5313, 'Lifts': 5314, 'Upton': 5315, 'happened': 5316, 'promise': 5317, 'buoy': 5318, 'Monroe': 5319, 'Rival': 5320, 'Recession': 5321, 'Allergy': 5322, 'Print': 5323, 'Skin': 5324, 'Communications': 5325, 'afterparty': 5326, 'Guinness': 5327, 'Pono': 5328, 'player': 5329, 'download': 5330, 'Burke': 5331, 'jitters': 5332, 'maternity': 5333, 'wear': 5334, 'updates': 5335, 'Excessive': 5336, 'Dimmed': 5337, 'Campaign': 5338, 'Left': 5339, 'Padma': 5340, 'Lakshmi': 5341, 'smartwatch': 5342, 'pulled': 5343, 'fit': 5344, 'Versace': 5345, 'romance': 5346, 'PayPal': 5347, 'Eye': 5348, 'Families': 5349, 'Passover': 5350, 'remove': 5351, 'stronger': 5352, 'Pollen': 5353, 'Villain': 5354, 'Doom': 5355, 'attends': 5356, 'candidate': 5357, 'lenders': 5358, 'Hacker': 5359, 'gig': 5360, 'targeted': 5361, 'apparent': 5362, 'Tension': 5363, 'Blonde': 5364, 'firmer': 5365, 'iconic': 5366, 'Insane': 5367, 'Fly': 5368, '80s': 5369, 'Kingfisher': 5370, 'hails': 5371, 'Jena': 5372, 'Irene': 5373, 'Walgreen': 5374, 'vaccine': 5375, 'finale': 5376, 'Hook': 5377, 'Ultron': 5378, 'Moody': 5379, 'Storms': 5380, 'Riding': 5381, 'Originals': 5382, 'rocks': 5383, 'Alitalia': 5384, 'Austria': 5385, 'Nia': 5386, 'DuPont': 5387, 'Threatened': 5388, 'Felony': 5389, 'franchise': 5390, 'baseball': 5391, 'pet': 5392, 'Liars': 5393, 'IDR': 5394, 'stroke': 5395, 'come': 5396, 'Changes': 5397, 'Newest': 5398, 'every': 5399, 'Controls': 5400, 'Donald': 5401, 'stumbles': 5402, 'Investments': 5403, 'brighten': 5404, 'rides': 5405, 'Pro': 5406, 'Independent': 5407, 'Struggling': 5408, 'turn': 5409, 'uncoupling': 5410, 'said': 5411, 'virgin': 5412, 'winning': 5413, 'Motherhood': 5414, 'Sheryl': 5415, 'banking': 5416, 'sketch': 5417, 'Tibetans': 5418, 'Un': 5419, 'quality': 5420, 'Orbiting': 5421, 'Dramatic': 5422, 'collide': 5423, 'anemic': 5424, 'chugs': 5425, 'Cruze': 5426, 'clothes': 5427, 'weakness': 5428, 'Twin': 5429, 'Richman': 5430, 'wows': 5431, 'complete': 5432, 'Hundreds': 5433, 'evacuated': 5434, 'researchers': 5435, 'rape': 5436, 'Chikungunya': 5437, 'Sleeping': 5438, 'Beauty': 5439, 'Wolverine': 5440, 'bed': 5441, 'Chapter': 5442, 'follows': 5443, 'Unexpected': 5444, 'Bundchen': 5445, 'Espirito': 5446, 'Santo': 5447, 'relaxed': 5448, 'Ciara': 5449, 'jab': 5450, 'Product': 5451, 'Stockpiles': 5452, 'Shrink': 5453, 'Buyers': 5454, 'scandal': 5455, 'Snub': 5456, 'footsteps': 5457, 'patients': 5458, 'Natural': 5459, 'Dolce': 5460, 'Gabbana': 5461, 'WWE': 5462, 'Universal': 5463, 'Myself': 5464, 'JC': 5465, 'Martha': 5466, 'Burberry': 5467, 'Loved': 5468, 'Symptoms': 5469, 'Connor': 5470, 'Eczema': 5471, 'Boyfriends': 5472, 'Defended': 5473, 'Wears': 5474, 'humans': 5475, 'lyrics': 5476, 'Cadillac': 5477, 'Greedy': 5478, 'speaks': 5479, 'Drought': 5480, 'Lesson': 5481, 'Grant': 5482, 'settles': 5483, 'deceptive': 5484, 'tears': 5485, 'Twins': 5486, 'Healthier': 5487, '777X': 5488, 'Lion': 5489, 'Tumbles': 5490, 'Breakfast': 5491, 'Tunnel': 5492, 'breakdown': 5493, 'meat': 5494, 'pounds': 5495, 'grow': 5496, 'Kroger': 5497, 'Vitacost': 5498, 'Drunk': 5499, 'catches': 5500, 'Chastain': 5501, 'sued': 5502, 'thousands': 5503, 'Nadine': 5504, 'Gordimer': 5505, 'Fischer': 5506, 'Whaling': 5507, 'emergency': 5508, 'Greatest': 5509, 'Allowed': 5510, 'outrageous': 5511, 'Li': 5512, 'Slowest': 5513, 'Feed': 5514, 'Watchdog': 5515, 'roughly': 5516, 'Scraps': 5517, 'Wake': 5518, 'couple': 5519, 'incident': 5520, 'surface': 5521, 'missile': 5522, 'Bike': 5523, 'Dozens': 5524, 'write': 5525, 'cable': 5526, 'midnight': 5527, 'Accuses': 5528, 'Bogus': 5529, 'Veep': 5530, 'ill': 5531, 'add': 5532, 'Cowell': 5533, 'Hint': 5534, 'Miners': 5535, 'Trapped': 5536, 'customer': 5537, 'advantage': 5538, 'fail': 5539, 'Elevator': 5540, 'Measures': 5541, 'McCreery': 5542, 'robbery': 5543, 'error': 5544, 'Bears': 5545, 'Paramount': 5546, 'Students': 5547, 'Directing': 5548, 'Kardashians': 5549, 'Hoax': 5550, 'discuss': 5551, 'PetSmart': 5552, 'ichi': 5553, 'Protective': 5554, 'flags': 5555, 'retreats': 5556, 'Happens': 5557, 'serious': 5558, 'Bally': 5559, 'Gaming': 5560, 'Rankings': 5561, 'Ikea': 5562, 'Progress': 5563, 'OKs': 5564, 'Marie': 5565, 'Recovers': 5566, '120': 5567, 'Greenpeace': 5568, 'Rig': 5569, 'slave': 5570, 'secures': 5571, 'option': 5572, 'doubts': 5573, 'Hasn': 5574, 'Connelly': 5575, 'quiet': 5576, 'Warned': 5577, 'Smashes': 5578, 'Faced': 5579, 'Ship': 5580, 'Cities': 5581, 'Ivan': 5582, 'Reitman': 5583, 'Patient': 5584, 'slowdown': 5585, 'Changing': 5586, 'Mayor': 5587, 'commerce': 5588, 'Unlikely': 5589, 'mastectomies': 5590, 'Dreyfus': 5591, 'renewed': 5592, 'fourth': 5593, 'Holder': 5594, 'Dem': 5595, 'Seas': 5596, 'Qualcomm': 5597, '53': 5598, 'Rejects': 5599, 'recommends': 5600, 'vials': 5601, 'Prepare': 5602, 'binding': 5603, 'Ragu': 5604, 'Warm': 5605, 'blooded': 5606, 'Dinosaurs': 5607, 'human': 5608, 'Reforms': 5609, 'BNY': 5610, 'TPG': 5611, 'Prays': 5612, 'tough': 5613, 'yield': 5614, 'Taiwan': 5615, 'improve': 5616, 'networks': 5617, 'requests': 5618, 'annex': 5619, 'Clean': 5620, 'Hashtag': 5621, 'Rosemary': 5622, 'Zoe': 5623, 'Saldana': 5624, 'Declared': 5625, 'Hop': 5626, 'alert': 5627, 'Alamo': 5628, 'Lionel': 5629, 'Richie': 5630, 'Coyne': 5631, 'Sally': 5632, 'Armstrong': 5633, 'Objections': 5634, 'Trademark': 5635, 'Wicked': 5636, 'Cleary': 5637, 'message': 5638, 'Wheel': 5639, 'designed': 5640, 'Lululemon': 5641, 'turning': 5642, 'Rosneft': 5643, 'ride': 5644, 'effective': 5645, 'N': 5646, 'Word': 5647, 'Salomon': 5648, 'indicted': 5649, 'Department': 5650, 'McKellar': 5651, 'splits': 5652, 'Dreadful': 5653, 'recoups': 5654, 'Mideast': 5655, 'robotic': 5656, 'draws': 5657, 'Attend': 5658, 'Subsidy': 5659, 'Halt': 5660, 'improves': 5661, 'Spills': 5662, 'gushes': 5663, 'Vanessa': 5664, 'elegant': 5665, 'hasn': 5666, 'Signal': 5667, 'Trillion': 5668, 'Alliance': 5669, 'Boots': 5670, 'normal': 5671, 'Narrows': 5672, 'Swing': 5673, 'Degeneres': 5674, '–': 5675, 'Impacts': 5676, 'fitness': 5677, 'longer': 5678, 'monster': 5679, 'Generation': 5680, 'Main': 5681, 'Tool': 5682, 'federal': 5683, 'Mersch': 5684, 'fast': 5685, 'listing': 5686, 'cradles': 5687, 'Miscarriage': 5688, 'annualized': 5689, 'edging': 5690, 'button': 5691, 'Attempted': 5692, 'Whiting': 5693, 'Sorrentino': 5694, 'prove': 5695, 'Feb': 5696, 'Esposito': 5697, 'proud': 5698, 'increases': 5699, 'Equities': 5700, 'Moss': 5701, 'lockout': 5702, 'Oz': 5703, 'Hosts': 5704, 'Lunch': 5705, 'Marathon': 5706, 'Hess': 5707, 'producers': 5708, 'outing': 5709, 'Gender': 5710, 'Criticism': 5711, 'Kristin': 5712, 'Cavallari': 5713, 'Cutler': 5714, 'art': 5715, 'iPads': 5716, 'Luxottica': 5717, 'McConaughey': 5718, 'Beer': 5719, 'Tear': 5720, 'Popular': 5721, 'Y': 5722, 'Herself': 5723, 'lag': 5724, 'Denzel': 5725, 'Jazz': 5726, 'Went': 5727, 'Worse': 5728, 'Cooperation': 5729, 'Tokyo': 5730, 'PMIs': 5731, 'Winston': 5732, 'experiencing': 5733, 'threatens': 5734, 'trip': 5735, 'Purchase': 5736, 'Square': 5737, 'Halston': 5738, 'Sage': 5739, 'unlikely': 5740, 'Trends': 5741, 'withdrawal': 5742, 'unacceptable': 5743, 'Integrys': 5744, 'edgy': 5745, 'United': 5746, 'Sikorsky': 5747, 'staff': 5748, 'ticks': 5749, 'Lashes': 5750, 'Sbarro': 5751, 'Missed': 5752, 'Colfer': 5753, 'mansion': 5754, 'creditor': 5755, 'brand': 5756, 'fossil': 5757, 'classic': 5758, 'lines': 5759, 'Balance': 5760, 'drivers': 5761, 'invade': 5762, 'Coulier': 5763, 'NLRB': 5764, 'DEALTALK': 5765, 'Reaction': 5766, 'Sweeney': 5767, 'Phones': 5768, 'screen': 5769, 'tale': 5770, 'Orbital': 5771, 'divesting': 5772, 'sports': 5773, 'CK': 5774, 'Playstation': 5775, 'virtual': 5776, 'Prevention': 5777, 'Godfather': 5778, 'Racism': 5779, 'boat': 5780, 'Anger': 5781, 'Pleading': 5782, 'Astronauts': 5783, 'Illness': 5784, 'Darden': 5785, 'trim': 5786, 'rewrite': 5787, 'Paetz': 5788, 'sending': 5789, 'standing': 5790, 'Smoking': 5791, 'Inequality': 5792, 'CP': 5793, 'cheer': 5794, 'inventory': 5795, 'Spur': 5796, 'Kiss': 5797, 'force': 5798, '106': 5799, 'Experts': 5800, 'Fraud': 5801, 'Hopes': 5802, 'Gallbladder': 5803, 'URGENT': 5804, 'Pose': 5805, 'nuptials': 5806, 'Benedict': 5807, 'Cumberbatch': 5808, 'cigarette': 5809, 'reckless': 5810, 'Lay': 5811, 'Raised': 5812, 'Jeep': 5813, 'transforms': 5814, 'Slammed': 5815, 'Cook': 5816, 'turmoil': 5817, 'Created': 5818, 'Sector': 5819, 'owns': 5820, 'Hat': 5821, 'ear': 5822, 'ISM': 5823, 'circus': 5824, 'Having': 5825, 'Takeda': 5826, 'jury': 5827, 'award': 5828, 'Actos': 5829, 'poison': 5830, 'management': 5831, 'user': 5832, 'design': 5833, 'Storm': 5834, 'Shuts': 5835, 'bureau': 5836, 'Vincent': 5837, 'Gogh': 5838, 'Cameras': 5839, 'Guardianship': 5840, 'Seized': 5841, 'witness': 5842, 'Emily': 5843, 'Horror': 5844, 'enjoys': 5845, 'bounce': 5846, 'Ricci': 5847, 'wealth': 5848, 'Pride': 5849, 'comment': 5850, 'Related': 5851, '74': 5852, 'tributes': 5853, 'Someone': 5854, 'jewelry': 5855, 'Barbra': 5856, 'Streisand': 5857, 'Kramer': 5858, 'Liza': 5859, 'Minnelli': 5860, 'pot': 5861, 'Dealer': 5862, 'keen': 5863, 'Goodbye': 5864, 'Gave': 5865, 'college': 5866, 'OKCupid': 5867, 'upholds': 5868, 'Infected': 5869, 'Pills': 5870, 'Wiz': 5871, 'Khalifa': 5872, 'Homeland': 5873, 'crowded': 5874, 'comic': 5875, 'showing': 5876, 'Loeb': 5877, 'bash': 5878, 'Rangers': 5879, 'Dove': 5880, 'Solve': 5881, 'suggests': 5882, 'Wynn': 5883, 'hole': 5884, 'Whilst': 5885, 'Joined': 5886, 'Holdouts': 5887, 'holiday': 5888, 'Charlize': 5889, 'Theron': 5890, 'Inspired': 5891, 'rest': 5892, 'Lo': 5893, 'Cheap': 5894, 'Couple': 5895, 'Jenna': 5896, 'Dewan': 5897, 'Tragic': 5898, 'Apologizing': 5899, 'Hospitalised': 5900, 'Rescue': 5901, 'Dot': 5902, 'Scary': 5903, 'underwriter': 5904, 'Coppola': 5905, 'Dangerous': 5906, 'Uneven': 5907, 'Tank': 5908, '650': 5909, 'Macquarie': 5910, 'Thank': 5911, 'defending': 5912, 'Slur': 5913, 'Saga': 5914, 'Sam': 5915, '97': 5916, 'ADM': 5917, 'Salute': 5918, 'Beastie': 5919, 'shipments': 5920, 'Poster': 5921, 'RWE': 5922, 'footage': 5923, 'Fury': 5924, 'FiancÃ©': 5925, 'shines': 5926, 'Mtv': 5927, 'Dakota': 5928, 'skinny': 5929, 'Robot': 5930, 'presses': 5931, 'Extreme': 5932, 'Saint': 5933, 'Prom': 5934, 'resumes': 5935, 'location': 5936, 'Partner': 5937, 'XSCAPE': 5938, 'Pilots': 5939, 'Tang': 5940, 'striped': 5941, 'Loves': 5942, 'urged': 5943, 'think': 5944, 'fines': 5945, 'Zynga': 5946, 'Lures': 5947, 'pinned': 5948, 'Hurts': 5949, 'Collaboration': 5950, 'Remainder': 5951, 'University': 5952, 'Restores': 5953, 'Links': 5954, 'plus': 5955, 'fatal': 5956, 'Outfitters': 5957, 'shifts': 5958, 'cells': 5959, 'Stalls': 5960, 'Mayhew': 5961, 'Tweeting': 5962, 'expect': 5963, 'Honeywell': 5964, 'Shrinking': 5965, 'Console': 5966, 'robot': 5967, 'Spat': 5968, 'Helped': 5969, 'followed': 5970, 'extreme': 5971, 'mode': 5972, 'Ads': 5973, 'wide': 5974, '99': 5975, 'Shrinks': 5976, 'becomes': 5977, 'Obese': 5978, 'obesity': 5979, 'Bra': 5980, 'CFDA': 5981, 'Suing': 5982, 'Megaupload': 5983, 'wipe': 5984, 'Actors': 5985, 'Construction': 5986, 'Neutral': 5987, 'Exactly': 5988, 'fighting': 5989, 'odds': 5990, '89': 5991, 'guide': 5992, 'celebrating': 5993, 'anniversary': 5994, 'Shipping': 5995, 'frontman': 5996, 'AKA': 5997, 'Driven': 5998, 'Sovaldi': 5999, 'Stability': 6000, 'Attempts': 6001, 'Took': 6002, 'Racy': 6003, 'Xscape': 6004, 'Room': 6005, 'proposing': 6006, 'Braff': 6007, 'Garden': 6008, 'ticket': 6009, 'Paulson': 6010, 'Lunar': 6011, 'Eclipse': 6012, 'information': 6013, 'rebel': 6014, 'Dudley': 6015, 'cycle': 6016, 'Century': 6017, 'Willis': 6018, 'topless': 6019, 'handset': 6020, 'Dame': 6021, 'strategic': 6022, 'Cervical': 6023, 'Testifies': 6024, 'Involved': 6025, 'Trek': 6026, 'Born': 6027, 'Calling': 6028, 'HR': 6029, 'Giger': 6030, 'Fill': 6031, 'distance': 6032, 'worry': 6033, 'swaps': 6034, 'international': 6035, 'crime': 6036, 'Harley': 6037, 'Race': 6038, 'cryptic': 6039, 'spends': 6040, 'Adult': 6041, 'Mustang': 6042, 'features': 6043, 'Patricia': 6044, 'Mario': 6045, 'Biotech': 6046, 'Amidst': 6047, 'Rural': 6048, 'McVie': 6049, 'Fleetwood': 6050, 'Honor': 6051, 'hammer': 6052, 'Reynolds': 6053, 'HUGE': 6054, 'Lenovo': 6055, 'Intellectual': 6056, 'Iranian': 6057, 'Casts': 6058, 'pilot': 6059, 'Resigns': 6060, 'certain': 6061, 'Pitch': 6062, 'Doubt': 6063, 'Barbie': 6064, 'Decide': 6065, 'Airplanes': 6066, 'broadly': 6067, 'enlists': 6068, 'carrier': 6069, 'Prepon': 6070, 'Drivers': 6071, 'traffic': 6072, 'Bergdahl': 6073, 'Dom': 6074, 'Glencore': 6075, 'passes': 6076, 'Session': 6077, 'unsettled': 6078, 'outrage': 6079, 'KPN': 6080, 'Prison': 6081, 'Distraction': 6082, 'Gross': 6083, 'Obsessed': 6084, 'Lombardi': 6085, 'OpenTable': 6086, 'Priceline': 6087, 'Putting': 6088, 'blocks': 6089, 'Solid': 6090, 'foothold': 6091, 'Harvard': 6092, 'Insurance': 6093, 'Coffee': 6094, 'Stakes': 6095, 'Managers': 6096, 'Dismisses': 6097, 'Income': 6098, 'Leak': 6099, 'Clone': 6100, 'Plunge': 6101, 'Expires': 6102, 'Yourself': 6103, 'Performers': 6104, 'sneak': 6105, 'peek': 6106, 'ALS': 6107, 'Cannot': 6108, 'Waste': 6109, 'grabs': 6110, 'Unveil': 6111, 'consider': 6112, 'crazy': 6113, 'Treat': 6114, 'hand': 6115, 'saved': 6116, 'removes': 6117, 'am': 6118, 'Fluctuate': 6119, 'ask': 6120, 'SanDisk': 6121, 'Fusion': 6122, 'io': 6123, 'anchor': 6124, 'Dates': 6125, 'draft': 6126, 'Lawsuits': 6127, 'lion': 6128, 'politics': 6129, 'weakens': 6130, 'Abercrombie': 6131, 'Arctic': 6132, 'rig': 6133, 'Protein': 6134, 'Travolta': 6135, 'revealing': 6136, 'November': 6137, 'Freedom': 6138, 'Diabetics': 6139, 'Pancreas': 6140, 'Cosmos': 6141, 'Departure': 6142, 'Mortgages': 6143, 'Timeline': 6144, 'Confronts': 6145, 'Dilemma': 6146, 'Wheeler': 6147, 'prospects': 6148, 'cheaper': 6149, 'lied': 6150, 'speeds': 6151, 'Southwest': 6152, 'Welfare': 6153, 'Picket': 6154, 'Plants': 6155, 'employee': 6156, 'penis': 6157, 'Grown': 6158, 'Dropped': 6159, 'dividend': 6160, 'buyback': 6161, 'attendant': 6162, 'Beijing': 6163, 'Commerce': 6164, 'Bankers': 6165, 'Update': 6166, 'Asked': 6167, 'Utilities': 6168, 'debate': 6169, 'Winds': 6170, 'Weidmann': 6171, 'Duty': 6172, 'Baldwin': 6173, 'Elton': 6174, 'Furnish': 6175, 'Gowex': 6176, 'hunt': 6177, 'Supposedly': 6178, 'conducting': 6179, 'rover': 6180, 'Fines': 6181, '111': 6182, 'Releasing': 6183, 'Absolutely': 6184, 'Films': 6185, 'Deliver': 6186, 'difference': 6187, 'tool': 6188, 'core': 6189, 'Oklahoma': 6190, 'Poet': 6191, 'addiction': 6192, 'Mulally': 6193, 'Albums': 6194, '2018': 6195, 'increased': 6196, 'large': 6197, 'remake': 6198, 'biotechs': 6199, 'homes': 6200, 'Voted': 6201, 'parrot': 6202, 'Con': 6203, 'justices': 6204, 'Duane': 6205, 'Reade': 6206, 'Boyle': 6207, 'Renewed': 6208, 'Uk': 6209, 'Success': 6210, 'Competitive': 6211, 'Cryptic': 6212, 'Sia': 6213, 'Lack': 6214, 'round': 6215, 'Strait': 6216, 'Carry': 6217, 'Nickelodeon': 6218, 'clarifies': 6219, 'processed': 6220, 'drillers': 6221, 'versus': 6222, 'governor': 6223, 'Reform': 6224, 'Across': 6225, 'embarks': 6226, '28th': 6227, 'Zara': 6228, 'affirms': 6229, 'Chanel': 6230, 'skips': 6231, 'Manipulation': 6232, 'Gmail': 6233, 'investments': 6234, 'anything': 6235, 'Kills': 6236, 'tepid': 6237, 'INSIGHT': 6238, 'introduce': 6239, 'NYSE': 6240, 'releases': 6241, 'NAB': 6242, 'diners': 6243, 'Surprised': 6244, 'Windows': 6245, 'Excited': 6246, 'Kristeen': 6247, 'Also': 6248, 'Beard': 6249, 'Viral': 6250, 'SIX': 6251, 'Slip': 6252, 'Fifth': 6253, 'Surprises': 6254, 'corporate': 6255, 'sun': 6256, 'Taxis': 6257, 'Victoria': 6258, 'Beckham': 6259, 'pole': 6260, 'Int': 6261, 'l': 6262, 'Videos': 6263, 'Current': 6264, 'Foxx': 6265, 'Roles': 6266, 'Blast': 6267, 'Older': 6268, 'Chat': 6269, 'Joffrey': 6270, 'solve': 6271, 'twice': 6272, 'Arcade': 6273, 'Cat': 6274, 'Probed': 6275, 'declines': 6276, 'Wed': 6277, 'Clown': 6278, 'purchase': 6279, 'non': 6280, 'deficit': 6281, 'fin': 6282, 'min': 6283, 'defective': 6284, 'glittering': 6285, 'silver': 6286, 'Rumored': 6287, 'added': 6288, 'Screens': 6289, 'Asteroid': 6290, 'Mosquitoes': 6291, 'Revamp': 6292, 'Hack': 6293, 'Savage': 6294, 'Supports': 6295, 'ago': 6296, 'CO2': 6297, 'jacket': 6298, 'Executives': 6299, 'Average': 6300, 'Politics': 6301, 'nominations': 6302, 'Critic': 6303, 'FOCUS': 6304, 'hawkish': 6305, 'Malfunction': 6306, 'spent': 6307, 'devastating': 6308, 'postponed': 6309, 'EasyJet': 6310, 'McChrystal': 6311, 'expectancy': 6312, 'Sheer': 6313, 'Alaska': 6314, 'Greater': 6315, 'helping': 6316, 'unchanged': 6317, 'Forgotten': 6318, 'Alli': 6319, 'Lineup': 6320, 'Banker': 6321, 'Gifts': 6322, 'taken': 6323, 'Aerospace': 6324, 'pledges': 6325, 'downing': 6326, 'Pact': 6327, 'Sending': 6328, 'average': 6329, 'Outrage': 6330, 'teenage': 6331, 'Abe': 6332, 'suspended': 6333, 'Exposure': 6334, 'battling': 6335, 'Reuters': 6336, 'Alarm': 6337, 'Flops': 6338, 'Highs': 6339, 'Yacht': 6340, 'Spend': 6341, 'Chaos': 6342, 'Feel': 6343, 'sought': 6344, 'AG': 6345, 'Surging': 6346, 'zero': 6347, 'Complain': 6348, '1999': 6349, 'internet': 6350, 'crashed': 6351, 'Branson': 6352, 'Boycott': 6353, 'Aquaman': 6354, 'extortion': 6355, 'Roundup': 6356, 'peace': 6357, 'engaged': 6358, 'arrive': 6359, 'Courteney': 6360, 'scheme': 6361, 'Saying': 6362, 'Robbed': 6363, 'purchases': 6364, 'character': 6365, 'periphery': 6366, 'Hogs': 6367, 'closing': 6368, 'rich': 6369, 'Ally': 6370, 'Westboro': 6371, 'Baptist': 6372, 'alien': 6373, 'LAX': 6374, 'bombshell': 6375, 'Wikipedia': 6376, 'Hathaway': 6377, 'blast': 6378, 'Note': 6379, 'fly': 6380, 'opener': 6381, 'Mint': 6382, 'Gunpoint': 6383, 'Happened': 6384, 'words': 6385, 'structure': 6386, 'web': 6387, 'Pass': 6388, 'Entire': 6389, 'Units': 6390, 'Boosted': 6391, 'Flying': 6392, 'Camaros': 6393, 'deepens': 6394, 'Richest': 6395, 'Pitches': 6396, 'Lowers': 6397, 'controversy': 6398, 'ALL': 6399, 'mum': 6400, 'Then': 6401, 'Consumers': 6402, 'tick': 6403, 'Filing': 6404, 'Angus': 6405, 'lawyer': 6406, 'Scania': 6407, 'Aviation': 6408, 'Vaccine': 6409, 'worse': 6410, 'supports': 6411, 'Sink': 6412, 'stunning': 6413, 'single': 6414, 'Upgrades': 6415, 'curbs': 6416, 'Atlantic': 6417, 'Ago': 6418, 'Wheelan': 6419, 'troubled': 6420, 'cholesterol': 6421, 'tablets': 6422, 'nurses': 6423, 'Pinterest': 6424, 'Valued': 6425, 'Mixtape': 6426, 'Regrets': 6427, 'among': 6428, 'Thornton': 6429, 'authority': 6430, 'Budget': 6431, 'hiring': 6432, 'Preparing': 6433, 'domestic': 6434, 'Objects': 6435, 'Duck': 6436, 'Minister': 6437, 'doctor': 6438, 'autism': 6439, 'Mayors': 6440, 'Leaders': 6441, 'taxes': 6442, 'Reduces': 6443, 'paves': 6444, 'JJ': 6445, 'Falcon': 6446, 'challenging': 6447, 'Headed': 6448, 'bear': 6449, 'Merck': 6450, 'rethink': 6451, 'Lift': 6452, 'Warn': 6453, 'Airport': 6454, 'Singapore': 6455, 'Passwords': 6456, 'sperm': 6457, 'Nephew': 6458, 'censorship': 6459, 'recover': 6460, 'Daniels': 6461, 'appears': 6462, 'starring': 6463, 'inspections': 6464, 'Mia': 6465, 'believes': 6466, 'Settings': 6467, 'flow': 6468, 'Disturbing': 6469, 'Via': 6470, '2016': 6471, 'Numericable': 6472, 'AKB48': 6473, 'budget': 6474, 'Meryl': 6475, 'Cries': 6476, 'Inner': 6477, 'Lip': 6478, 'Proposal': 6479, 'forces': 6480, 'spotted': 6481, 'Henry': 6482, 'Cavill': 6483, 'Festivals': 6484, 'String': 6485, 'standoff': 6486, 'Blow': 6487, 'Compares': 6488, 'Gilts': 6489, 'Im': 6490, 'Mason': 6491, 'stuns': 6492, 'Kepler': 6493, 'ICE': 6494, 'Iraqi': 6495, 'checks': 6496, 'beauty': 6497, 'monitored': 6498, 'Economies': 6499, 'Inch': 6500, 'sultry': 6501, 'Rowe': 6502, 'sue': 6503, 'Drive': 6504, 'Usher': 6505, 'fever': 6506, 'loyal': 6507, 'Soul': 6508, 'cities': 6509, 'flows': 6510, 'hotel': 6511, '16000': 6512, 'Landing': 6513, 'celebrities': 6514, 'dreams': 6515, 'boycott': 6516, 'Cross': 6517, 'glass': 6518, 'Expand': 6519, 'growing': 6520, 'VMware': 6521, 'RACHEL': 6522, 'JOHNSON': 6523, 'Crystal': 6524, 'learns': 6525, 'mergers': 6526, 'Wyoming': 6527, 'judges': 6528, 'Approaches': 6529, 'strongly': 6530, 'shrink': 6531, 'Beginning': 6532, 'fun': 6533, 'Kendra': 6534, 'Wilkinson': 6535, 'Hank': 6536, 'struggling': 6537, 'true': 6538, 'Hitting': 6539, 'ripples': 6540, 'crew': 6541, 'allergy': 6542, 'Wear': 6543, 'tights': 6544, 'Discovery': 6545, 'Civil': 6546, 'fiber': 6547, 'Deliveries': 6548, 'rumoured': 6549, 'racism': 6550, 'visit': 6551, 'Doubles': 6552, 'Directors': 6553, 'crushed': 6554, 'finance': 6555, 'warrant': 6556, 'SEALs': 6557, 'ordered': 6558, 'Berkshire': 6559, 'beating': 6560, 'b': 6561, 'Bunch': 6562, 'Ended': 6563, '1950s': 6564, 'storm': 6565, 'Shepard': 6566, 'interview': 6567, 'Disruption': 6568, 'projects': 6569, 'Expectations': 6570, 'Triumphs': 6571, 'Touch': 6572, 'Sky': 6573, 'Reserves': 6574, 'dirty': 6575, 'Pal': 6576, 'MILLION': 6577, 'beer': 6578, 'loom': 6579, 'Antonoff': 6580, 'Damp': 6581, 'Eve': 6582, 'wages': 6583, 'Rubik': 6584, 'Adviser': 6585, 'HK': 6586, 'Flick': 6587, 'Chemical': 6588, 'Stark': 6589, 'strikers': 6590, 'Kaley': 6591, 'Cuoco': 6592, 'BSkyB': 6593, 'retire': 6594, 'advise': 6595, 'MP': 6596, 'transparency': 6597, 'Bacteria': 6598, 'Epic': 6599, 'Astronomers': 6600, 'Discover': 6601, 'nods': 6602, 'Gear': 6603, 'Clothes': 6604, 'Downtown': 6605, 'Cheerleader': 6606, 'partial': 6607, 'Hawking': 6608, 'grown': 6609, 'JK': 6610, 'ET': 6611, 'Atari': 6612, 'Narrator': 6613, 'IAC': 6614, 'also': 6615, 'receive': 6616, 'Icon': 6617, 'Lenses': 6618, 'Tame': 6619, 'Eni': 6620, 'Propose': 6621, 'Per': 6622, 'Gallon': 6623, 'stainless': 6624, 'pauses': 6625, 'strongest': 6626, 'asteroid': 6627, 'Promotion': 6628, 'movement': 6629, 'Grandfather': 6630, 'Hologram': 6631, 'Theme': 6632, 'RLPC': 6633, 'filing': 6634, 'riots': 6635, 'evacuates': 6636, 'Rocks': 6637, 'Hurdles': 6638, 'Technical': 6639, 'Failures': 6640, 'Fades': 6641, 'everywhere': 6642, 'Kept': 6643, 'shared': 6644, 'Event': 6645, 'pings': 6646, 'wash': 6647, 'chicken': 6648, 'Creepy': 6649, 'pulling': 6650, 'mark': 6651, 'pursues': 6652, 'Slam': 6653, 'Practices': 6654, 'Protecting': 6655, 'hip': 6656, 'Researcher': 6657, 'shouldn': 6658, 'Reactions': 6659, 'attend': 6660, 'mocked': 6661, 'program': 6662, 'Unfair': 6663, 'Mintz': 6664, 'Hough': 6665, 'Sookie': 6666, 'exploiting': 6667, 'Marshall': 6668, 'Deadline': 6669, 'Startups': 6670, 'Covering': 6671, 'Pulls': 6672, 'simple': 6673, 'Blackberry': 6674, 'Privilege': 6675, 'contracts': 6676, 'hugging': 6677, 'Cocaine': 6678, 'threats': 6679, 'Mourn': 6680, 'Tracks': 6681, 'Utah': 6682, 'grapples': 6683, 'Rockwood': 6684, 'Ghasemi': 6685, 'Worked': 6686, 'Pin': 6687, 'Yeager': 6688, 'shots': 6689, 'Bettie': 6690, 'Al': 6691, 'cite': 6692, 'thin': 6693, 'strokes': 6694, 'Penelope': 6695, 'Eyewear': 6696, 'Dui': 6697, 'Unchanged': 6698, 'sexism': 6699, 'sweeps': 6700, 'MONTGOMERY': 6701, 'Ala': 6702, 'Grew': 6703, 'Lesbian': 6704, 'costly': 6705, 'Explosion': 6706, 'Rocket': 6707, 'Autopsy': 6708, 'Frontman': 6709, 'restraining': 6710, 'extending': 6711, 'Stunned': 6712, 'Biden': 6713, 'Candid': 6714, 'ballet': 6715, 'dancer': 6716, 'streets': 6717, 'Both': 6718, 'Urinate': 6719, 'Western': 6720, 'Wrongful': 6721, 'svelte': 6722, 'floral': 6723, 'Texting': 6724, 'Jets': 6725, 'Racial': 6726, 'drugging': 6727, 'raping': 6728, 'HARRIS': 6729, 'administration': 6730, 'Gigs': 6731, 'Oates': 6732, 'inducted': 6733, 'Nudity': 6734, 'Clause': 6735, 'negotiate': 6736, 'Honest': 6737, 'Horizon': 6738, 'Adopted': 6739, 'tips': 6740, 'Lachlan': 6741, 'hopeful': 6742, 'Planned': 6743, 'bids': 6744, 'joined': 6745, 'Jerry': 6746, 'Violent': 6747, 'Throw': 6748, 'Ferrera': 6749, 'Apologises': 6750, 'Mum': 6751, 'Laverne': 6752, 'Immelt': 6753, 'Pitching': 6754, 'Bulls': 6755, 'Broker': 6756, 'Messaging': 6757, 'Opts': 6758, 'reverting': 6759, 'match': 6760, 'Disputes': 6761, 'Franchise': 6762, 'VR': 6763, 'dumping': 6764, 'Poor': 6765, 'Resistant': 6766, 'Tyrion': 6767, 'Lannister': 6768, 'butterfly': 6769, 'Royalty': 6770, 'Delaware': 6771, 'mega': 6772, 'Sports': 6773, 'Hatred': 6774, 'screening': 6775, 'Craft': 6776, 'productive': 6777, 'Neuman': 6778, 'Fantasy': 6779, 'notes': 6780, 'Collection': 6781, 'Amiga': 6782, 'disappointing': 6783, 'pizza': 6784, 'Offset': 6785, 'inhaled': 6786, 'Afrezza': 6787, 'buoyant': 6788, 'Mistakes': 6789, 'Preparations': 6790, 'underway': 6791, 'Lovers': 6792, 'Brave': 6793, 'Haters': 6794, 'Guest': 6795, 'Anarchy': 6796, 'Stymie': 6797, 'Thefts': 6798, 'Rand': 6799, 'Intoxication': 6800, '£5': 6801, 'Dinklage': 6802, 'Shock': 6803, 'Cheryl': 6804, 'Adidas': 6805, 'Karl': 6806, 'stg': 6807, 'Calista': 6808, 'Flockhart': 6809, 'Rushes': 6810, 'cancel': 6811, 'None': 6812, 'Efficient': 6813, 'awareness': 6814, 'honor': 6815, 'Goal': 6816, '230': 6817, 'chemistry': 6818, 'brightly': 6819, 'eat': 6820, 'display': 6821, 'military': 6822, 'Antarctica': 6823, 'PICTURE': 6824, 'Regeneron': 6825, 'Approved': 6826, '2million': 6827, 'capitalist': 6828, 'bitcoin': 6829, 'capsule': 6830, 'Bread': 6831, 'Delta': 6832, 'clearing': 6833, 'Micros': 6834, 'Multi': 6835, 'Traced': 6836, 'Dragons': 6837, 'Stoll': 6838, 'salary': 6839, 'versatile': 6840, 'showman': 6841, 'Weev': 6842, 'Chilling': 6843, 'Tiny': 6844, 'Significant': 6845, 'Superheroes': 6846, 'GO': 6847, 'propose': 6848, 'antitrust': 6849, 'Outsider': 6850, 'Insurers': 6851, 'Initial': 6852, 'packed': 6853, 'Animals': 6854, 'Praise': 6855, 'Form': 6856, 'Publishers': 6857, 'Contracts': 6858, 'Amount': 6859, 'Monopoly': 6860, 'Stroke': 6861, 'artworks': 6862, 'floppy': 6863, 'disks': 6864, 'slim': 6865, 'backed': 6866, 'bridge': 6867, 'undervalues': 6868, 'favourite': 6869, 'Q4': 6870, 'Sardinia': 6871, 'miscarriage': 6872, 'flaunts': 6873, 'restrictions': 6874, 'Mugshots': 6875, 'Booty': 6876, 'Limited': 6877, 'agreed': 6878, 'principal': 6879, 'Sanchez': 6880, 'Dismissed': 6881, 'Marketwired': 6882, 'frequency': 6883, 'cater': 6884, 'Wednesday': 6885, 'Frequent': 6886, 'grads': 6887, 'Ashley': 6888, 'parades': 6889, 'separation': 6890, 'Busts': 6891, 'miserable': 6892, 'Proxy': 6893, 'Pursue': 6894, 'planned': 6895, 'Panic': 6896, 'Button': 6897, 'Recovering': 6898, 'Closing': 6899, 'Advocates': 6900, 'Superior': 6901, 'Standoff': 6902, 'Learning': 6903, 'sober': 6904, 'Austin': 6905, 'imply': 6906, 'Kicked': 6907, 'TIAA': 6908, 'CREF': 6909, 'Nuveen': 6910, 'Russians': 6911, 'Eastern': 6912, 'Overdraft': 6913, 'letter': 6914, 'chocolate': 6915, 'microbes': 6916, 'cocoa': 6917, 'conscious': 6918, 'Motorcycling': 6919, 'guru': 6920, 'probably': 6921, 'Arm': 6922, 'malpractice': 6923, 'Mood': 6924, 'leaders': 6925, 'Altitude': 6926, 'blunt': 6927, 'shocker': 6928, 'hated': 6929, 'Resistance': 6930, 'Observatory': 6931, 'Monitor': 6932, 'Searchers': 6933, 'disaster': 6934, 'Weighed': 6935, 'interrupts': 6936, 'immediate': 6937, 'returning': 6938, 'Peaks': 6939, 'Lynch': 6940, 'Material': 6941, 'coach': 6942, 'grey': 6943, 'foot': 6944, 'predict': 6945, 'Powdered': 6946, 'Tips': 6947, 'studded': 6948, 'chemical': 6949, 'Singing': 6950, 'dogs': 6951, 'Solider': 6952, 'Frat': 6953, 'lying': 6954, 'orbit': 6955, 'Nolan': 6956, 'boring': 6957, 'Sustain': 6958, 'Covered': 6959, 'Drawing': 6960, 'buyers': 6961, 'Clyde': 6962, 'Bondholders': 6963, 'cheerleader': 6964, 'fiancé': 6965, 'realism': 6966, 'lka': 6967, 'pacemaker': 6968, 'Choir': 6969, 'Benefits': 6970, '37': 6971, 'Devon': 6972, 'Linn': 6973, 'Hey': 6974, 'studios': 6975, 'attempt': 6976, 'GMA': 6977, 'Shed': 6978, 'pensions': 6979, 'harassment': 6980, 'Historic': 6981, 'removing': 6982, 'Spare': 6983, 'threshold': 6984, 'Micex': 6985, 'relatively': 6986, 'modest': 6987, 'premium': 6988, 'ConAgra': 6989, 'Pinette': 6990, 'serial': 6991, 'assaults': 6992, 'Evasion': 6993, 'timelines': 6994, 'impress': 6995, 'Colon': 6996, 'Soyuz': 6997, 'craft': 6998, 'successfully': 6999, 'docks': 7000, 'ON': 7001, 'shopping': 7002, 'allowed': 7003, 'hunk': 7004, 'Pump': 7005, '179': 7006, 'taxpayers': 7007, 'WATCH': 7008, 'Breakup': 7009, 'citizen': 7010, 'visiting': 7011, 'fabulous': 7012, 'brunch': 7013, 'smell': 7014, 'Soundtrack': 7015, 'Revised': 7016, 'Desperate': 7017, 'Kaepernick': 7018, 'TMZ': 7019, 'backlash': 7020, 'Answer': 7021, 'Classist': 7022, 'Idle': 7023, 'scared': 7024, 'Gustin': 7025, 'bruised': 7026, 'Swipe': 7027, 'Exits': 7028, 'Gamble': 7029, 'Holding': 7030, 'research': 7031, 'Rover': 7032, 'miles': 7033, 'Hare': 7034, 'Error': 7035, 'bankers': 7036, 'might': 7037, 'something': 7038, 'Leader': 7039, 'Nose': 7040, 'Incoming': 7041, 'Sings': 7042, 'Sort': 7043, 'Added': 7044, 'Asking': 7045, 'Buybacks': 7046, 'Blunder': 7047, 'acquire': 7048, 'CardioMEMS': 7049, 'rap': 7050, 'Authors': 7051, 'Dots': 7052, 'Revive': 7053, 'Program': 7054, 'licences': 7055, 'Truth': 7056, 'Contestant': 7057, 'Meditation': 7058, 'Maundy': 7059, 'Flooding': 7060, 'Gift': 7061, 'suits': 7062, 'Sophie': 7063, 'Brink': 7064, 'Seattle': 7065, 'Beckel': 7066, 'HIMYM': 7067, 'Nestle': 7068, 'Hertz': 7069, 'equipment': 7070, 'Friendly': 7071, 'Adventure': 7072, 'Chic': 7073, 'Violation': 7074, 'Posting': 7075, 'Finger': 7076, 'Kayne': 7077, 'includes': 7078, 'vandalism': 7079, 'egg': 7080, 'Lottery': 7081, 'Hedging': 7082, 'Swings': 7083, 'Soviet': 7084, 'Ride': 7085, 'boxes': 7086, 'Scripts': 7087, 'Sequels': 7088, 'MSG': 7089, 'Runs': 7090, 'Renews': 7091, 'Scientist': 7092, 'holdout': 7093, 'Bakken': 7094, 'Rajaratnam': 7095, 'Upheld': 7096, 'getaway': 7097, 'Costa': 7098, 'Diamond': 7099, 'Wet': 7100, 'bittersweet': 7101, 'Depressed': 7102, 'References': 7103, 'Songs': 7104, 'Grossing': 7105, 'Latinos': 7106, 'Mine': 7107, 'massive': 7108, 'Underwear': 7109, 'Bust': 7110, 'Prayers': 7111, 'nudge': 7112, 'Meteor': 7113, 'LIVESTREAM': 7114, 'burial': 7115, 'Switzerland': 7116, 'slept': 7117, 'trousers': 7118, 'Tila': 7119, '5m': 7120, 'ageing': 7121, 'Monte': 7122, 'Paschi': 7123, 'increasing': 7124, 'League': 7125, 'Departs': 7126, 'Wise': 7127, 'Antivirus': 7128, '60000': 7129, 'Sciences': 7130, 'Pare': 7131, 'Credible': 7132, 'Coy': 7133, 'dealings': 7134, 'verbal': 7135, 'Cord': 7136, 'skull': 7137, '32': 7138, 'Earns': 7139, 'Mastermind': 7140, 'Dominates': 7141, 'Hope': 7142, 'televised': 7143, 'Chip': 7144, 'Falters': 7145, 'Stabilizes': 7146, 'Axes': 7147, 'Believing': 7148, 'bare': 7149, 'Happily': 7150, 'Norway': 7151, 'Drilling': 7152, 'linger': 7153, 'performed': 7154, 'Whether': 7155, 'Engine': 7156, 'Websites': 7157, 'proposals': 7158, 'student': 7159, 'Pixies': 7160, 'Coeure': 7161, 'Portrayal': 7162, 'sparking': 7163, 'Apologies': 7164, 'Ghostbusters': 7165, 'FTSEurofirst': 7166, 'Channels': 7167, 'accelerate': 7168, '249': 7169, 'logistics': 7170, 'Fuels': 7171, 'worrying': 7172, 'spoils': 7173, 'Ships': 7174, 'theme': 7175, 'park': 7176, 'Smiling': 7177, 'fob': 7178, 'Bodyguard': 7179, 'commitments': 7180, 'legally': 7181, 'Except': 7182, 'SlimFast': 7183, 'Emerges': 7184, 'Contender': 7185, 'collecting': 7186, 'Artworks': 7187, 'Spooky': 7188, 'Snowden': 7189, 'Leaks': 7190, 'Field': 7191, 'Undercover': 7192, 'Writebol': 7193, 'Stricken': 7194, 'Missionary': 7195, 'Jessie': 7196, 'blouse': 7197, 'pencil': 7198, 'Adopt': 7199, 'Les': 7200, 'Miserables': 7201, 'duet': 7202, 'Abandoned': 7203, 'done': 7204, 'partnership': 7205, 'Publisher': 7206, 'Maureen': 7207, 'Eats': 7208, 'Signed': 7209, 'Cheese': 7210, 'Issued': 7211, 'Ouster': 7212, 'Unleashes': 7213, 'Purpose': 7214, 'exclusive': 7215, 'Zombie': 7216, 'Max': 7217, 'Image': 7218, 'tragedy': 7219, 'painting': 7220, 'Portrait': 7221, 'inaction': 7222, 'sent': 7223, 'worldwide': 7224, 'Evolution': 7225, 'Separate': 7226, 'halts': 7227, 'TOWIE': 7228, 'bolster': 7229, 'Avoided': 7230, 'Impress': 7231, 'Vivienne': 7232, 'Typo': 7233, 'welcomes': 7234, 'bail': 7235, 'Sahara': 7236, 'landing': 7237, 'Shortage': 7238, 'Beverage': 7239, 'engineer': 7240, '95': 7241, 'revs': 7242, 'Custody': 7243, 'Appleton': 7244, 'Freeze': 7245, 'Tedious': 7246, 'prepared': 7247, 'receives': 7248, 'authors': 7249, 'cups': 7250, 'Conan': 7251, 'ADHD': 7252, 'Establishes': 7253, 'Task': 7254, 'Bees': 7255, 'rehearsal': 7256, 'brace': 7257, 'stalker': 7258, 'Discourages': 7259, 'Reese': 7260, 'Witherspoon': 7261, 'entry': 7262, 'Conchita': 7263, 'Wurst': 7264, 'Infamous': 7265, 'Lab': 7266, 'flirts': 7267, 'kind': 7268, 'earthquake': 7269, 'Swirl': 7270, 'Attends': 7271, 'Flow': 7272, 'Tariffs': 7273, 'Charming': 7274, 'footing': 7275, 'any': 7276, 'Levi': 7277, 'Denial': 7278, 'opportunity': 7279, 'Pollution': 7280, 'Clear': 7281, 'Proving': 7282, 'Damps': 7283, 'methane': 7284, 'Further': 7285, 'benefit': 7286, 'Commissioner': 7287, 'Prostate': 7288, 'filled': 7289, 'Erdogan': 7290, 'Limiting': 7291, 'Impact': 7292, 'supporting': 7293, 'SE': 7294, 'irreversible': 7295, 'IPCC': 7296, 'Lanes': 7297, 'speakers': 7298, '116': 7299, 'highlights': 7300, 'Bans': 7301, 'Rossi': 7302, 'torn': 7303, 'Gaza': 7304, 'acquires': 7305, 'Closer': 7306, 'exactly': 7307, 'Connecticut': 7308, 'Thinks': 7309, 'Robots': 7310, 'recede': 7311, 'easier': 7312, 'prepare': 7313, 'address': 7314, 'ASML': 7315, 'measure': 7316, 'estimated': 7317, '370': 7318, 'drawn': 7319, 'Luxembourg': 7320, 'conviction': 7321, 'Loving': 7322, 'Reject': 7323, 'Seemingly': 7324, 'Expletive': 7325, 'Saft': 7326, 'Considering': 7327, 'Kodiak': 7328, 'Previews': 7329, 'Gritty': 7330, 'Figure': 7331, 'Tanning': 7332, 'Salon': 7333, 'Authority': 7334, 'Memory': 7335, 'permission': 7336, 'Versailles': 7337, 'limo': 7338, 'Identified': 7339, 'progresses': 7340, 'examine': 7341, 'DirectTV': 7342, 'Heats': 7343, 'Sneakers': 7344, 'Reilly': 7345, 'Godard': 7346, 'screens': 7347, 'Adieu': 7348, 'weddings': 7349, 'lavish': 7350, 'Roots': 7351, 'Independence': 7352, 'Jam': 7353, 'Unites': 7354, 'Backed': 7355, 'Pussy': 7356, 'Breakers': 7357, 'fades': 7358, 'mediator': 7359, 'Telus': 7360, 'Entwistle': 7361, 'NOTHING': 7362, 'embellished': 7363, 'Pre': 7364, 'Likeness': 7365, 'CinemaCon': 7366, 'Dreams': 7367, 'listings': 7368, 'Title': 7369, 'hell': 7370, 'Jaxon': 7371, 'Wyatt': 7372, 'Standing': 7373, 'plot': 7374, 'Sweet': 7375, 'Hammered': 7376, 'Liquidation': 7377, 'Veggies': 7378, 'Wally': 7379, 'Pfister': 7380, 'Intelligence': 7381, 'explains': 7382, 'carmaker': 7383, 'Carlos': 7384, 'iPhones': 7385, '320': 7386, 'Ergon': 7387, 'Philadelphia': 7388, 'Commuter': 7389, 'Rail': 7390, 'Prove': 7391, 'Publicist': 7392, 'Equalizer': 7393, 'OPEC': 7394, 'shortage': 7395, 'Melt': 7396, 'Ingenuity': 7397, 'Catastrophe': 7398, 'billionaire': 7399, 'Pill': 7400, 'Triggered': 7401, 'pants': 7402, 'Churchill': 7403, 'Dive': 7404, 'soaring': 7405, 'matches': 7406, 'hiding': 7407, 'shuts': 7408, 'Display': 7409, 'Male': 7410, 'preparations': 7411, 'overhaul': 7412, 'pattern': 7413, 'lapses': 7414, 'Favorable': 7415, 'NATO': 7416, 'snooping': 7417, 'completely': 7418, 'Foxcatcher': 7419, 'Predator': 7420, 'Geneva': 7421, 'Audi': 7422, 'deny': 7423, 'Looked': 7424, 'Dapper': 7425, 'Appetite': 7426, 'limelight': 7427, 'Gellar': 7428, 'Sinister': 7429, 'clause': 7430, 'inventories': 7431, 'Goonies': 7432, 'Donner': 7433, 'Hidden': 7434, 'Debris': 7435, 'Gallup': 7436, 'Obsession': 7437, 'lawyers': 7438, 'Bullion': 7439, 'Targeted': 7440, 'restart': 7441, 'YesAllWomen': 7442, 'supportive': 7443, 'Mull': 7444, 'Sheet': 7445, 'MacFarlane': 7446, 'BHP': 7447, 'Ariel': 7448, 'Castro': 7449, 'CCTV': 7450, 'Gorgeous': 7451, 'Reversal': 7452, 'TurboTax': 7453, 'Employers': 7454, 'pro': 7455, 'ARRESTED': 7456, 'joke': 7457, 'Aging': 7458, 'ratio': 7459, 'Implants': 7460, 'wildlife': 7461, 'chest': 7462, 'Moretz': 7463, 'Knocks': 7464, 'ATK': 7465, 'gun': 7466, 'Galifianakis': 7467, 'Baskets': 7468, 'picked': 7469, 'headset': 7470, 'Vietnamese': 7471, 'fishing': 7472, 'texts': 7473, 'Spacewalk': 7474, 'Unaware': 7475, 'Truths': 7476, 'Rudimental': 7477, 'seafood': 7478, 'REPORT': 7479, 'cheating': 7480, 'Michel': 7481, 'Onstage': 7482, 'prenup': 7483, 'Accor': 7484, 'SA': 7485, 'Apologise': 7486, 'Cleveland': 7487, 'Premature': 7488, 'Births': 7489, 'monsoon': 7490, 'touch': 7491, 'Errors': 7492, 'Topping': 7493, 'inject': 7494, 'era': 7495, 'Seoul': 7496, 'Listing': 7497, 'Scare': 7498, 'member': 7499, 'Troubles': 7500, 'Coveted': 7501, 'Park': 7502, 'Fesival': 7503, 'Aldean': 7504, 'Gloomy': 7505, 'Seafood': 7506, 'Combat': 7507, 'Stamos': 7508, 'Distant': 7509, 'Imports': 7510, 'Blocked': 7511, 'Bisexual': 7512, 'Rutler': 7513, 'Calvin': 7514, 'Klein': 7515, 'pack': 7516, 'Stance': 7517, 'Runway': 7518, 'EMT': 7519, 'Overseas': 7520, 'stokes': 7521, 'Alfa': 7522, 'Whitbread': 7523, 'Iranians': 7524, 'trust': 7525, 'illness': 7526, 'Allman': 7527, 'GSK': 7528, 'Map': 7529, 'operation': 7530, 'travellers': 7531, 'CNPC': 7532, 'Medium': 7533, 'Dementia': 7534, '50000': 7535, '281000': 7536, 'Dodge': 7537, 'Ram': 7538, 'Glamour': 7539, 'recession': 7540, 'Attempt': 7541, 'correction': 7542, 'Dogs': 7543, 'Mining': 7544, 'Melanoma': 7545, 'Gotta': 7546, 'Jailed': 7547, 'Noriega': 7548, 'Bjork': 7549, 'misconduct': 7550, 'Verdict': 7551, 'Damages': 7552, 'Benzene': 7553, 'Aus': 7554, 'update': 7555, 'Replica': 7556, 'Ear': 7557, 'boys': 7558, 'cracks': 7559, 'jokes': 7560, 'oxygen': 7561, 'mask': 7562, 'Olympic': 7563, 'swimming': 7564, 'champion': 7565, 'Pursuing': 7566, 'Sizzurp': 7567, 'rant': 7568, 'Dedicates': 7569, 'flu': 7570, 'stood': 7571, 'Tweeted': 7572, 'PICTURED': 7573, 'DWTS': 7574, 'Announcing': 7575, 'Sandler': 7576, 'sag': 7577, 'fix': 7578, 'kissing': 7579, 'aids': 7580, 'Ruined': 7581, 'Sand': 7582, 'Dodgers': 7583, 'tones': 7584, 'sweater': 7585, 'Campaigns': 7586, 'Holders': 7587, 'teams': 7588, 'urge': 7589, 'Benz': 7590, 'emotion': 7591, 'Kathleen': 7592, 'Sebelius': 7593, 'Cooking': 7594, 'perch': 7595, 'Norovirus': 7596, 'Hateful': 7597, 'Gasp': 7598, 'Architect': 7599, 'Reacted': 7600, 'inch': 7601, 'Pile': 7602, 'recreational': 7603, 'investigated': 7604, 'attempted': 7605, 'Forgiven': 7606, 'BRIEF': 7607, 'Costly': 7608, 'Presented': 7609, 'Brags': 7610, 'God': 7611, 'complications': 7612, 'Type': 7613, 'lesson': 7614, 'Shopping': 7615, 'subsidies': 7616, 'Testify': 7617, 'probing': 7618, 'Reunites': 7619, 'Tower': 7620, 'girlfriends': 7621, 'Patches': 7622, 'Communicated': 7623, 'Advanced': 7624, 'dose': 7625, 'sunshine': 7626, 'drunk': 7627, 'Urged': 7628, 'Training': 7629, 'Booed': 7630, 'Separates': 7631, 'Subpoenaed': 7632, 'differences': 7633, 'HGTV': 7634, 'airs': 7635, 'TJX': 7636, 'blamed': 7637, 'Expensive': 7638, 'Manhattan': 7639, 'unfazed': 7640, 'IFO': 7641, 'drives': 7642, 'margins': 7643, 'Dior': 7644, 'golden': 7645, 'Subpoena': 7646, 'Reed': 7647, 'Complacent': 7648, 'Cee': 7649, 'Chance': 7650, 'Laws': 7651, 'Waves': 7652, 'Hunting': 7653, 'Burglary': 7654, 'Aluminum': 7655, 'partying': 7656, 'insurance': 7657, 'hunky': 7658, 'dedicates': 7659, 'Ankle': 7660, 'Shames': 7661, 'Baxter': 7662, 'Bettany': 7663, 'Hijacked': 7664, 'Documents': 7665, 'Tycoon': 7666, 'arguments': 7667, 'Frankel': 7668, 'millionaire': 7669, 'Mermaid': 7670, 'Christ': 7671, 'Conversion': 7672, 'Nearby': 7673, 'serving': 7674, 'Condemn': 7675, 'Pattern': 7676, 'Bureau': 7677, 'Hide': 7678, 'bandits': 7679, 'computers': 7680, 'scientist': 7681, 'Beagle': 7682, 'disputes': 7683, 'scientific': 7684, 'Ricky': 7685, 'Vacation': 7686, 'busty': 7687, 'savings': 7688, 'Bursts': 7689, 'DAILY': 7690, 'Homophobic': 7691, 'replaced': 7692, 'SNC': 7693, 'Lavalin': 7694, 'Kentz': 7695, 'Niche': 7696, 'fares': 7697, 'Orbitz': 7698, 'Stuff': 7699, 'attacking': 7700, 'Committed': 7701, 'rejected': 7702, 'Glastonbury': 7703, 'Military': 7704, 'shore': 7705, 'Pic': 7706, 'Dismiss': 7707, 'Vatican': 7708, 'Schaeuble': 7709, 'ESM': 7710, 'vindicates': 7711, 'heightened': 7712, 'Moving': 7713, 'Suites': 7714, 'Revival': 7715, 'patents': 7716, 'development': 7717, 'HUFFPOLLSTER': 7718, 'dented': 7719, 'BG': 7720, '46': 7721, 'mocks': 7722, 'pig': 7723, 'Depends': 7724, 'Mount': 7725, 'Gabrielle': 7726, 'Ashanti': 7727, 'emails': 7728, 'Senator': 7729, 'Intimate': 7730, 'Pushed': 7731, 'Trilogy': 7732, 'Filmed': 7733, 'Deserve': 7734, 'stub': 7735, 'lackluster': 7736, 'politicians': 7737, 'defies': 7738, 'dashes': 7739, 'Remedies': 7740, 'Oilfield': 7741, 'Foot': 7742, 'Falling': 7743, 'Hearts': 7744, 'Endocyte': 7745, 'themed': 7746, 'Royals': 7747, 'came': 7748, 'Elvis': 7749, 'Bristol': 7750, 'Sarepta': 7751, 'disorder': 7752, 'Barkhad': 7753, 'Abdi': 7754, 'lie': 7755, 'Reprise': 7756, 'Chewbacca': 7757, 'Seventeen': 7758, 'Harm': 7759, 'Birds': 7760, 'Quits': 7761, 'Speleers': 7762, 'compete': 7763, 'Stooges': 7764, 'Asheton': 7765, 'surgical': 7766, 'Roiling': 7767, 'diet': 7768, 'ranks': 7769, 'Improve': 7770, 'Bowl': 7771, 'Aided': 7772, 'stylish': 7773, 'Gawker': 7774, 'dismissed': 7775, 'Core': 7776, 'corner': 7777, 'firming': 7778, 'Whoopi': 7779, 'Goldberg': 7780, 'marijuana': 7781, 'Viacom': 7782, 'moved': 7783, 'grins': 7784, 'Shelton': 7785, 'REAL': 7786, 'Brought': 7787, 'seizing': 7788, 'Lazaretto': 7789, 'Forming': 7790, 'Choose': 7791, 'Lowe': 7792, 'Sh': 7793, 'Maintains': 7794, 'Charts': 7795, 'Miles': 7796, 'intensifies': 7797, 'Cristina': 7798, 'strengthening': 7799, 'looser': 7800, 'Cooling': 7801, 'Heels': 7802, 'Attacking': 7803, 'Bombs': 7804, 'soldier': 7805, 'impossible': 7806, 'McHale': 7807, 'Prankster': 7808, 'Coli': 7809, 'Raw': 7810, '1964': 7811, 'SNB': 7812, 'facial': 7813, 'Server': 7814, 'Schneiderman': 7815, 'tender': 7816, 'Accelerate': 7817, 'File': 7818, 'passenger': 7819, 'Hawaii': 7820, 'Subway': 7821, 'Maserati': 7822, 'estate': 7823, 'Approve': 7824, 'Plenty': 7825, 'crawl': 7826, 'Timing': 7827, 'Forward': 7828, 'passwords': 7829, 'Chips': 7830, 'shine': 7831, 'courts': 7832, 'Protections': 7833, 'shoppers': 7834, 'alive': 7835, 'rescued': 7836, 'abyss': 7837, 'thrusters': 7838, 'lived': 7839, 'Creation': 7840, 'telecom': 7841, 'Kent': 7842, 'Whale': 7843, 'tied': 7844, 'Wanting': 7845, 'Editor': 7846, 'NHTSA': 7847, 'sacked': 7848, 'Inflated': 7849, '20th': 7850, 'Equity': 7851, 'Ratio': 7852, 'Scout': 7853, 'Maggie': 7854, 'sides': 7855, 'Screening': 7856, 'Hear': 7857, 'posting': 7858, 'sink': 7859, 'hurdles': 7860, 'Mickelson': 7861, 'few': 7862, 'flowers': 7863, 'fifth': 7864, 'Designed': 7865, 'Dan': 7866, 'Drawn': 7867, 'distant': 7868, 'costume': 7869, 'bra': 7870, 'insurer': 7871, 'Renesas': 7872, 'Nation': 7873, 'block': 7874, 'abortion': 7875, 'slur': 7876, 'Onscreen': 7877, 'heights': 7878, '108': 7879, 'rock': 7880, 'Theroux': 7881, 'elope': 7882, 'shortages': 7883, 'hinder': 7884, 'profile': 7885, 'underpinned': 7886, 'emotional': 7887, 'zip': 7888, 'lining': 7889, 'vacation': 7890, 'Hamill': 7891, 'Von': 7892, 'Muni': 7893, 'Tree': 7894, 'Disappointing': 7895, 'Chai': 7896, 'brothers': 7897, 'Caleb': 7898, 'fill': 7899, 'sings': 7900, 'Jake': 7901, 'Peg': 7902, 'then': 7903, 'Toilet': 7904, 'Hugging': 7905, '500000': 7906, 'Computers': 7907, 'Disrupts': 7908, 'Sheds': 7909, 'daughters': 7910, 'Grint': 7911, 'groups': 7912, 'Lancer': 7913, 'career': 7914, 'trying': 7915, 'Definition': 7916, 'chips': 7917, 'bogus': 7918, 'Rouhani': 7919, 'Shift': 7920, 'Slapped': 7921, 'striking': 7922, 'convicted': 7923, 'Peters': 7924, 'lend': 7925, 'Rap': 7926, 'Genius': 7927, 'Killer': 7928, 'complex': 7929, 'Softbank': 7930, 'Ladies': 7931, 'Ac': 7932, 'Dc': 7933, '360': 7934, 'Pipe': 7935, 'Pulling': 7936, 'Dated': 7937, 'Came': 7938, 'Alters': 7939, 'Permit': 7940, 'Conditions': 7941, 'Earthquakes': 7942, 'Popeyes': 7943, 'Recipes': 7944, 'elusive': 7945, 'trades': 7946, 'Chaotic': 7947, 'Indie': 7948, 'confirming': 7949, 'broadcasters': 7950, 'Cinema': 7951, 'Sexuality': 7952, 'Introducing': 7953, 'Breakout': 7954, 'apparel': 7955, 'honoured': 7956, 'finding': 7957, 'pushes': 7958, 'Employees': 7959, 'Annoying': 7960, 'Bowe': 7961, 'mate': 7962, 'Contamination': 7963, 'Tempered': 7964, 'Biblical': 7965, 'prefers': 7966, 'builds': 7967, 'replica': 7968, 'powered': 7969, 'aircraft': 7970, 'Lag': 7971, 'Magnificent': 7972, 'Controllers': 7973, 'Shifts': 7974, 'usual': 7975, 'Christians': 7976, 'quickens': 7977, 'reduces': 7978, 'Bubbles': 7979, 'Orbit': 7980, 'Grammy': 7981, 'printing': 7982, 'Interested': 7983, 'Parties': 7984, 'Nightmare': 7985, 'Port': 7986, 'Accidentally': 7987, 'Spoiler': 7988, 'Handwritten': 7989, 'Establishment': 7990, 'Supporters': 7991, 'Vow': 7992, 'Blues': 7993, 'Winchester': 7994, 'finish': 7995, 'Klan': 7996, 'Owned': 7997, 'Restaurants': 7998, 'Sisterly': 7999, 'decide': 8000, 'Alley': 8001, 'Rated': 8002, 'Sound': 8003, 'Familiar': 8004, 'Travelers': 8005, 'Functioning': 8006, 'Stolen': 8007, 'Dresses': 8008, 'Ministry': 8009, 'Recommends': 8010, 'Pilgrims': 8011, 'Hospitals': 8012, 'bum': 8013, 'male': 8014, 'Rejected': 8015, 'Maersk': 8016, 'shipping': 8017, 'Juniper': 8018, 'Networks': 8019, 'Maintain': 8020, 'surfs': 8021, 'wave': 8022, 'elevator': 8023, 'client': 8024, 'sight': 8025, 'Sulzberger': 8026, 'Laid': 8027, 'Darabont': 8028, 'Wonders': 8029, 'Fashionable': 8030, 'AND': 8031, 'Chime': 8032, 'penalties': 8033, 'Am': 8034, 'Focuses': 8035, 'Capitalism': 8036, 'Cells': 8037, 'Breakthrough': 8038, 'Lockup': 8039, 'prosecutors': 8040, 'GoT': 8041, 'Journey': 8042, 'Procedure': 8043, 'Turks': 8044, 'Caicos': 8045, 'USD': 8046, 'coal': 8047, 'Generic': 8048, 'sons': 8049, 'smash': 8050, 'Raps': 8051, 'Dares': 8052, 'Wearable': 8053, 'code': 8054, 'Mix': 8055, 'Interim': 8056, 'nominees': 8057, 'Administration': 8058, 'loud': 8059, 'Styles': 8060, 'blasted': 8061, 'stream': 8062, 'IPad': 8063, 'Writer': 8064, 'Seem': 8065, 'Whatever': 8066, 'Bandmates': 8067, 'Aired': 8068, 'strengthens': 8069, 'accord': 8070, 'banana': 8071, 'draw': 8072, 'families': 8073, 'Hormel': 8074, 'Muscle': 8075, 'Milk': 8076, '450': 8077, 'Diddy': 8078, 'meteor': 8079, 'shower': 8080, 'respectfully': 8081, 'guns': 8082, 'CAN': 8083, 'Visit': 8084, 'Divided': 8085, 'Judges': 8086, 'thanks': 8087, 'IFR': 8088, 'ForexWatch': 8089, 'Regional': 8090, 'Briefing': 8091, 'favour': 8092, 'den': 8093, 'Upholds': 8094, 'Chu': 8095, 'Sxsw': 8096, 'protesters': 8097, 'Statoil': 8098, 'drilling': 8099, 'Oathkeeper': 8100, 'Swords': 8101, 'Killing': 8102, 'offshore': 8103, 'Earlier': 8104, 'Writes': 8105, 'Commodities': 8106, 'Contained': 8107, 'Hague': 8108, 'Creationism': 8109, 'ways': 8110, 'Quiznos': 8111, 'Diversity': 8112, 'Industrial': 8113, 'Pals': 8114, 'Including': 8115, 'Trailers': 8116, 'Thoughts': 8117, 'legacy': 8118, 'wanted': 8119, 'guests': 8120, 'Tepco': 8121, 'quarantined': 8122, 'tested': 8123, 'Ghana': 8124, 'statistics': 8125, 'retract': 8126, 'Marion': 8127, 'Cotillard': 8128, 'Produce': 8129, 'Siberia': 8130, 'heat': 8131, 'Rivalry': 8132, 'Officer': 8133, 'Cupcake': 8134, 'Anytime': 8135, 'Deborah': 8136, 'Lyme': 8137, 'sole': 8138, 'Gurlitt': 8139, 'alleged': 8140, 'slot': 8141, 'candy': 8142, 'Clarifies': 8143, 'morning': 8144, 'coffee': 8145, 'Photographer': 8146, 'Lengthy': 8147, 'Alec': 8148, 'toxic': 8149, 'Bars': 8150, 'Turmoil': 8151, 'Exchanges': 8152, 'Prosecutors': 8153, 'Hospitalization': 8154, '2020': 8155, 'staying': 8156, 'brake': 8157, 'Watched': 8158, 'Wladimir': 8159, 'Klitschko': 8160, 'Clash': 8161, 'nominee': 8162, 'Angela': 8163, 'Bassett': 8164, 'terrible': 8165, 'longest': 8166, 'Dec': 8167, 'Vaccines': 8168, 'Thrilled': 8169, 'Blamed': 8170, 'IT': 8171, 'defense': 8172, 'Fortune': 8173, 'Lucky': 8174, 'Incredible': 8175, 'Flappy': 8176, 'Developer': 8177, 'addictive': 8178, 'Costco': 8179, 'Groceries': 8180, 'potentially': 8181, 'Switches': 8182, 'Headcount': 8183, 'eastern': 8184, 'meaningful': 8185, 'repo': 8186, 'machinery': 8187, 'skipped': 8188, 'Savings': 8189, 'teens': 8190, 'adults': 8191, 'skintight': 8192, 'intimate': 8193, 'Continued': 8194, 'Timothy': 8195, 'childhood': 8196, 'according': 8197, 'Mercury': 8198, 'extravagant': 8199, 'Jungle': 8200, 'Items': 8201, 'Tow': 8202, 'Sharknado': 8203, 'Lennar': 8204, 'Fate': 8205, 'Pythons': 8206, 'flogging': 8207, 'hilarious': 8208, 'skit': 8209, 'wore': 8210, '6m': 8211, 'Nominations': 8212, 'Peltz': 8213, 'Orphan': 8214, 'Discuss': 8215, 'Granddaughter': 8216, 'Drunken': 8217, 'Quick': 8218, 'clash': 8219, 'Provincial': 8220, 'nervous': 8221, 'avoided': 8222, 'talent': 8223, 'Intensifies': 8224, 'Revealing': 8225, 'Annie': 8226, 'urbanisation': 8227, 'Entertainer': 8228, 'Oregon': 8229, 'Centre': 8230, 'Extortion': 8231, 'parade': 8232, 'Duet': 8233, 'Dwayne': 8234, 'Clout': 8235, 'Hercules': 8236, 'harder': 8237, 'Mccurdy': 8238, 'river': 8239, 'Shamed': 8240, 'attempts': 8241, 'lightly': 8242, 'publicist': 8243, 'Meester': 8244, 'deputy': 8245, 'Charity': 8246, 'Promise': 8247, 'journey': 8248, 'concessions': 8249, 'Remaining': 8250, 'leader': 8251, 'complaints': 8252, 'Rebuffed': 8253, 'Chen': 8254, 'Concentration': 8255, 'Camp': 8256, 'Uniform': 8257, 'Twist': 8258, 'timeframe': 8259, 'Anthrax': 8260, 'drones': 8261, 'portrait': 8262, 'Waiting': 8263, 'stitches': 8264, 'Mutant': 8265, 'forex': 8266, 'aspiring': 8267, 'contender': 8268, 'Organization': 8269, 'abused': 8270, 'rekindle': 8271, '5C': 8272, 'Reference': 8273, 'pat': 8274, 'lifted': 8275, 'Tumble': 8276, 'aboard': 8277, 'Storage': 8278, 'Bron': 8279, 'Yr': 8280, 'Aur': 8281, 'cottage': 8282, 'Nervous': 8283, 'Mamet': 8284, 'EMC': 8285, 'termination': 8286, 'Tourism': 8287, 'produce': 8288, 'Applications': 8289, 'Seventh': 8290, 'infectious': 8291, 'Spell': 8292, 'Views': 8293, 'uncomfortable': 8294, 'Fare': 8295, 'revenues': 8296, 'Bullying': 8297, 'pick': 8298, 'Newspaper': 8299, 'Agenda': 8300, 'augurs': 8301, 'revises': 8302, 'Basically': 8303, 'club': 8304, 'bulls': 8305, 'Canceled': 8306, 'Cool': 8307, 'Raiffeisen': 8308, 'Ideas': 8309, 'Offensive': 8310, 'Delivers': 8311, 'Saved': 8312, 'winners': 8313, 'joining': 8314, 'Democrat': 8315, 'Leigh': 8316, 'Nwa': 8317, 'willing': 8318, 'Suggestion': 8319, 'selected': 8320, 'storytelling': 8321, 'Pelvic': 8322, 'Provide': 8323, 'Proof': 8324, 'RIP': 8325, 'Archie': 8326, 'Dish': 8327, 'shoes': 8328, 'backfoot': 8329, 'Peanuts': 8330, 'Consoles': 8331, 'Tackles': 8332, 'Founders': 8333, 'Alternative': 8334, 'Celebrating': 8335, 'steadying': 8336, 'Pilgrim': 8337, 'scenes': 8338, 'Soothe': 8339, 'Slowdown': 8340, 'Horn': 8341, '84': 8342, 'prompts': 8343, 'meltdown': 8344, 'Correct': 8345, 'Aust': 8346, 'Bridesmaid': 8347, 'Hobart': 8348, 'Hobie': 8349, 'Echoes': 8350, 'Either': 8351, 'DMV': 8352, 'intervene': 8353, 'Info': 8354, 'stunt': 8355, 'Posse': 8356, 'claiming': 8357, 'custody': 8358, 'jolt': 8359, 'landscape': 8360, 'Ryanair': 8361, 'Anyone': 8362, 'Purdy': 8363, 'Within': 8364, 'Range': 8365, 'equitable': 8366, 'effects': 8367, 'CEOs': 8368, 'reunites': 8369, 'mom': 8370, 'Headlights': 8371, 'Started': 8372, 'Couldn': 8373, 'Influential': 8374, 'Ep': 8375, 'OBESE': 8376, 'muni': 8377, 'heading': 8378, 'AIDS': 8379, 'Sources': 8380, 'Observed': 8381, 'CFTC': 8382, 'Greg': 8383, 'Invades': 8384, 'AgBank': 8385, 'ankle': 8386, 'Jacques': 8387, 'Cousteau': 8388, 'grandson': 8389, 'undersea': 8390, 'Virtu': 8391, 'Wealthy': 8392, 'Machines': 8393, 'clock': 8394, 'Clarkson': 8395, 'whistleblower': 8396, 'retaliation': 8397, 'Shuns': 8398, 'UberX': 8399, 'promote': 8400, 'Durable': 8401, 'Goods': 8402, 'Holy': 8403, 'Gentleman': 8404, 'Others': 8405, 'Promote': 8406, 'Grading': 8407, 'Each': 8408, 'Soprano': 8409, 'Renault': 8410, 'Laughs': 8411, 'Bidding': 8412, 'holidays': 8413, 'hear': 8414, 'Wardrobe': 8415, 'cashing': 8416, 'Visual': 8417, 'Running': 8418, 'devoted': 8419, 'Shulgin': 8420, 'Saving': 8421, 'Newlywed': 8422, 'Celebs': 8423, 'developer': 8424, 'Movil': 8425, 'Bindi': 8426, 'Donnie': 8427, 'Injury': 8428, 'Ronald': 8429, 'Valuations': 8430, 'Gown': 8431, 'enhanced': 8432, 'Aegis': 8433, 'SM': 8434, 'onshore': 8435, 'Postpones': 8436, 'Angara': 8437, 'Watches': 8438, 'Fisheries': 8439, 'twerking': 8440, 'Retire': 8441, 'kisses': 8442, 'apologizes': 8443, 'Faux': 8444, 'Pas': 8445, 'knock': 8446, 'views': 8447, 'graft': 8448, 'recordings': 8449, 'Honeymoon': 8450, 'Updated': 8451, 'Polish': 8452, 'RBS': 8453, 'Citizens': 8454, 'compares': 8455, 'Brandy': 8456, 'Bates': 8457, 'Automakers': 8458, 'Tablet': 8459, 'Learns': 8460, 'Tampering': 8461, 'Mighty': 8462, 'Steal': 8463, 'Celgene': 8464, 'psoriatic': 8465, 'arthritis': 8466, 'gave': 8467, 'equal': 8468, 'question': 8469, 'resume': 8470, 'freeze': 8471, 'Portuguese': 8472, 'historical': 8473, 'extinction': 8474, 'Raytheon': 8475, 'Fence': 8476, 'reached': 8477, 'turbocharger': 8478, 'woes': 8479, 'cards': 8480, 'Countdown': 8481, 'Rips': 8482, 'DOJ': 8483, 'Stall': 8484, 'recently': 8485, 'resumed': 8486, '40m': 8487, 'finalises': 8488, 'Simply': 8489, 'Muster': 8490, 'Excitement': 8491, 'Zip': 8492, 'Lining': 8493, 'Cracks': 8494, 'advises': 8495, 'Gus': 8496, 'rule': 8497, 'Encryption': 8498, 'Stresses': 8499, 'Mar': 8500, 'Soybean': 8501, 'species': 8502, 'closely': 8503, 'earring': 8504, 'inner': 8505, 'signed': 8506, 'nup': 8507, 'happiness': 8508, 'Misused': 8509, 'FREE': 8510, 'Competitor': 8511, 'Struck': 8512, 'Airliner': 8513, 'Fiance': 8514, 'hospitalized': 8515, 'Fixed': 8516, 'Cabbies': 8517, 'mend': 8518, 'Diverse': 8519, 'SUVs': 8520, 'athlete': 8521, 'melting': 8522, 'uses': 8523, 'Absurd': 8524, 'invites': 8525, 'Insulin': 8526, 'slaps': 8527, 'Sought': 8528, 'Modi': 8529, 'Clunky': 8530, 'TED': 8531, 'Stella': 8532, 'creates': 8533, 'Previously': 8534, 'crackdown': 8535, '2900': 8536, 'Recovered': 8537, 'Axe': 8538, 'Carrying': 8539, 'shortly': 8540, 'Privileged': 8541, 'Wale': 8542, 'Pick': 8543, 'Unsung': 8544, 'extension': 8545, 'creditors': 8546, 'Colorful': 8547, 'Minidress': 8548, 'Alicia': 8549, 'attacked': 8550, 'raccoon': 8551, 'Toxic': 8552, 'Disorderly': 8553, 'Dump': 8554, 'Busted': 8555, 'promising': 8556, 'Momoa': 8557, 'disrupts': 8558, 'Bride': 8559, 'shrank': 8560, 'imposes': 8561, 'Decreases': 8562, 'Fallen': 8563, 'seals': 8564, 'coolest': 8565, 'risky': 8566, 'NINE': 8567, 'sixth': 8568, 'McCurdy': 8569, 'condition': 8570, 'eligibility': 8571, 'undies': 8572, 'paralysed': 8573, 'adviser': 8574, 'Gaining': 8575, 'Terminator': 8576, 'Beatrice': 8577, 'Dust': 8578, 'Sight': 8579, 'mediators': 8580, 'bitter': 8581, 'CCC': 8582, 'braces': 8583, 'Pig': 8584, 'Brett': 8585, 'industrial': 8586, 'spilled': 8587, 'Ton': 8588, 'comics': 8589, 'ouster': 8590, 'Questioned': 8591, 'Charging': 8592, 'PG': 8593, 'Bruno': 8594, 'Instability': 8595, 'transports': 8596, 'Optimistic': 8597, 'Alexandra': 8598, 'Lenders': 8599, 'Luxury': 8600, 'Keaton': 8601, 'Weigh': 8602, 'Clues': 8603, 'Photoshop': 8604, '34': 8605, 'Suffered': 8606, 'Menino': 8607, 'Invasion': 8608, 'Sept': 8609, 'Filan': 8610, 'precious': 8611, 'Chubby': 8612, 'pint': 8613, 'Alive': 8614, 'Scope': 8615, 'Helping': 8616, 'Respect': 8617, 'tower': 8618, 'Believes': 8619, 'Defaults': 8620, 'Signers': 8621, 'Guarantees': 8622, 'Factories': 8623, 'Sudeikis': 8624, 'Spreading': 8625, 'Gaps': 8626, 'Payrolls': 8627, 'Roils': 8628, 'Solo': 8629, 'Homes': 8630, 'Rhonda': 8631, 'Expects': 8632, 'Aim': 8633, 'became': 8634, 'fracking': 8635, 'earthquakes': 8636, 'lunches': 8637, 'pose': 8638, 'apartment': 8639, 'begged': 8640, 'renewal': 8641, 'fish': 8642, 'NEWS': 8643, 'EUROPE': 8644, 'failure': 8645, 'Surplus': 8646, 'reboot': 8647, 'reunite': 8648, 'lucky': 8649, 'Suspect': 8650, 'extradited': 8651, 'pares': 8652, 'spark': 8653, 'Failing': 8654, 'Ono': 8655, 'Connick': 8656, 'flashback': 8657, 'Owner': 8658, 'ditch': 8659, 'flawed': 8660, 'dots': 8661, 'Fairfax': 8662, 'probed': 8663, 'Knocked': 8664, 'Scottish': 8665, 'Singerâ€™s': 8666, 'pools': 8667, 'parent': 8668, 'Gliese': 8669, 'Mechanical': 8670, 'Bringing': 8671, 'Ties': 8672, 'Nigerian': 8673, 'Crucifixion': 8674, 'Guitarist': 8675, 'Clip': 8676, 'adjusted': 8677, 'hidden': 8678, 'Revolution': 8679, 'fixed': 8680, 'proceeds': 8681, 'Trendy': 8682, 'false': 8683, 'Aussies': 8684, 'Peabody': 8685, 'Sherman': 8686, 'Walks': 8687, 'Recognize': 8688, 'Pens': 8689, 'Sotheby': 8690, 'Congressional': 8691, 'Grid': 8692, 'flare': 8693, 'paragliding': 8694, 'gowns': 8695, 'Johannes': 8696, 'Bay': 8697, 'BREAKING': 8698, 'improving': 8699, 'Butts': 8700, 'Embarrassed': 8701, 'soil': 8702, 'Rampage': 8703, 'Picasso': 8704, 'status': 8705, 'gather': 8706, 'Brangelina': 8707, 'channels': 8708, 'stockpiling': 8709, 'Fetch': 8710, 'Harness': 8711, 'Bible': 8712, 'shape': 8713, 'Alcatel': 8714, 'Lucent': 8715, 'stripped': 8716, 'honours': 8717, 'Worn': 8718, 'Solitude': 8719, 'Fluid': 8720, 'camp': 8721, 'Wood': 8722, 'diplomat': 8723, 'III': 8724, 'Mock': 8725, 'fewer': 8726, 'touching': 8727, 'Funnyman': 8728, 'Throwback': 8729, 'Ian': 8730, 'Ziering': 8731, 'smartphones': 8732, '15th': 8733, 'Fairness': 8734, 'REUTERS': 8735, 'LIVE': 8736, 'Milhiser': 8737, 'Wyman': 8738, 'Chicken': 8739, 'Financing': 8740, 'Haim': 8741, 'bodes': 8742, 'Banksy': 8743, 'Headphones': 8744, 'restructure': 8745, 'Smallest': 8746, 'Nest': 8747, 'Shiller': 8748, 'Enrollment': 8749, 'blows': 8750, 'Mazda': 8751, 'Schedules': 8752, 'Calif': 8753, 'kitchens': 8754, 'overdose': 8755, 'Gate': 8756, '63': 8757, 'beyond': 8758, 'engineering': 8759, 'Woodside': 8760, 'Checking': 8761, 'Surgeons': 8762, 'KFC': 8763, 'Rubin': 8764, 'outlines': 8765, 'Startup': 8766, 'minidress': 8767, 'Kleiner': 8768, 'Replaced': 8769, 'tree': 8770, 'Shakeup': 8771, 'translate': 8772, 'trims': 8773, 'Diplomatic': 8774, 'broader': 8775, 'Insiders': 8776, 'Upgraded': 8777, 'Corps': 8778, 'Promo': 8779, 'Simmons': 8780, 'Rappers': 8781, 'Copy': 8782, 'homophobic': 8783, 'trimmed': 8784, 'BOC': 8785, 'Millennium': 8786, 'Binoche': 8787, 'NORDIC': 8788, 'Cowles': 8789, 'Towns': 8790, 'learned': 8791, 'Chooses': 8792, 'analysis': 8793, 'Bundesbank': 8794, 'Surgery': 8795, 'Newark': 8796, 'Retreats': 8797, 'Chia': 8798, 'Scooter': 8799, 'crops': 8800, 'Finland': 8801, 'Gov': 8802, 'Places': 8803, 'suing': 8804, 'ball': 8805, 'reserves': 8806, 'treads': 8807, 'ProCredit': 8808, 'Misled': 8809, 'Approach': 8810, 'lashing': 8811, 'Rossiya': 8812, 'Pledges': 8813, 'explore': 8814, 'Sina': 8815, 'overcoming': 8816, 'triggers': 8817, 'cries': 8818, 'officer': 8819, 'sound': 8820, 'privacy': 8821, 'bus': 8822, 'schedule': 8823, 'railroad': 8824, 'Sub': 8825, 'Stallone': 8826, 'heroes': 8827, 'significant': 8828, 'ANALYSIS': 8829, 'Wielding': 8830, 'Monetary': 8831, 'asked': 8832, 'fitted': 8833, 'grounds': 8834, 'fleet': 8835, 'path': 8836, 'homebuilders': 8837, 'Nokia': 8838, 'protege': 8839, 'governors': 8840, 'boosted': 8841, 'briefly': 8842, 'Holiday': 8843, 'offered': 8844, 'Jerusalem': 8845, 'Pull': 8846, 'buoyed': 8847, 'COMMODITIES': 8848, 'Grandma': 8849, 'criticises': 8850, 'Labour': 8851, 'independent': 8852, '467': 8853, 'newspaper': 8854, 'Maksim': 8855, 'partner': 8856, 'Copper': 8857, 'Transit': 8858, 'TweetDeck': 8859, 'Powerade': 8860, 'Ingredient': 8861, 'Anonymous': 8862, 'Waters': 8863, 'gal': 8864, 'pals': 8865, 'Mccreery': 8866, 'Terrifying': 8867, 'swings': 8868, 'Skipping': 8869, 'Tickets': 8870, 'Hottest': 8871, 'Priciest': 8872, 'Survival': 8873, 'CoreValve': 8874, 'warned': 8875, 'Methane': 8876, 'Greenhouse': 8877, 'green': 8878, 'ensemble': 8879, 'Blu': 8880, 'afford': 8881, 'specs': 8882, 'TENTH': 8883, 'Frames': 8884, 'Hemingway': 8885, 'Sanrio': 8886, 'Vimeo': 8887, 'harm': 8888, 'Beaches': 8889, 'Blythe': 8890, 'Danner': 8891, 'nothing': 8892, 'Zack': 8893, 'Snyder': 8894, 'Sinead': 8895, 'Pat': 8896, 'Sajak': 8897, 'puzzle': 8898, 'denial': 8899, 'Telescope': 8900, 'Isaac': 8901, 'Content': 8902, 'tickets': 8903, 'Chemistry': 8904, 'â€˜The': 8905, 'Exposed': 8906, 'treats': 8907, 'pleased': 8908, 'dancing': 8909, 'skills': 8910, 'Peeta': 8911, 'Lira': 8912, 'airliner': 8913, 'widened': 8914, 'Cancellation': 8915, 'Spotlights': 8916, 'Bankrupt': 8917, 'celebrity': 8918, 'suspected': 8919, 'stabilises': 8920, 'Theater': 8921, 'bonanza': 8922, 'wonder': 8923, 'Assessment': 8924, 'Spark': 8925, 'Trips': 8926, 'Reforming': 8927, 'Rodgers': 8928, 'Reverses': 8929, 'Faith': 8930, 'Division': 8931, 'messages': 8932, 'Hype': 8933, 'removed': 8934, 'Evidence': 8935, 'SingTel': 8936, 'trouble': 8937, 'accuse': 8938, 'Marlboro': 8939, 'ditches': 8940, 'Avoids': 8941, 'investigates': 8942, 'Caracal': 8943, '300K': 8944, 'Indicted': 8945, 'Sexism': 8946, 'Buddies': 8947, 'Dazeem': 8948, 'Echo': 8949, 'Draft': 8950, 'Shields': 8951, 'peripheral': 8952, 'Arden': 8953, 'Betrayed': 8954, 'Björk': 8955, 'Exhibition': 8956, 'seized': 8957, 'Krona': 8958, 'Busby': 8959, 'Berkeley': 8960, 'Soy': 8961, 'dives': 8962, 'waits': 8963, 'swoons': 8964, 'chair': 8965, 'offering': 8966, 'Tracing': 8967, 'Mild': 8968, 'Soft': 8969, 'Tabloid': 8970, 'machine': 8971, 'Written': 8972, 'STOLE': 8973, 'finalists': 8974, 'focuses': 8975, 'Sabotage': 8976, 'infamous': 8977, 'events': 8978, 'Anything': 8979, 'Transition': 8980, 'Trials': 8981, 'Asteroids': 8982, 'FDR': 8983, 'Dives': 8984, 'Songza': 8985, 'Address': 8986, 'Virginia': 8987, 'Clinic': 8988, 'pretty': 8989, 'delights': 8990, 'Snack': 8991, 'PepsiCo': 8992, 'sharia': 8993, 'Worried': 8994, 'secretly': 8995, '1m': 8996, 'package': 8997, 'floor': 8998, 'Barring': 8999, 'LSE': 9000, 'ETF': 9001, 'expectation': 9002, 'separated': 9003, 'conflict': 9004, 'Buster': 9005, 'licenses': 9006, 'rehabilitation': 9007, 'margin': 9008, 'teaser': 9009, 'clip': 9010, 'bar': 9011, 'FireEye': 9012, 'gears': 9013, 'Managing': 9014, 'pricing': 9015, 'volumes': 9016, 'Levar': 9017, 'Burton': 9018, 'Florence': 9019, 'Backtracks': 9020, 'honeymoon': 9021, 'invite': 9022, 'Frieze': 9023, 'younger': 9024, 'Sticks': 9025, 'Extra': 9026, 'each': 9027, 'shakes': 9028, 'appointments': 9029, 'Relativity': 9030, 'slinky': 9031, 'platform': 9032, 'clear': 9033, 'glamour': 9034, 'stick': 9035, 'rockets': 9036, 'furious': 9037, 'Foundation': 9038, 'bullish': 9039, 'triples': 9040, 'Viewers': 9041, 'Eliminating': 9042, '18000': 9043, 'Wine': 9044, 'Bln': 9045, 'slack': 9046, 'Flights': 9047, 'squeeze': 9048, 'silent': 9049, 'Drastic': 9050, 'movies': 9051, 'soul': 9052, 'English': 9053, 'loving': 9054, 'Feuding': 9055, 'Kiev': 9056, '4G': 9057, 'Astronomer': 9058, 'discovers': 9059, 'silence': 9060, 'Marilyn': 9061, 'Multiple': 9062, 'Chair': 9063, 'Tossing': 9064, 'Brawl': 9065, 'patch': 9066, 'Wisdom': 9067, 'reawakens': 9068, 'Alsina': 9069, 'impresses': 9070, 'allegations': 9071, 'Premium': 9072, 'lowers': 9073, 'eruption': 9074, 'NHS': 9075, 'gone': 9076, 'lunar': 9077, 'Gotten': 9078, 'Jaywalkers': 9079, 'bunch': 9080, 'borrowing': 9081, '1550': 9082, 'Destroy': 9083, 'Olympian': 9084, 'Hers': 9085, 'Remembered': 9086, 'Mirrors': 9087, 'reforms': 9088, 'Economists': 9089, 'viewing': 9090, 'luxury': 9091, 'Audiences': 9092, 'included': 9093, 'tell': 9094, 'pollen': 9095, 'Beasts': 9096, 'Deleting': 9097, 'Mess': 9098, 'Pornographic': 9099, 'Sent': 9100, 'honey': 9101, 'female': 9102, 'ten': 9103, 'Shadow': 9104, 'partners': 9105, 'Unearthed': 9106, 'Separation': 9107, 'Brian': 9108, 'quarterback': 9109, 'Jim': 9110, 'reporter': 9111, 'Parenthood': 9112, 'Aisle': 9113, 'Honorary': 9114, 'Reeva': 9115, 'Securities': 9116, 'Bezos': 9117, 'dramatic': 9118, 'Coolest': 9119, 'Machine': 9120, 'Monolith': 9121, 'Performances': 9122, 'solo': 9123, 'Athens': 9124, 'Previous': 9125, 'Posthumous': 9126, 'Everywhere': 9127, 'Protection': 9128, 'Robertson': 9129, 'Peers': 9130, 'hat': 9131, 'preacher': 9132, 'spying': 9133, 'wrong': 9134, 'Tutorial': 9135, 'Representative': 9136, 'screaming': 9137, 'TAKE': 9138, 'FILE': 9139, 'PAY': 9140, 'saw': 9141, 'episode': 9142, 'minor': 9143, 'opposed': 9144, 'ZEW': 9145, 'remote': 9146, 'teenagers': 9147, 'divorced': 9148, 'hackers': 9149, 'sooner': 9150, 'shr': 9151, 'Effective': 9152, 'brushes': 9153, 'Setting': 9154, 'Outage': 9155, 'grandfather': 9156, 'countries': 9157, 'USB': 9158, 'stumble': 9159, 'Antitrust': 9160, 'centre': 9161, 'Swan': 9162, 'â€“': 9163, 'volatile': 9164, 'Bullets': 9165, 'Infections': 9166, 'aviation': 9167, 'epic': 9168, 'chops': 9169, 'Watts': 9170, 'pharmacies': 9171, 'Taught': 9172, 'Sperm': 9173, 'Painkillers': 9174, 'sugary': 9175, 'Fools': 9176, 'fishnet': 9177, 'Successor': 9178, 'Negotiations': 9179, 'Publicly': 9180, 'Mckellar': 9181, 'Soda': 9182, 'Hole': 9183, 'Telling': 9184, 'Elsewhere': 9185, 'valuations': 9186, 'reasonable': 9187, 'returned': 9188, 'bridesmaid': 9189, 'Americas': 9190, 'Kurdistan': 9191, 'load': 9192, 'Dax': 9193, 'Candidly': 9194, 'file': 9195, 'friendly': 9196, 'sharing': 9197, 'pact': 9198, 'Newfound': 9199, 'Glow': 9200, 'Angers': 9201, 'sovereign': 9202, 'Delays': 9203, 'Predicted': 9204, 'Lucy': 9205, 'Restructuring': 9206, 'princess': 9207, 'unveiled': 9208, 'Coke': 9209, 'crossed': 9210, 'Nations': 9211, 'Hindering': 9212, 'reopen': 9213, 'Dons': 9214, 'Legalized': 9215, 'escapes': 9216, 'tail': 9217, 'senator': 9218, 'Derrickson': 9219, 'reverses': 9220, 'Fallout': 9221, 'Pete': 9222, 'Tong': 9223, 'sweet': 9224, 'Condescending': 9225, 'Plosser': 9226, 'chaos': 9227, 'Hurting': 9228, 'Transparency': 9229, 'Fukushima': 9230, 'defeat': 9231, 'Delhi': 9232, 'sing': 9233, 'Cochran': 9234, 'Inducted': 9235, 'Draws': 9236, 'Maps': 9237, 'Regulation': 9238, 'suffer': 9239, 'horrific': 9240, 'injuries': 9241, 'crazed': 9242, 'committee': 9243, 'Blasio': 9244, 'Shareholders': 9245, 'Resist': 9246, 'Caribbean': 9247, 'Carnival': 9248, 'laid': 9249, 'sights': 9250, 'Attached': 9251, 'gene': 9252, 'Lags': 9253, 'surrounded': 9254, 'Clock': 9255, 'proposal': 9256, 'Replacement': 9257, 'astronauts': 9258, 'origination': 9259, 'Palin': 9260, 'doldrums': 9261, 'UP': 9262, 'Sth': 9263, 'MuchMusic': 9264, 'Metals': 9265, 'Elliott': 9266, 'Else': 9267, 'Minds': 9268, 'Safran': 9269, 'inflows': 9270, 'Vardalos': 9271, 'gadget': 9272, 'GTA': 9273, 'Ericsson': 9274, 'Margins': 9275, 'Bridal': 9276, 'Remembers': 9277, 'survival': 9278, 'Easy': 9279, 'shift': 9280, 'Chemicals': 9281, 'Curiosity': 9282, 'require': 9283, 'Meals': 9284, 'Pip': 9285, 'television': 9286, 'Owe': 9287, 'maintains': 9288, 'rejection': 9289, 'raised': 9290, 'matching': 9291, 'Maryland': 9292, 'unintended': 9293, 'apology': 9294, 'Waterloo': 9295, 'dairy': 9296, 'turbulent': 9297, 'rounds': 9298, 'Wash': 9299, 'EIA': 9300, 'walking': 9301, '90s': 9302, 'AIRSHOW': 9303, 'Poisoning': 9304, 'swift': 9305, 'Designing': 9306, 'unexpectedly': 9307, 'Appoints': 9308, 'Vehicle': 9309, 'Checked': 9310, '911': 9311, 'Smallpox': 9312, 'ample': 9313, 'Kicillof': 9314, 'Wire': 9315, 'Mill': 9316, 'Squeeze': 9317, 'interactive': 9318, 'Origins': 9319, 'Struggles': 9320, 'audited': 9321, 'flagged': 9322, '777': 9323, 'Chest': 9324, 'Dwarf': 9325, 'painful': 9326, 'MONEY': 9327, 'Threaten': 9328, 'Hulk': 9329, 'wither': 9330, 'Polluted': 9331, 'Unusual': 9332, 'mix': 9333, 'Powers': 9334, 'unheard': 9335, 'Blooded': 9336, 'Several': 9337, 'Bowie': 9338, 'Stacey': 9339, 'Dash': 9340, 'Nickel': 9341, 'Vin': 9342, 'Diesel': 9343, 'Dept': 9344, 'cease': 9345, '£4': 9346, '254': 9347, 'Cemetery': 9348, 'pops': 9349, 'Brokers': 9350, 'Moto': 9351, 'Rigging': 9352, 'Parting': 9353, 'advisers': 9354, 'Zone': 9355, 'Obamas': 9356, 'NTSB': 9357, 'killing': 9358, 'camel': 9359, 'clarify': 9360, 'revoked': 9361, 'Beige': 9362, 'Finalists': 9363, 'Doodle': 9364, 'dementia': 9365, 'License': 9366, 'Departing': 9367, 'Sisters': 9368, '30000': 9369, 'rebellious': 9370, 'peanut': 9371, 'commercial': 9372, 'Bautista': 9373, 'Kudrow': 9374, 'potato': 9375, 'salad': 9376, 'Justina': 9377, 'Pelletier': 9378, 'confesses': 9379, 'Turner': 9380, 'DeGrasse': 9381, 'Cultural': 9382, 'Deciding': 9383, 'Antibacterial': 9384, 'Triclosan': 9385, 'Fever': 9386, 'Mockingbird': 9387, 'Exposition': 9388, 'newcomers': 9389, 'Aaron': 9390, 'Liberian': 9391, 'Clint': 9392, 'Eastwood': 9393, 'Recover': 9394, 'AutoNation': 9395, 'reset': 9396, 'donors': 9397}\n",
            "9397\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dts-87ZHaOzZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d194da2d-3a50-4026-fce3-2f1049fd13ad"
      },
      "source": [
        "# 与えられた単語列に対し単語IDを返す関数\n",
        "def return_id(text):\n",
        "  # 単語列の単語IDを入れるリスト\n",
        "  ids = []\n",
        "  # 同じように文から単語を取得し、それに対応する単語IDをリストに与える\n",
        "  table = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
        "  words = text.translate(table).split()\n",
        "  for word in words:\n",
        "    # get()で単語IDが与えられていない単語には0を返すようにする\n",
        "    ids.append(word_id.get(word, 0))\n",
        "\n",
        "  return ids\n",
        "\n",
        "# 確認(適当な記事見出しを選択)\n",
        "text = train['TITLE'][12]\n",
        "print(text)\n",
        "print(return_id(text))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UPDATE 2-Dollar General CEO to retire, Icahn's proposed merger in doubt\n",
            "[4, 13, 55, 880, 60, 1, 6594, 2098, 2, 1568, 566, 3, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCwl1IUZic7H"
      },
      "source": [
        "# 81. RNNによる予測\n",
        "# 標準的に必要となるライブラリ\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHqHCNMlLDfg"
      },
      "source": [
        "# バッチ処理を行えるようにデータセットを作成する\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "  def __init__(self, xdata, ydata, return_id):\n",
        "    self.data = xdata\n",
        "    self.label = ydata\n",
        "    self.return_id = return_id\n",
        "\n",
        "  # len(Dataset)で返す値を指定\n",
        "  def __len__(self):  \n",
        "    return len(self.label)\n",
        "\n",
        "  # Dataset[idx]で返す値を指定\n",
        "  def __getitem__(self, idx):\n",
        "    # 前問で作成した関数を用いて単語列をIDに変換し返す\n",
        "    text = self.data[idx]\n",
        "    x = self.return_id(text)\n",
        "    y = self.label[idx]\n",
        "    return x,y\n",
        "\n",
        "# 文の長さが一定ではないのでPaddingを行ってDataLoaderの出力とする\n",
        "def my_collate_fn(batch):\n",
        "  # バッチサイズ分のデータを取得\n",
        "  xdata, ydata = list(zip(*batch))\n",
        "  xs = list(xdata)\n",
        "  # Paddingを行う\n",
        "  xs1 = []\n",
        "  for k in range(len(xs)):\n",
        "    ids = xs[k]\n",
        "    xs1.append(torch.LongTensor(ids))\n",
        "  # Paddingの数値は単語ID辞書に登録されている単語数+1とする\n",
        "  xs1 = pad_sequence(xs1, batch_first=True, padding_value=len(word_id)+1)\n",
        "  \n",
        "  ys = list(ydata)\n",
        "  ys1 = torch.LongTensor(ys)\n",
        "\n",
        "  return xs1, ys1"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Pw4WLLmc7ad"
      },
      "source": [
        "# 記事のカテゴリ名をラベルに変更するための辞書(8章と同じもの)\n",
        "category_dict = {'b': 0, 't': 1, 'e':2, 'm':3}\n",
        "Y_train = torch.tensor(list(map(lambda x: category_dict[x], train['CATEGORY'])))\n",
        "Y_valid = torch.tensor(list(map(lambda x: category_dict[x], valid['CATEGORY'])))\n",
        "Y_test = torch.tensor(list(map(lambda x: category_dict[x], test['CATEGORY'])))\n",
        "\n",
        "# それぞれのデータセットを作成\n",
        "dataset_train = MyDataset(train['TITLE'], Y_train, return_id)\n",
        "dataset_valid = MyDataset(valid['TITLE'], Y_valid, return_id)\n",
        "dataset_test = MyDataset(test['TITLE'], Y_test, return_id)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDUtKxHVORNw",
        "outputId": "59c3057b-8ed6-4234-e13d-69c252b0fcfe"
      },
      "source": [
        "# 確認(バッチ処理とするのでバッチサイズはデータ全て)\n",
        "dataloader_train = DataLoader(dataset_train, batch_size=len(dataset_train), shuffle=True,\n",
        "                        collate_fn=my_collate_fn)\n",
        "d1 = dataloader_train.__iter__()\n",
        "xs, ys = d1.next()\n",
        "print(xs)\n",
        "print(len(xs))\n",
        "print(ys)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1569,   15,  945,  ..., 9398, 9398, 9398],\n",
            "        [ 155,    0, 3349,  ..., 9398, 9398, 9398],\n",
            "        [1386,   10, 6794,  ..., 9398, 9398, 9398],\n",
            "        ...,\n",
            "        [1257, 1985, 2747,  ..., 9398, 9398, 9398],\n",
            "        [3116,    2,  116,  ..., 9398, 9398, 9398],\n",
            "        [ 424,  601, 2778,  ..., 9398, 9398, 9398]])\n",
            "10672\n",
            "tensor([1, 3, 2,  ..., 2, 0, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIJTUVjXiwY2"
      },
      "source": [
        "# モデルの設定\n",
        "class Nlp81(nn.Module):\n",
        "  def __init__(self, vocab_size, embd_size, output_size, hid_size, padding_idx):\n",
        "    super(Nlp81, self).__init__()\n",
        "\n",
        "    # 埋め込み層でone-hotから単語ベクトルに変換\n",
        "    self.embd = nn.Embedding(vocab_size, embd_size, padding_idx=padding_idx)\n",
        "\n",
        "    # RNN層を定義\n",
        "    # 活性化関数はtanhとする   \n",
        "    self.rnn = nn.RNN(embd_size, hid_size, nonlinearity='tanh', batch_first=True)\n",
        "\n",
        "    # 隠れ層を定義\n",
        "    self.l1=nn.Linear(hid_size, output_size)\n",
        "    # 今回は重みをランダムな値で(正規分布により)初期化する\n",
        "    nn.init.normal_(self.l1.weight, 0.0, 1.0) \n",
        "        \n",
        "  # 順方向の計算\n",
        "  def forward(self,x):\n",
        "    # 埋め込み層で単語ベクトルに直し\n",
        "    ex = self.embd(x)\n",
        "    # RNNユニットで計算する\n",
        "    out, h_T = self.rnn(ex)\n",
        "\n",
        "    # RNNでは各単語に対する出力と、最後の隠れ状態ベクトルが得られる\n",
        "    # 最後の隠れ状態ベクトルは単語列の最後の単語に対する出力と等しいのでそちらを使用する\n",
        "    # ソフトマックス関数を適用し求める(dim=-1で行のsoftmaxを指定)\n",
        "    h1 = torch.softmax(self.l1(out[:,-1,:]), dim=-1)\n",
        "    return h1"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcIVyDd0SaTJ",
        "outputId": "8d0c1d37-14e4-496e-e2ac-1ea96941e623"
      },
      "source": [
        "# 確認\n",
        "# モデルの引数は単語の総数、単語ベクトル、出力ラベル、隠れ層の次元、Paddingの数値\n",
        "# 単語の総数は単語ID辞書に登録されている単語数＋2(登録されていない単語+Padding)\n",
        "model = Nlp81(len(word_id)+2, 300, 4, 50, len(word_id)+1)\n",
        "for xs, ys in dataloader_train:\n",
        "  y1_hat=model(xs)\n",
        "  print(y1_hat)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.0287, 0.2458, 0.4089, 0.3166],\n",
            "        [0.0286, 0.2487, 0.4042, 0.3185],\n",
            "        [0.0264, 0.2724, 0.4065, 0.2947],\n",
            "        ...,\n",
            "        [0.0283, 0.2489, 0.4030, 0.3198],\n",
            "        [0.0283, 0.2462, 0.4077, 0.3178],\n",
            "        [0.0285, 0.2457, 0.4122, 0.3137]], grad_fn=<SoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EK1lvDS50f5y"
      },
      "source": [
        "# 82. 確率的勾配降下法による学習\n",
        "\n",
        "# 正解率と損失の計算のための関数\n",
        "def cal_loss_accuracy(model, criterion, dataset):\n",
        "  # 正解率、損失を求めるときには比較のためshuffleはFalseとする\n",
        "  # バッチ処理で求める\n",
        "  dataloader = DataLoader(dataset, batch_size=len(dataset), shuffle=False,\n",
        "                        collate_fn=my_collate_fn)\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for xs, ys in dataloader:\n",
        "      # 順方向による出力\n",
        "      output = model(xs)\n",
        "      # 損失の計算\n",
        "      loss = criterion(output, ys).item()\n",
        "      # 正解率の計算\n",
        "      ans = torch.argmax(output,1)\n",
        "      accuracy = ((ys == ans).sum().float() / len(ans)).item()\n",
        "  return loss, accuracy"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOj__PRDDGQS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2a2ca5a-2442-4b0b-cf65-967599bf1287"
      },
      "source": [
        "# モデルのインスタンス、損失関数、最適化関数の設定\n",
        "model = Nlp81(len(word_id)+2, 300, 4, 50, len(word_id)+1)\n",
        "\n",
        "# ラベルはPaddingを行っていないのでクロスエントロピーで気にする必要はない\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "# データをロードする\n",
        "dataloader_train = DataLoader(dataset_train, batch_size=len(dataset_train), shuffle=True,\n",
        "                        collate_fn=my_collate_fn)\n",
        "\n",
        "# 学習の開始\n",
        "# 10エポックで終了とする\n",
        "for ep in range(10):\n",
        "  \n",
        "  model.train()\n",
        "  # データも81で取得したdataloader_trainを使用する\n",
        "  for xs, ys in dataloader_train:\n",
        "    output = model(xs) \n",
        "    loss = criterion(output, ys) \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward() \n",
        "    optimizer.step()\n",
        "\n",
        "  loss_train, accuracy_train = cal_loss_accuracy(model, criterion, dataset_train)\n",
        "  loss_test, accuracy_test = cal_loss_accuracy(model, criterion, dataset_test) \n",
        "  print('エポック数', ep)\n",
        "  print('[訓練データ]損失：',loss_train,'正解率:',accuracy_train)\n",
        "  print('[評価データ]損失：',loss_test,'正解率:',accuracy_test)\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "エポック数 0\n",
            "[訓練データ]損失： 1.2951695919036865 正解率: 0.4222263991832733\n",
            "[評価データ]損失： 1.294743537902832 正解率: 0.4220389723777771\n",
            "エポック数 1\n",
            "[訓練データ]損失： 1.283414602279663 正解率: 0.42306971549987793\n",
            "[評価データ]損失： 1.2827931642532349 正解率: 0.4220389723777771\n",
            "エポック数 2\n",
            "[訓練データ]損失： 1.2742602825164795 正解率: 0.4253185987472534\n",
            "[評価データ]損失： 1.2733274698257446 正解率: 0.4220389723777771\n",
            "エポック数 3\n",
            "[訓練データ]損失： 1.2694734334945679 正解率: 0.4300037622451782\n",
            "[評価データ]損失： 1.2684270143508911 正解率: 0.4220389723777771\n",
            "エポック数 4\n",
            "[訓練データ]損失： 1.2669267654418945 正解率: 0.4315029978752136\n",
            "[評価データ]損失： 1.2659424543380737 正解率: 0.4220389723777771\n",
            "エポック数 5\n",
            "[訓練データ]損失： 1.2652689218521118 正解率: 0.4320652186870575\n",
            "[評価データ]損失： 1.2643778324127197 正解率: 0.4220389723777771\n",
            "エポック数 6\n",
            "[訓練データ]損失： 1.264090657234192 正解率: 0.43234631419181824\n",
            "[評価データ]損失： 1.2632941007614136 正解率: 0.4220389723777771\n",
            "エポック数 7\n",
            "[訓練データ]損失： 1.2632015943527222 正解率: 0.43318966031074524\n",
            "[評価データ]損失： 1.2625010013580322 正解率: 0.4220389723777771\n",
            "エポック数 8\n",
            "[訓練データ]損失： 1.2624998092651367 正解率: 0.4330959618091583\n",
            "[評価データ]損失： 1.2618964910507202 正解率: 0.4220389723777771\n",
            "エポック数 9\n",
            "[訓練データ]損失： 1.2619256973266602 正解率: 0.4335644543170929\n",
            "[評価データ]損失： 1.2614208459854126 正解率: 0.4220389723777771\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JkfDoLBTZFd"
      },
      "source": [
        "# 83. ミニバッチ化・GPU上での学習\n",
        "# GPUに送るためのコード\n",
        "device = torch.device(\"cuda:0\" \n",
        "                     if torch.cuda.is_available()\n",
        "                     else \"cpu\") "
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N92sZeLCTZLz",
        "outputId": "cd7e5488-5a66-473e-8c34-99fd70793ae3"
      },
      "source": [
        "# バッチサイズは、データロードのときにサイズを指定すれば変更できる\n",
        "dataloader_train = DataLoader(dataset_train, batch_size=4, shuffle=True,\n",
        "                        collate_fn=my_collate_fn)\n",
        "\n",
        "# 確認\n",
        "d1 = dataloader_train.__iter__()\n",
        "xs, ys = d1.next()\n",
        "print(xs)\n",
        "print(len(xs))\n",
        "print(ys)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 127,   17,  168,  978,   52,    2,   84,  113,   25,   20, 8183, 9398],\n",
            "        [  51,  402,    5, 4759,   88,  484,    6,   67, 3971, 5246,    8,  830],\n",
            "        [  22,   19,   34,   30,  587, 1655,    5,   14, 1591, 9398, 9398, 9398],\n",
            "        [ 404,   60,   36,  760,  306,  476,  108,  217, 7129, 1347,    3,  481]])\n",
            "4\n",
            "tensor([2, 0, 2, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRwNA85HWdtB"
      },
      "source": [
        "# モデルの設定(81の流用(重みなどの初期化は省いている))\n",
        "class Nlp83(nn.Module):\n",
        "  def __init__(self, vocab_size, embd_size, output_size, hid_size, padding_idx):\n",
        "    super(Nlp83, self).__init__()\n",
        "\n",
        "    self.embd = nn.Embedding(vocab_size, embd_size, padding_idx=padding_idx)\n",
        "    self.rnn = nn.RNN(embd_size, hid_size, nonlinearity='tanh', batch_first=True)\n",
        "    self.l1=nn.Linear(hid_size, output_size)\n",
        "        \n",
        "  def forward(self,x):\n",
        "    ex = self.embd(x)\n",
        "    out, h_T = self.rnn(ex)\n",
        "    h1 = torch.softmax(self.l1(out[:,-1,:]), dim=-1)\n",
        "    return h1"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsPiqgpEXcdK"
      },
      "source": [
        "# 正解率と損失の計算のための関数(GPU用)\n",
        "def cal_loss_accuracy_gpu(model, criterion, dataset):\n",
        "  dataloader = DataLoader(dataset, batch_size=len(dataset), shuffle=False,\n",
        "                        collate_fn=my_collate_fn)\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for xs, ys in dataloader:\n",
        "      # 計算を行うためのベクトルをGPUに移動する\n",
        "      xs = xs.to(device)\n",
        "      ys = ys.to(device)\n",
        "      output = model(xs)\n",
        "      loss = criterion(output, ys).item()\n",
        "      ans = torch.argmax(output,1)\n",
        "      accuracy = ((ys == ans).sum().float() / len(ans)).item()\n",
        "  return loss, accuracy"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIfYZY0gTZRT",
        "outputId": "988deff3-d1a0-456a-c904-819835de6a4a"
      },
      "source": [
        "# モデルのインスタンス、損失関数、最適化関数の設定\n",
        "# モデルのインスタンス作成時にGPUに送る\n",
        "model = Nlp83(len(word_id)+2, 300, 4, 50, len(word_id)+1).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "# データロード時にバッチサイズを指定する(今回は4とする)\n",
        "dataloader_train = DataLoader(dataset_train, batch_size=4, shuffle=True,\n",
        "                        collate_fn=my_collate_fn)\n",
        "\n",
        "# 学習の開始\n",
        "# 10エポックで終了とする\n",
        "for ep in range(10):\n",
        "  model.train()\n",
        "  for xs, ys in dataloader_train:\n",
        "    # 学習時に使用するベクトルをGPUに移動する\n",
        "    xs = xs.to(device)\n",
        "    ys = ys.to(device)\n",
        "    output = model(xs) \n",
        "    loss = criterion(output, ys) \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward() \n",
        "    optimizer.step()\n",
        "\n",
        "  loss_train, accuracy_train = cal_loss_accuracy_gpu(model, criterion, dataset_train)\n",
        "  loss_test, accuracy_test = cal_loss_accuracy_gpu(model, criterion, dataset_test) \n",
        "  print('エポック数', ep)\n",
        "  print('[訓練データ]損失：',loss_train,'正解率:',accuracy_train)\n",
        "  print('[評価データ]損失：',loss_test,'正解率:',accuracy_test)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "エポック数 0\n",
            "[訓練データ]損失： 1.300644040107727 正解率: 0.42185157537460327\n",
            "[評価データ]損失： 1.3006950616836548 正解率: 0.4220389723777771\n",
            "エポック数 1\n",
            "[訓練データ]損失： 1.2570574283599854 正解率: 0.44865068793296814\n",
            "[評価データ]損失： 1.2578916549682617 正解率: 0.4227886199951172\n",
            "エポック数 2\n",
            "[訓練データ]損失： 1.163278341293335 正解率: 0.5803973078727722\n",
            "[評価データ]損失： 1.1754601001739502 正解率: 0.5682159066200256\n",
            "エポック数 3\n",
            "[訓練データ]損失： 1.286340594291687 正解率: 0.45239880681037903\n",
            "[評価データ]損失： 1.3207647800445557 正解率: 0.4227886199951172\n",
            "エポック数 4\n",
            "[訓練データ]損失： 1.2519757747650146 正解率: 0.4906296730041504\n",
            "[評価データ]損失： 1.278905987739563 正解率: 0.46476760506629944\n",
            "エポック数 5\n",
            "[訓練データ]損失： 1.165626883506775 正解率: 0.577867329120636\n",
            "[評価データ]損失： 1.188205599784851 正解率: 0.5554722547531128\n",
            "エポック数 6\n",
            "[訓練データ]損失： 1.1831978559494019 正解率: 0.5528485774993896\n",
            "[評価データ]損失： 1.2030823230743408 正解率: 0.5367316603660583\n",
            "エポック数 7\n",
            "[訓練データ]損失： 1.1659795045852661 正解率: 0.5776799321174622\n",
            "[評価データ]損失： 1.2001930475234985 正解率: 0.54347825050354\n",
            "エポック数 8\n",
            "[訓練データ]損失： 1.1475555896759033 正解率: 0.596045732498169\n",
            "[評価データ]損失： 1.1934453248977661 正解率: 0.5502249002456665\n",
            "エポック数 9\n",
            "[訓練データ]損失： 1.143967866897583 正解率: 0.5995127558708191\n",
            "[評価データ]損失： 1.1492220163345337 正解率: 0.5944527983665466\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F41DoC2wZv1P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92b92b2e-597e-422c-aab6-b03bd01486bb"
      },
      "source": [
        "# 84. 単語ベクトルの導入\n",
        "# 学習済み単語ベクトルのダウンロード(コピペ)\n",
        "# 学習済み単語ベクトルのダウンロード\n",
        "FILE_ID = \"0B7XkCwpI5KDYNlNUTTlSS21pQmM\"\n",
        "FILE_NAME = \"GoogleNews-vectors-negative300.bin.gz\"\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=$FILE_ID' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=$FILE_ID\" -O $FILE_NAME && rm -rf /tmp/cookies.txt"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-11 23:58:08--  https://docs.google.com/uc?export=download&confirm=pYZz&id=0B7XkCwpI5KDYNlNUTTlSS21pQmM\n",
            "Resolving docs.google.com (docs.google.com)... 142.250.97.101, 142.250.97.113, 142.250.97.139, ...\n",
            "Connecting to docs.google.com (docs.google.com)|142.250.97.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-04-1o-docs.googleusercontent.com/docs/securesc/ltuj0v0sk3jk3mcgcr6dik8tnmvdbpo1/e21m4564sjdhdj35c515oq15omj7jqg2/1626047850000/06848720943842814915/15678850346165452570Z/0B7XkCwpI5KDYNlNUTTlSS21pQmM?e=download [following]\n",
            "--2021-07-11 23:58:08--  https://doc-04-1o-docs.googleusercontent.com/docs/securesc/ltuj0v0sk3jk3mcgcr6dik8tnmvdbpo1/e21m4564sjdhdj35c515oq15omj7jqg2/1626047850000/06848720943842814915/15678850346165452570Z/0B7XkCwpI5KDYNlNUTTlSS21pQmM?e=download\n",
            "Resolving doc-04-1o-docs.googleusercontent.com (doc-04-1o-docs.googleusercontent.com)... 74.125.141.132, 2607:f8b0:400c:c06::84\n",
            "Connecting to doc-04-1o-docs.googleusercontent.com (doc-04-1o-docs.googleusercontent.com)|74.125.141.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://docs.google.com/nonceSigner?nonce=vimmcv0p3vock&continue=https://doc-04-1o-docs.googleusercontent.com/docs/securesc/ltuj0v0sk3jk3mcgcr6dik8tnmvdbpo1/e21m4564sjdhdj35c515oq15omj7jqg2/1626047850000/06848720943842814915/15678850346165452570Z/0B7XkCwpI5KDYNlNUTTlSS21pQmM?e%3Ddownload&hash=gc0no13lnul9rkvaumtdmjmflk1v782f [following]\n",
            "--2021-07-11 23:58:09--  https://docs.google.com/nonceSigner?nonce=vimmcv0p3vock&continue=https://doc-04-1o-docs.googleusercontent.com/docs/securesc/ltuj0v0sk3jk3mcgcr6dik8tnmvdbpo1/e21m4564sjdhdj35c515oq15omj7jqg2/1626047850000/06848720943842814915/15678850346165452570Z/0B7XkCwpI5KDYNlNUTTlSS21pQmM?e%3Ddownload&hash=gc0no13lnul9rkvaumtdmjmflk1v782f\n",
            "Connecting to docs.google.com (docs.google.com)|142.250.97.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://doc-04-1o-docs.googleusercontent.com/docs/securesc/ltuj0v0sk3jk3mcgcr6dik8tnmvdbpo1/e21m4564sjdhdj35c515oq15omj7jqg2/1626047850000/06848720943842814915/15678850346165452570Z/0B7XkCwpI5KDYNlNUTTlSS21pQmM?e=download&nonce=vimmcv0p3vock&user=15678850346165452570Z&hash=9u9g26c038m05teao7qve57f5tmr02rl [following]\n",
            "--2021-07-11 23:58:09--  https://doc-04-1o-docs.googleusercontent.com/docs/securesc/ltuj0v0sk3jk3mcgcr6dik8tnmvdbpo1/e21m4564sjdhdj35c515oq15omj7jqg2/1626047850000/06848720943842814915/15678850346165452570Z/0B7XkCwpI5KDYNlNUTTlSS21pQmM?e=download&nonce=vimmcv0p3vock&user=15678850346165452570Z&hash=9u9g26c038m05teao7qve57f5tmr02rl\n",
            "Connecting to doc-04-1o-docs.googleusercontent.com (doc-04-1o-docs.googleusercontent.com)|74.125.141.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/x-gzip]\n",
            "Saving to: ‘GoogleNews-vectors-negative300.bin.gz’\n",
            "\n",
            "GoogleNews-vectors-     [        <=>         ]   1.53G  83.3MB/s    in 19s     \n",
            "\n",
            "2021-07-11 23:58:29 (81.3 MB/s) - ‘GoogleNews-vectors-negative300.bin.gz’ saved [1647046227]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zv_IEGnHhvUb"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "embd_model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFVn7MxIfjnU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "303856da-5369-4140-89d2-25a46a605eb0"
      },
      "source": [
        "# 事前学習済みの単語ベクトルで初期化するための行列を作成する\n",
        "# 行列のサイズを決める(単語数、単語ベクトルの次元)\n",
        "vocab_size = len(word_id)+2\n",
        "embd_size = 300\n",
        "# そのサイズの0行列を作成\n",
        "embd_weights = np.zeros((vocab_size, embd_size))\n",
        "# 単語ID辞書に登録されている単語が事前学習済みの単語ベクトルに存在するなら\n",
        "# その単語ベクトルを取得する\n",
        "for i, word  in enumerate(word_id.keys()):\n",
        "    if word in embd_model.index2word:\n",
        "        embd_weights[i] = embd_model[word]\n",
        "\n",
        "# 配列の型が異なるので合わせておく  \n",
        "embd_weights = torch.from_numpy(embd_weights.astype((np.float32)))\n",
        "# 確認\n",
        "print(embd_weights)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.2910,  0.1787,  0.0500,  ..., -0.0228,  0.1177,  0.3535],\n",
            "        [ 0.0703,  0.0869,  0.0879,  ..., -0.0476,  0.0145, -0.0625],\n",
            "        ...,\n",
            "        [ 0.2207,  0.1963,  0.0649,  ...,  0.1011,  0.0388, -0.1152],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i47hTJK3jnZi"
      },
      "source": [
        "# モデルの設定(81の流用)\n",
        "class Nlp84(nn.Module):\n",
        "  def __init__(self, vocab_size, embd_size, output_size, hid_size, padding_idx, embd_weights):\n",
        "    super(Nlp84, self).__init__()\n",
        "\n",
        "    # 事前学習済み単語ベクトルを使う場合は\n",
        "    # Embedding.from_pretrainedとし、パラメータに作成した行列を指定する\n",
        "    self.embd = nn.Embedding.from_pretrained(embd_weights, padding_idx=padding_idx)\n",
        "    self.rnn = nn.RNN(embd_size, hid_size, nonlinearity='tanh', batch_first=True)\n",
        "    self.l1=nn.Linear(hid_size, output_size)\n",
        "        \n",
        "  def forward(self,x):\n",
        "    ex = self.embd(x)\n",
        "    out, h_T = self.rnn(ex)\n",
        "    h1 = torch.softmax(self.l1(out[:,-1,:]), dim=-1)\n",
        "    return h1"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wVZt70ujdQY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5567ff7f-1169-4ffe-b586-a7bbc4c4a1b5"
      },
      "source": [
        "# モデルのインスタンス、損失関数、最適化関数の設定(GPUには送らない)\n",
        "# 引数に作成した行列を追加する\n",
        "model = Nlp84(len(word_id)+2, 300, 4, 50, len(word_id)+1, embd_weights)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "# 今回もバッチサイズ4とする\n",
        "dataloader_train = DataLoader(dataset_train, batch_size=4, shuffle=True,\n",
        "                        collate_fn=my_collate_fn)\n",
        "\n",
        "# 学習の開始\n",
        "# 10エポックで終了とする\n",
        "for ep in range(10):\n",
        "  model.train()\n",
        "  for xs, ys in dataloader_train:\n",
        "    output = model(xs) \n",
        "    loss = criterion(output, ys) \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward() \n",
        "    optimizer.step()\n",
        "\n",
        "  loss_train, accuracy_train = cal_loss_accuracy(model, criterion, dataset_train)\n",
        "  loss_test, accuracy_test = cal_loss_accuracy(model, criterion, dataset_test) \n",
        "  print('エポック数', ep)\n",
        "  print('[訓練データ]損失：',loss_train,'正解率:',accuracy_train)\n",
        "  print('[評価データ]損失：',loss_test,'正解率:',accuracy_test)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "エポック数 0\n",
            "[訓練データ]損失： 1.2789360284805298 正解率: 0.43412667512893677\n",
            "[評価データ]損失： 1.2973862886428833 正解率: 0.32383808493614197\n",
            "エポック数 1\n",
            "[訓練データ]損失： 1.2983262538909912 正解率: 0.42185157537460327\n",
            "[評価データ]損失： 1.2979673147201538 正解率: 0.4220389723777771\n",
            "エポック数 2\n",
            "[訓練データ]損失： 1.319261908531189 正解率: 0.3957083821296692\n",
            "[評価データ]損失： 1.3188124895095825 正解率: 0.3958021104335785\n",
            "エポック数 3\n",
            "[訓練データ]損失： 1.2765278816223145 正解率: 0.39683282375335693\n",
            "[評価データ]損失： 1.2771085500717163 正解率: 0.3965517282485962\n",
            "エポック数 4\n",
            "[訓練データ]損失： 1.3178727626800537 正解率: 0.4196026921272278\n",
            "[評価データ]損失： 1.319366455078125 正解率: 0.4227886199951172\n",
            "エポック数 5\n",
            "[訓練データ]損失： 1.2825437784194946 正解率: 0.4090142548084259\n",
            "[評価データ]損失： 1.2890218496322632 正解率: 0.4227886199951172\n",
            "エポック数 6\n",
            "[訓練データ]損失： 1.289052128791809 正解率: 0.42185157537460327\n",
            "[評価データ]損失： 1.2888617515563965 正解率: 0.4220389723777771\n",
            "エポック数 7\n",
            "[訓練データ]損失： 1.2895276546478271 正解率: 0.42185157537460327\n",
            "[評価データ]損失： 1.289247751235962 正解率: 0.4220389723777771\n",
            "エポック数 8\n",
            "[訓練データ]損失： 1.3198267221450806 正解率: 0.3957083821296692\n",
            "[評価データ]損失： 1.3196851015090942 正解率: 0.3958021104335785\n",
            "エポック数 9\n",
            "[訓練データ]損失： 1.268262267112732 正解率: 0.42185157537460327\n",
            "[評価データ]損失： 1.2676981687545776 正解率: 0.4227886199951172\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETRidP4urpmW"
      },
      "source": [
        "# 85. 双方向RNN・多層化\n",
        "\n",
        "# 双方向RNN・多層化はnn.RNNのパラメータを変更するだけで実装可能\n",
        "# モデルの設定(81の流用(事前学習済み単語ベクトルでは評価が下がったので使用しない))\n",
        "class Nlp85(nn.Module):\n",
        "  def __init__(self, vocab_size, embd_size, output_size, hid_size, padding_idx):\n",
        "    super(Nlp85, self).__init__()\n",
        "    self.embd = nn.Embedding(vocab_size, embd_size, padding_idx=padding_idx)\n",
        "\n",
        "    # 双方向にするにはbidirectional=True\n",
        "    # 多層化にはnum_layersの数値を変更すればよい(デフォルトは1)\n",
        "    self.rnn = nn.RNN(embd_size, hid_size, nonlinearity='tanh', batch_first=True,\n",
        "                      num_layers=2, bidirectional=True)\n",
        "    \n",
        "    # この時RNNのあとの分散表現のサイズが2倍になっているので注意\n",
        "    self.l1=nn.Linear(hid_size*2, output_size)\n",
        "        \n",
        "  def forward(self,x):\n",
        "    ex = self.embd(x)\n",
        "    out, h_T = self.rnn(ex)\n",
        "    h1 = torch.softmax(self.l1(out[:,-1,:]), dim=-1)\n",
        "    return h1"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMhB71LNsgIW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d48bbc6-bf9a-4a7b-c001-c500c5e8a4f1"
      },
      "source": [
        "# モデルのインスタンス、損失関数、最適化関数の設定\n",
        "model = Nlp85(len(word_id)+2, 300, 4, 50, len(word_id)+1)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "dataloader_train = DataLoader(dataset_train, batch_size=4, shuffle=True,\n",
        "                        collate_fn=my_collate_fn)\n",
        "\n",
        "# 学習の開始\n",
        "# 10エポックで終了とする\n",
        "for ep in range(10):\n",
        "  model.train()\n",
        "  for xs, ys in dataloader_train:\n",
        "    output = model(xs) \n",
        "    loss = criterion(output, ys) \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward() \n",
        "    optimizer.step()\n",
        "\n",
        "  loss_train, accuracy_train = cal_loss_accuracy(model, criterion, dataset_train)\n",
        "  loss_test, accuracy_test = cal_loss_accuracy(model, criterion, dataset_test) \n",
        "  print('エポック数', ep)\n",
        "  print('[訓練データ]損失：',loss_train,'正解率:',accuracy_train)\n",
        "  print('[評価データ]損失：',loss_test,'正解率:',accuracy_test)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "エポック数 0\n",
            "[訓練データ]損失： 1.2618197202682495 正解率: 0.422132670879364\n",
            "[評価データ]損失： 1.2628974914550781 正解率: 0.4227886199951172\n",
            "エポック数 1\n",
            "[訓練データ]損失： 1.1313163042068481 正解率: 0.6144115328788757\n",
            "[評価データ]損失： 1.3472105264663696 正解率: 0.3958021104335785\n",
            "エポック数 2\n",
            "[訓練データ]損失： 1.0827618837356567 正解率: 0.6619190573692322\n",
            "[評価データ]損失： 1.093271017074585 正解率: 0.6514242887496948\n",
            "エポック数 3\n",
            "[訓練データ]損失： 1.1246137619018555 正解率: 0.6196589469909668\n",
            "[評価データ]損失： 1.1422545909881592 正解率: 0.6019490361213684\n",
            "エポック数 4\n",
            "[訓練データ]損失： 1.3479722738265991 正解率: 0.3957083821296692\n",
            "[評価データ]損失： 1.348515510559082 正解率: 0.3950524628162384\n",
            "エポック数 5\n",
            "[訓練データ]損失： 1.3478336334228516 正解率: 0.3957083821296692\n",
            "[評価データ]損失： 1.3480664491653442 正解率: 0.3958021104335785\n",
            "エポック数 6\n",
            "[訓練データ]損失： 1.3193633556365967 正解率: 0.4242878556251526\n",
            "[評価データ]損失： 1.3209311962127686 正解率: 0.4227886199951172\n",
            "エポック数 7\n",
            "[訓練データ]損失： 1.1567015647888184 正解率: 0.5718703269958496\n",
            "[評価データ]損失： 1.1563701629638672 正解率: 0.5787106156349182\n",
            "エポック数 8\n",
            "[訓練データ]損失： 1.2206745147705078 正解率: 0.5223950743675232\n",
            "[評価データ]損失： 1.245054006576538 正解率: 0.4985007643699646\n",
            "エポック数 9\n",
            "[訓練データ]損失： 1.2083868980407715 正解率: 0.5355135202407837\n",
            "[評価データ]損失： 1.2169965505599976 正解率: 0.5269864797592163\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpZDgOU65Wg-"
      },
      "source": [
        "# 86. 畳み込みニューラルネットワーク (CNN)\n",
        "# モデルの作成\n",
        "class Nlp86(nn.Module):\n",
        "  def __init__(self, vocab_size, embd_size, output_size, hid_size, padding_idx, kernel_size, stride, padding):\n",
        "    super(Nlp86, self).__init__()\n",
        "    self.embd = nn.Embedding(vocab_size, embd_size, padding_idx=padding_idx)\n",
        "\n",
        "    # CNNはPyTorchのConv2dを用いる\n",
        "    # kernel_size(フィルターのサイズ)、ストライド、パディングの有無(オプションは0)を決定\n",
        "    # 最初の１はCNNの層の数（おそらく）\n",
        "    self.cnn = nn.Conv2d(1, hid_size, (kernel_size, embd_size), stride, (padding, 0))\n",
        "    # 活性化関数は今回はreluを用いる\n",
        "    self.g = nn.ReLU()\n",
        "    self.l1=nn.Linear(hid_size, output_size)\n",
        "        \n",
        "  def forward(self,x):\n",
        "    # 埋め込み層に通した後、unsqueezeでバッチとして直す(CNNに通すため)\n",
        "    ex = self.embd(x).unsqueeze(1)\n",
        "    cn = self.cnn(ex)\n",
        "    # 3個のトークンを活性化関数(今回はrelu)に入力する\n",
        "    pt = self.g(cn.squeeze(3))\n",
        "    # max_pool1d(一次元)を用いて最大値プーリングを行う\n",
        "    # pt.size()[2]はその文の単語数を表している\n",
        "    # つまり文全体を範囲としてプーリングを行う\n",
        "    c = F.max_pool1d(pt, pt.size()[2])\n",
        "    # プーリングで得たcの要素数は3つあるが、最後の軸が必要ないので、squeezeで省く\n",
        "    h1 = torch.softmax(self.l1(c.squeeze(2)), dim=-1)\n",
        "    return h1"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScndJKjr5Y4Z",
        "outputId": "d22ca72d-738f-4059-e71c-91e5802be8a1"
      },
      "source": [
        "# 確認\n",
        "# モデルの引数はRNNとほぼ同じで、最後の3つがフィルターのサイズ(3)、ストライド(1)、パディングの有無(有)\n",
        "model = Nlp86(len(word_id)+2, 300, 4, 50, len(word_id)+1, 3, 1, 1)\n",
        "\n",
        "# 今回は確認なのでバッチ処理で行う\n",
        "dataloader_train = DataLoader(dataset_train, batch_size=len(dataset_train), shuffle=True,\n",
        "                        collate_fn=my_collate_fn)\n",
        "for xs, ys in dataloader_train:\n",
        "  y1_hat=model(xs)\n",
        "  print(y1_hat)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.2035, 0.1997, 0.3897, 0.2071],\n",
            "        [0.2001, 0.1596, 0.4919, 0.1484],\n",
            "        [0.2259, 0.1484, 0.4345, 0.1913],\n",
            "        ...,\n",
            "        [0.1860, 0.0986, 0.4852, 0.2302],\n",
            "        [0.1838, 0.1343, 0.5296, 0.1523],\n",
            "        [0.2429, 0.1552, 0.4276, 0.1743]], grad_fn=<SoftmaxBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2eTUYeiE6z2",
        "outputId": "79dac6a2-8497-4ef9-dda8-edc01727d9ad"
      },
      "source": [
        "# 87. 確率的勾配降下法によるCNNの学習\n",
        "# RNNのときと変わりはない\n",
        "# モデルのインスタンス、損失関数、最適化関数の設定\n",
        "model = Nlp86(len(word_id)+2, 300, 4, 50, len(word_id)+1, 3, 1, 1)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# バッチサイズは同じく4とする\n",
        "dataloader_train = DataLoader(dataset_train, batch_size=4, shuffle=True,\n",
        "                        collate_fn=my_collate_fn)\n",
        "\n",
        "# 学習の開始\n",
        "# 10エポックで終了とする\n",
        "for ep in range(10):\n",
        "  model.train()\n",
        "  for xs, ys in dataloader_train:\n",
        "    output = model(xs) \n",
        "    loss = criterion(output, ys) \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward() \n",
        "    optimizer.step()\n",
        "\n",
        "  loss_train, accuracy_train = cal_loss_accuracy(model, criterion, dataset_train)\n",
        "  loss_test, accuracy_test = cal_loss_accuracy(model, criterion, dataset_test) \n",
        "  print('エポック数', ep)\n",
        "  print('[訓練データ]損失：',loss_train,'正解率:',accuracy_train)\n",
        "  print('[評価データ]損失：',loss_test,'正解率:',accuracy_test)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "エポック数 0\n",
            "[訓練データ]損失： 0.99582839012146 正解率: 0.7579647898674011\n",
            "[評価データ]損失： 1.0292918682098389 正解率: 0.7181409001350403\n",
            "エポック数 1\n",
            "[訓練データ]損失： 0.956272542476654 正解率: 0.7919790148735046\n",
            "[評価データ]損失： 1.0095410346984863 正解率: 0.739130437374115\n",
            "エポック数 2\n",
            "[訓練データ]損失： 0.9396811723709106 正解率: 0.8038793206214905\n",
            "[評価データ]損失： 0.9952110052108765 正解率: 0.7473763227462769\n",
            "エポック数 3\n",
            "[訓練データ]損失： 0.9321897625923157 正解率: 0.8094077706336975\n",
            "[評価データ]損失： 0.9941712021827698 正解率: 0.7481259107589722\n",
            "エポック数 4\n",
            "[訓練データ]損失： 0.9273912310600281 正解率: 0.8118440508842468\n",
            "[評価データ]損失： 0.9898421764373779 正解率: 0.7481259107589722\n",
            "エポック数 5\n",
            "[訓練データ]損失： 0.9249825477600098 正解率: 0.8130621910095215\n",
            "[評価データ]損失： 0.9882882833480835 正解率: 0.7533733248710632\n",
            "エポック数 6\n",
            "[訓練データ]損失： 0.9230136275291443 正解率: 0.8139992356300354\n",
            "[評価データ]損失： 0.9866572022438049 正解率: 0.7533733248710632\n",
            "エポック数 7\n",
            "[訓練データ]損失： 0.9217024445533752 正解率: 0.8145614862442017\n",
            "[評価データ]損失： 0.9871091246604919 正解率: 0.7503747940063477\n",
            "エポック数 8\n",
            "[訓練データ]損失： 0.9208493828773499 正解率: 0.8149362802505493\n",
            "[評価データ]損失： 0.9866696000099182 正解率: 0.7541229128837585\n",
            "エポック数 9\n",
            "[訓練データ]損失： 0.9198656678199768 正解率: 0.815311074256897\n",
            "[評価データ]損失： 0.9862561821937561 正解率: 0.7533733248710632\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e99yVMPwWx_M",
        "outputId": "3e74b5a1-80a9-4b99-e9ad-5e781937b9c5"
      },
      "source": [
        "# 88. パラメータチューニング\n",
        "# チューニングのためにoptunaを用いるのでインストールする\n",
        "!pip install optuna"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/18/b49ca91cf592747e19f2d333c2a86cd7c81895b922a5a09adf6335471576/optuna-2.8.0-py3-none-any.whl (301kB)\n",
            "\u001b[K     |████████████████████████████████| 307kB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.19.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (20.9)\n",
            "Collecting alembic\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/80/ef186e599a57d0e4cb78fc76e0bfc2e6953fa9716b2a5cf2de0117ed8eb5/alembic-1.6.5-py2.py3-none-any.whl (164kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 5.2MB/s \n",
            "\u001b[?25hCollecting cmaes>=0.8.2\n",
            "  Downloading https://files.pythonhosted.org/packages/01/1f/43b01223a0366171f474320c6e966c39a11587287f098a5f09809b45e05f/cmaes-0.8.2-py3-none-any.whl\n",
            "Collecting colorlog\n",
            "  Downloading https://files.pythonhosted.org/packages/32/e6/e9ddc6fa1104fda718338b341e4b3dc31cd8039ab29e52fc73b508515361/colorlog-5.0.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Collecting cliff\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/11/aea1cacbd4cf8262809c4d6f95dcb3f2802594de1f51c5bd454d69bf15c5/cliff-3.8.0-py3-none-any.whl (80kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 4.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.6.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (2.8.1)\n",
            "Collecting Mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/54/dbc07fbb20865d3b78fdb7cf7fa713e2cba4f87f71100074ef2dc9f9d1f7/Mako-1.1.4-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 4.6MB/s \n",
            "\u001b[?25hCollecting python-editor>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
            "Collecting cmd2>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/ca/d407811641ec1d8bd8a38ee3165d73aa44776d7700436bd4d4a6606f2736/cmd2-2.1.2-py3-none-any.whl (141kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 5.4MB/s \n",
            "\u001b[?25hCollecting stevedore>=2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/49/b602307aeac3df3384ff1fcd05da9c0376c622a6c48bb5325f28ab165b57/stevedore-3.3.0-py3-none-any.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 3.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.13)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.1.0)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/e0/1d4702dd81121d04a477c272d47ee5b6bc970d1a0990b11befa275c55cf2/pbr-5.6.0-py2.py3-none-any.whl (111kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 6.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->sqlalchemy>=1.1.0->optuna) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->sqlalchemy>=1.1.0->optuna) (3.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->alembic->optuna) (1.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Collecting colorama>=0.3.7\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/a7/2c/4c64579f847bd5d539803c8b909e54ba087a79d01bb3aba433a95879a6c5/pyperclip-1.8.2.tar.gz\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.2.0)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-cp37-none-any.whl size=11136 sha256=620369dafe4ef6d49abcd58558ede05d502f557bf40187f4d42e8f18151c2818\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/af/b8/3407109267803f4015e1ee2ff23be0c8c19ce4008665931ee1\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: Mako, python-editor, alembic, cmaes, colorlog, colorama, pyperclip, cmd2, pbr, stevedore, cliff, optuna\n",
            "Successfully installed Mako-1.1.4 alembic-1.6.5 cliff-3.8.0 cmaes-0.8.2 cmd2-2.1.2 colorama-0.4.4 colorlog-5.0.1 optuna-2.8.0 pbr-5.6.0 pyperclip-1.8.2 python-editor-1.0.4 stevedore-3.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKKEx5lNY7NE"
      },
      "source": [
        "# 85(双方向RNN・多層化)のモデル\n",
        "# 活性化関数をtanhとreluに変更できるようにする\n",
        "class RNN88(nn.Module):\n",
        "  def __init__(self, vocab_size, embd_size, output_size, hid_size, padding_idx, g):\n",
        "    super(RNN88, self).__init__()\n",
        "    self.embd = nn.Embedding(vocab_size, embd_size, padding_idx=padding_idx)\n",
        "    if g == 'tanh':\n",
        "      self.rnn = nn.RNN(embd_size, hid_size, nonlinearity='tanh', batch_first=True,\n",
        "                        num_layers=2, bidirectional=True)\n",
        "    elif g == 'relu':\n",
        "      self.rnn = nn.RNN(embd_size, hid_size, nonlinearity='relu', batch_first=True,\n",
        "                        num_layers=2, bidirectional=True)\n",
        "    self.l1=nn.Linear(hid_size*2, output_size)\n",
        "        \n",
        "  def forward(self,x):\n",
        "    ex = self.embd(x)\n",
        "    out, h_T = self.rnn(ex)\n",
        "    h1 = torch.softmax(self.l1(out[:,-1,:]), dim=-1)\n",
        "    return h1"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Imhl-HRRYeRA"
      },
      "source": [
        "# 86(CNN)のモデル\n",
        "class CNN88(nn.Module):\n",
        "  def __init__(self, vocab_size, embd_size, output_size, hid_size, padding_idx, kernel_size, stride, padding, g):\n",
        "    super(CNN88, self).__init__()\n",
        "    self.embd = nn.Embedding(vocab_size, embd_size, padding_idx=padding_idx)\n",
        "    self.cnn = nn.Conv2d(1, hid_size, (kernel_size, embd_size), stride, (padding, 0))\n",
        "    if g == 'tanh':\n",
        "      self.g = nn.Tanh()\n",
        "    elif g == 'relu':\n",
        "      self.g = nn.ReLU()\n",
        "    self.l1=nn.Linear(hid_size, output_size)\n",
        "        \n",
        "  def forward(self,x):\n",
        "    ex = self.embd(x).unsqueeze(1)\n",
        "    cn = self.cnn(ex)\n",
        "    pt = self.g(cn.squeeze(3))\n",
        "    c = F.max_pool1d(pt, pt.size()[2])\n",
        "    h1 = torch.softmax(self.l1(c.squeeze(2)), dim=-1)\n",
        "    return h1"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkvBge1FW0FL"
      },
      "source": [
        "# optunaを用いてパラメータの探索を行う\n",
        "import optuna\n",
        "# 探索のための関数の設定\n",
        "def objective(trial):\n",
        "  # チューニング対象のパラメータを決める\n",
        "  # 用いるモデル、埋め込み層のサイズ、隠れ層のサイズ、学習率、バッチサイズを対象とする\n",
        "  model_category = trial.suggest_categorical(\"category\", [\"RNN\",\"CNN\"])\n",
        "  embd_size = int(trial.suggest_discrete_uniform('embd_size', 100, 400, 100))\n",
        "  hid_size = int(trial.suggest_discrete_uniform('hid_size', 50, 200, 50))\n",
        "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 1e-1)\n",
        "  batch_size = int(trial.suggest_discrete_uniform('batch_size', 4, 16, 4))\n",
        "  g = trial.suggest_categorical(\"g\", [\"tanh\", \"relu\"])\n",
        "\n",
        "  # 単語の総数、単語ベクトル、出力ラベル、隠れ層の次元、Paddingの数値は固定\n",
        "  vocab_size=len(word_id)+2\n",
        "  padding_idx=len(word_id)+1\n",
        "  output_size=4\n",
        "\n",
        "  # モデルの設定(最後に活性化関数の選択のための引数を追加しておく)\n",
        "  # RNNかCNNかを選択する\n",
        "  if model_category == \"RNN\":\n",
        "    model = RNN88(vocab_size, embd_size, output_size, hid_size, padding_idx, g)\n",
        "  elif model_category == \"CNN\":\n",
        "    # kernel_size(フィルターのサイズ)、ストライド、パディング有は固定\n",
        "    model = CNN88(vocab_size, embd_size, output_size, hid_size, padding_idx, 3, 1, 1, g)\n",
        "\n",
        "  # 損失関数、最適化関数の設定\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  # 学習率は上で設定したパラメータの中から選択される\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  # データの設定においてもバッチサイズは上で設定したものが選択される\n",
        "  dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True,\n",
        "                          collate_fn=my_collate_fn)\n",
        "\n",
        "  # 学習の開始\n",
        "  # 10エポックで終了とする\n",
        "  for ep in range(10):\n",
        "    model.train()\n",
        "    for xs, ys in dataloader_train:\n",
        "      output = model(xs) \n",
        "      loss = criterion(output, ys) \n",
        "      optimizer.zero_grad()\n",
        "      loss.backward() \n",
        "      optimizer.step()\n",
        "\n",
        "  # 検証用のデータを用いて、ベストなパラメータを決定する\n",
        "  loss_valid, accuracy_valid = cal_loss_accuracy(model, criterion, dataset_valid)\n",
        "\n",
        "  # 評価に用いるのは検証データの損失とする(optunaが最小を選択するため)\n",
        "  return loss_valid "
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_9DDa4chjev",
        "outputId": "73d44763-9a79-4034-c5e0-9c44a7278de5"
      },
      "source": [
        "# create_study()を用いてパラメータの探索を行う\n",
        "study = optuna.create_study()\n",
        "# timeoutで探索を切り上げる時間を設定(今回は短めにして1000秒)\n",
        "study.optimize(objective, timeout=1000)\n",
        "\n",
        "# study.best_trialでベストパラメータと値を取得可能\n",
        "trial = study.best_trial\n",
        "# 結果の表示\n",
        "print('Best Accuracy:', trial.value)\n",
        "print('[Best Params]')\n",
        "for key, value in trial.params.items():\n",
        "  print(key ,':', value)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-12 00:15:57,996]\u001b[0m A new study created in memory with name: no-name-45ed2896-aedf-4f89-b0a6-198861a89589\u001b[0m\n",
            "\u001b[32m[I 2021-07-12 00:23:43,528]\u001b[0m Trial 0 finished with value: 1.1324578523635864 and parameters: {'category': 'RNN', 'embd_size': 400.0, 'hid_size': 50.0, 'learning_rate': 0.015484215232821086, 'batch_size': 4.0, 'g': 'tanh'}. Best is trial 0 with value: 1.1324578523635864.\u001b[0m\n",
            "\u001b[32m[I 2021-07-12 00:25:37,643]\u001b[0m Trial 1 finished with value: 1.0060577392578125 and parameters: {'category': 'CNN', 'embd_size': 200.0, 'hid_size': 150.0, 'learning_rate': 0.011538353895505216, 'batch_size': 12.0, 'g': 'tanh'}. Best is trial 1 with value: 1.0060577392578125.\u001b[0m\n",
            "\u001b[32m[I 2021-07-12 00:29:05,112]\u001b[0m Trial 2 finished with value: 0.9895407557487488 and parameters: {'category': 'CNN', 'embd_size': 400.0, 'hid_size': 150.0, 'learning_rate': 0.021567578797463297, 'batch_size': 12.0, 'g': 'relu'}. Best is trial 2 with value: 0.9895407557487488.\u001b[0m\n",
            "\u001b[32m[I 2021-07-12 00:32:07,079]\u001b[0m Trial 3 finished with value: 1.0736619234085083 and parameters: {'category': 'RNN', 'embd_size': 200.0, 'hid_size': 100.0, 'learning_rate': 0.006761102228393395, 'batch_size': 8.0, 'g': 'tanh'}. Best is trial 2 with value: 0.9895407557487488.\u001b[0m\n",
            "\u001b[32m[I 2021-07-12 00:35:36,318]\u001b[0m Trial 4 finished with value: 1.0693291425704956 and parameters: {'category': 'RNN', 'embd_size': 200.0, 'hid_size': 200.0, 'learning_rate': 0.006763173787438854, 'batch_size': 12.0, 'g': 'tanh'}. Best is trial 2 with value: 0.9895407557487488.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best Accuracy: 0.9895407557487488\n",
            "[Best Params]\n",
            "category : CNN\n",
            "embd_size : 400.0\n",
            "hid_size : 150.0\n",
            "learning_rate : 0.021567578797463297\n",
            "batch_size : 12.0\n",
            "g : relu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-gKxufP1TYI",
        "outputId": "18118d7e-3a26-4e53-ca04-a096e84b0f6d"
      },
      "source": [
        "# 求めたパラメータで再度学習を行い評価データの正解率を求める\n",
        "# 単語の総数、単語ベクトル、出力ラベル、隠れ層の次元、Paddingの数値は固定\n",
        "vocab_size=len(word_id)+2\n",
        "padding_idx=len(word_id)+1\n",
        "output_size=4\n",
        "\n",
        "# ベストパラメータを取得\n",
        "# float型になっているので、sizeなどはint型に直しておく\n",
        "model_category = trial.params['category']\n",
        "embd_size = int(trial.params['embd_size'])\n",
        "hid_size = int(trial.params['hid_size'])\n",
        "learning_rate = trial.params['learning_rate']\n",
        "batch_size = int(trial.params['batch_size'])\n",
        "g = trial.params['g']\n",
        "\n",
        "# モデルの設定(最後に活性化関数の選択のための引数を追加しておく)\n",
        "if model_category == \"RNN\":\n",
        "  model = RNN88(vocab_size, embd_size, output_size, hid_size, padding_idx, g)\n",
        "elif model_category == \"CNN\":\n",
        "  model = CNN88(vocab_size, embd_size, output_size, hid_size, padding_idx, 3, 1, 1, g)\n",
        "\n",
        "# 損失関数、最適化関数の設定\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True,\n",
        "                        collate_fn=my_collate_fn)\n",
        "\n",
        "# 学習の開始\n",
        "# 10エポックで終了とする\n",
        "for ep in range(10):\n",
        "  model.train()\n",
        "  for xs, ys in dataloader_train:\n",
        "    output = model(xs) \n",
        "    loss = criterion(output, ys) \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward() \n",
        "    optimizer.step()\n",
        "\n",
        "# 検証用のデータを用いて、ベストなパラメータを決定する\n",
        "loss_test, accuracy_test = cal_loss_accuracy(model, criterion, dataset_test)\n",
        "print(accuracy_test)\n",
        "# モデルの確認\n",
        "print(model)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7646176815032959\n",
            "CNN88(\n",
            "  (embd): Embedding(9399, 400, padding_idx=9398)\n",
            "  (cnn): Conv2d(1, 150, kernel_size=(3, 400), stride=(1, 1), padding=(1, 0))\n",
            "  (g): ReLU()\n",
            "  (l1): Linear(in_features=150, out_features=4, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJFFV8F-7csb",
        "outputId": "888b3df6-3a7d-4b38-da0b-0bedcd35fec8"
      },
      "source": [
        "# 89. 事前学習済み言語モデルからの転移学習\n",
        "# BERTを用いるためにtransformersをインストールする\n",
        "!pip install transformers"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/1a/41c644c963249fd7f3836d926afa1e3f1cc234a1c40d80c5f03ad8f6f1b2/transformers-4.8.2-py3-none-any.whl (2.5MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5MB 3.9MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 33.5MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 44.9MB/s \n",
            "\u001b[?25hCollecting huggingface-hub==0.0.12\n",
            "  Downloading https://files.pythonhosted.org/packages/2f/ee/97e253668fda9b17e968b3f97b2f8e53aa0127e8807d24a547687423fe0b/huggingface_hub-0.0.12-py3-none-any.whl\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.0.12 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.8.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXPWWGcS8NfR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166,
          "referenced_widgets": [
            "cd166929bcc54b6abc0207708532fdf9",
            "595a66c0c7bb4195ae44bcf95285ef8f",
            "6823239db42543c59eb2feae40358a5f",
            "4bd9b9ba678a4f0988904861ac1425da",
            "c7a88a005e9f434a8f28dce02c980827",
            "75d6a6e3e9c842488a043c62c9509e09",
            "efa05073f73e45019d5d52a62dc2f2b1",
            "42be44f8afa24d44a13b5287470786c3",
            "de70af565f164d2299cadc3660f59a32",
            "92a5b8aa11e84e669caafb527a8e5401",
            "3a7be42e06f44b97851df454b0ff7d1b",
            "b8aa4967028d466fb7c94945b3683b3a",
            "17f78fa26485417bb1e91e2f398d4c8c",
            "ed27845a7aca4184b254ab49b2333a0a",
            "805f52ceae2241998b35c71b38585bd3",
            "db8450e5e4d14eb18df646ce40541880",
            "ffb59f745a7f4d57b4f88b0229db91f7",
            "fd5b7ca54f8e47bf87d77fe1cac8baf0",
            "8d3f116b99d4495fbc881550dc497ff2",
            "45a63dbdb06c4c7bba3bcf8cedc3ab82",
            "7d9c0d184a7c4c89809fe729b1a36c94",
            "98e2453ff0aa4934a306c01050e40074",
            "a46c652e0f654dbd99628d229bb3b334",
            "265da60f5f6b468fb214fbe35d83ec14"
          ]
        },
        "outputId": "a79b4600-0741-4eee-f18b-d873e4a38c07"
      },
      "source": [
        "from transformers import BertModel\n",
        "from transformers import BertTokenizer\n",
        "# BERTの入力となる単語id列に変換する必要がある(上で設定したidとは別)\n",
        "# 変換のためにBERTを読み込む(Hugging faceに登録されている？もの)\n",
        "tknz = BertTokenizer.from_pretrained('bert-base-cased')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd166929bcc54b6abc0207708532fdf9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de70af565f164d2299cadc3660f59a32",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=29.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ffb59f745a7f4d57b4f88b0229db91f7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435797.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yETh-G-i_rDi",
        "outputId": "b33759b5-b3ad-4557-b503-e9ed8f31984a"
      },
      "source": [
        "# 与えられた単語列に対しBERT用の単語idを返す関数\n",
        "def return_bert_id(text):\n",
        "  # 問80で作成したものと同じ前処理を施す\n",
        "  table = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
        "  words = text.translate(table).split()\n",
        "  # encode()で文を単語id列に変換する(80とは違い文をまとめて変換可能)\n",
        "  # 辞書に登録されていない単語も自動的にidに変換される(id:100)\n",
        "  ids = tknz.encode(words)\n",
        "  return ids\n",
        "\n",
        "# 確認(適当な記事見出しを選択)\n",
        "text = train['TITLE'][0]\n",
        "print(text)\n",
        "# BERTは文頭トークン([CLS])と文末トークン([SEP])がつく(idは101と102)\n",
        "print(return_bert_id(text))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bouygues confirms improved offer for Vivendi's SFR\n",
            "[101, 100, 26064, 4725, 2906, 1111, 100, 188, 100, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCpVHU1e73GR"
      },
      "source": [
        "# BERT用データセットを作成する(基本的には前と同じ)\n",
        "class MyDataset_bert(Dataset):\n",
        "  def __init__(self, xdata, ydata, return_bert_id):\n",
        "    self.data = xdata\n",
        "    self.label = ydata\n",
        "    self.return_bert_id = return_bert_id\n",
        "\n",
        "  def __len__(self):  \n",
        "    return len(self.label)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    # 上で作成したBERT用の関数を用いて単語列をidに変換し返す\n",
        "    text = self.data[idx]\n",
        "    x = self.return_bert_id(text)\n",
        "    y = self.label[idx]\n",
        "    return x,y\n",
        "\n",
        "# 同じくDataloaderの際にPaddingを行うようにする\n",
        "def my_collate_bert_fn(batch):\n",
        "  xdata, ydata = list(zip(*batch))\n",
        "  xs = list(xdata)\n",
        "  # Paddingを行うときにPaddingを行った箇所を示すマスク行列を作成する\n",
        "  # マスクはPadding以外の部分が1となるような行列である\n",
        "  xs1, xmsk = [], []\n",
        "  for k in range(len(xs)):\n",
        "    ids = xs[k]\n",
        "    xs1.append(torch.LongTensor(ids))\n",
        "    xmsk.append(torch.LongTensor([1]*len(ids)))\n",
        "  # Paddingの数値は0とする\n",
        "  xs1 = pad_sequence(xs1, batch_first=True, padding_value=0)\n",
        "  xmsk = pad_sequence(xmsk, batch_first=True, padding_value=0)\n",
        "  \n",
        "  ys = list(ydata)\n",
        "  ys1 = torch.LongTensor(ys)\n",
        "\n",
        "  return xs1, ys1, xmsk"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RrEv-sjAoL4"
      },
      "source": [
        "# ラベルに関しては必要ないが一応ここでも記述しておく\n",
        "category_dict = {'b': 0, 't': 1, 'e':2, 'm':3}\n",
        "Y_train = torch.tensor(list(map(lambda x: category_dict[x], train['CATEGORY'])))\n",
        "Y_valid = torch.tensor(list(map(lambda x: category_dict[x], valid['CATEGORY'])))\n",
        "Y_test = torch.tensor(list(map(lambda x: category_dict[x], test['CATEGORY'])))\n",
        "\n",
        "# それぞれのデータセットを作成\n",
        "dataset_bert_train = MyDataset_bert(train['TITLE'], Y_train, return_bert_id)\n",
        "dataset_bert_valid = MyDataset_bert(valid['TITLE'], Y_valid, return_bert_id)\n",
        "dataset_bert_test = MyDataset_bert(test['TITLE'], Y_test, return_bert_id)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Y0UCFQQQYpB",
        "outputId": "61cb15cd-d225-4caf-b144-2b2926db74da"
      },
      "source": [
        "# 確認\n",
        "dataloader_train = DataLoader(dataset_bert_train, batch_size=4, shuffle=True,\n",
        "                        collate_fn=my_collate_bert_fn)\n",
        "d1 = dataloader_train.__iter__()\n",
        "xs, ys, xmsk = d1.next()\n",
        "print(xs)\n",
        "print(xmsk)\n",
        "print(len(xs))\n",
        "print(ys)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[  101,   100, 21530,  6386,  1485,   125,  2370,  1822,  3075,  1104,\n",
            "           100,   188,  1963,   102],\n",
            "        [  101,  4754,   100,  5620,  1398,  1422,  4288,  7617,   100,  1335,\n",
            "          5691,   102,     0,     0],\n",
            "        [  101, 26356,   100,  2818,  6300,  1257,  1322,  1104, 13274, 18908,\n",
            "           102,     0,     0,     0],\n",
            "        [  101,   100,   122,  3461,   100,  5351,  1136, 20342,  2631,  5351,\n",
            "          1308,   102,     0,     0]])\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]])\n",
            "4\n",
            "tensor([0, 2, 0, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MDYHSa8WLzv"
      },
      "source": [
        "# モデルの実装\n",
        "class Bert89(nn.Module):\n",
        "  def __init__(self, bert):\n",
        "    super(Bert89, self).__init__()\n",
        "    # bertを読み込む\n",
        "    self.bert = bert\n",
        "    # bertの出力は768次元となる\n",
        "    # またラベルは4次元で固定なのでここで指定しておく\n",
        "    self.cls = nn.Linear(768, 4)\n",
        "  \n",
        "  # 計算時の引数としてマスクを追加する\n",
        "  def forward(self,x1,x2):\n",
        "    # attention_maskでマスクを渡せる\n",
        "    bout = self.bert(input_ids=x1, attention_mask=x2)\n",
        "    bs = len(bout[0])\n",
        "    # bout[0][i][0]はバッチ内のi番目の文に\n",
        "    # 対する[CLS]の埋め込み表現\n",
        "    # これをリストで集めstackで連結する\n",
        "    h0 = [ bout[0][i][0] for i in range(bs)]\n",
        "    h0 = torch.stack(h0,dim=0)\n",
        "    # 最終的に先頭の[CLS]の埋め込み表現を用いてラベルの予測をする\n",
        "    # 今回はsoftmax関数は用いない\n",
        "    return self.cls(h0)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyOqV2VxFr_0"
      },
      "source": [
        "# 正解率と損失の計算のための関数\n",
        "def cal_loss_accuracy_bert(model, dataset):\n",
        "  # BERTはサイズが大きいのでバッチ処理を行うとメモリが不足するので、1つずつ正解を見る\n",
        "  dataloader = DataLoader(dataset, batch_size=1, shuffle=False,\n",
        "                        collate_fn=my_collate_bert_fn)\n",
        "  real_data_num, ok = 0, 0\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for xs, ys, xmsk in dataloader:\n",
        "      output = model(xs, xmsk)\n",
        "      # 正解率のみ計算する\n",
        "      ans = torch.argmax(output,dim=1).item()\n",
        "      if ans == ys:\n",
        "        ok += 1\n",
        "      real_data_num += 1\n",
        "\n",
        "    accuracy = ok / real_data_num\n",
        "  return accuracy"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RK5Yzch34Mha",
        "outputId": "5fccb4ee-29c5-498c-9cec-0f68660cbcf4"
      },
      "source": [
        "# BERTを読み込む2\n",
        "bert = BertModel.from_pretrained('bert-base-cased')\n",
        "# 損失関数、モデルのインスタンス、最適化関数の設定\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "model = Bert89(bert)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# バッチサイズは4とする\n",
        "dataloader_train = DataLoader(dataset_bert_train, batch_size=4, shuffle=True,\n",
        "                        collate_fn=my_collate_bert_fn)\n",
        "\n",
        "# 学習の開始(流れは同じ)\n",
        "# 5エポックで終了とする(時間短縮のため)\n",
        "for ep in range(5):\n",
        "  model.train()\n",
        "  for xs, ys, xmsk in dataloader_train:\n",
        "    output = model(xs, xmsk) \n",
        "    loss = criterion(output, ys) \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward() \n",
        "    optimizer.step()\n",
        "\n",
        "  accuracy_train = cal_loss_accuracy_bert(model, dataset_bert_train)\n",
        "  accuracy_test = cal_loss_accuracy_bert(model, dataset_bert_test) \n",
        "  print('エポック数', ep)\n",
        "  print('[訓練データ]正解率:',accuracy_train)\n",
        "  print('[評価データ]正解率:',accuracy_test)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "エポック数 0\n",
            "[訓練データ]正解率: 0.8897113943028486\n",
            "[評価データ]正解率: 0.856071964017991\n",
            "エポック数 1\n",
            "[訓練データ]正解率: 0.9145427286356822\n",
            "[評価データ]正解率: 0.8590704647676162\n",
            "エポック数 2\n",
            "[訓練データ]正解率: 0.9347826086956522\n",
            "[評価データ]正解率: 0.8755622188905547\n",
            "エポック数 3\n",
            "[訓練データ]正解率: 0.9416229385307346\n",
            "[評価データ]正解率: 0.8650674662668666\n",
            "エポック数 4\n",
            "[訓練データ]正解率: 0.9580209895052474\n",
            "[評価データ]正解率: 0.8718140929535232\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}